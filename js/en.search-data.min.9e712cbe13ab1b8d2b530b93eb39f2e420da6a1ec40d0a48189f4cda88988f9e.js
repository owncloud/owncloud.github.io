'use strict';(function(){const indexCfg={};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create(indexCfg);window.geekdocSearchIndex=index;index.add({'id':0,'href':'/ocis/getting-started/','title':"Getting Started",'content':"    Installation  Docker  Dependencies Docker compose   Binaries  Dependencies     Usage  Server Health   Quickstart for Developers Runtime Metrics     Installation So far we are offering two different variants for the installation. You can choose between Docker or pre-built binaries which are stored on our download mirrors and GitHub releases. Maybe we will also provide system packages for the major distributions later if we see the need for it.\nDocker Docker images for ocis are hosted on https://hub.docker.com/r/owncloud/ocis.\nThe latest tag always reflects the current master branch.\ndocker pull owncloud/ocis Dependencies  Running ocis currently needs a working Redis caching server The default storage location in the container is /var/tmp/reva/data. You may want to create a volume to persist the files in the primary storage  Docker compose You can use our docker-compose playground example to run ocis with dependencies with a single command in a docker network.\ngit clone git@github.com:owncloud-docker/compose-playground.git cd compose-playground/ocis docker-compose -f ocis.yml -f ../cache/redis-ocis.yml up Binaries The pre-built binaries for different platforms are downloadable at https://download.owncloud.com/ocis/ocis/ . Specific releases are organized in separate folders. They are in sync which every release tag on GitHub. The binaries from the current master branch can be found in https://download.owncloud.com/ocis/ocis/testing/\ncurl https://download.owncloud.com/ocis/ocis/1.0.0-beta1/ocis-1.0.0-beta1-darwin-amd64 --output ocis chmod +x ocis ./ocis server Dependencies  Running ocis currently needs a working Redis caching server The default promary storage location is /var/tmp/reva/data. You can change that value by configuration.  Usage The program provides a few sub-commands on execution. The available configuration methods have already been mentioned above. Generally you can always see a formated help output if you execute the binary via ocis --help.\nServer The server command is used to start the http and debug server on two addresses within a single process. The http server is serving the general webservice while the debug server is used for health check, readiness check and to server the metrics mentioned below. For further help please execute:\nocis server --help Health The health command is used to execute a health check, if the exit code equals zero the service should be up and running, if the exist code is greater than zero the service is not in a healthy state. Generally this command is used within our Docker containers, it could also be used within Kubernetes.\nocis health --help Quickstart for Developers Following https://github.com/owncloud/ocis#development\ngit clone https://github.com/owncloud/ocis.git cd ocis make generate build Open https://localhost:9200 and login using one of the demo accounts:\neinstein:relativity marie:radioactivity feynman:superfluidity Runtime Included with the ocis binary is embedded a go-micro runtime that is in charge of starting services as a fork of the master process. This provides complete control over the services. Ocis extensions can be added as part of this runtime.\n./bin/ocis micro This will currently boot:\ncom.owncloud.api com.owncloud.http.broker com.owncloud.proxy com.owncloud.registry com.owncloud.router com.owncloud.runtime com.owncloud.web go.micro.http.broker Further ocis extensions can be added to the runtime via the ocis command like:\n./bin/ocis hello Which will register:\ncom.owncloud.web.hello com.owncloud.api.hello To the list of available services.\nMetrics This service provides some Prometheus metrics through the debug endpoint, you can optionally secure the metrics endpoint by some random token, which got to be configured through one of the flag --debug-token or the environment variable OCIS_DEBUG_TOKEN mentioned above. By default the metrics endpoint is bound to http://0.0.0.0:8001/metrics.\n go_gc_duration_seconds A summary of the GC invocation durations go_gc_duration_seconds_sum A summary of the GC invocation durations go_gc_duration_seconds_count A summary of the GC invocation durations go_goroutines Number of goroutines that currently exist go_info Information about the Go environment go_memstats_alloc_bytes Number of bytes allocated and still in use go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table go_memstats_frees_total Total number of frees go_memstats_gc_cpu_fraction The fraction of this program\u0026rsquo;s available CPU time used by the GC since the program started go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use go_memstats_heap_idle_bytes Number of heap bytes waiting to be used go_memstats_heap_inuse_bytes Number of heap bytes that are in use go_memstats_heap_objects Number of allocated objects go_memstats_heap_released_bytes Number of heap bytes released to OS go_memstats_heap_sys_bytes Number of heap bytes obtained from system go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection go_memstats_lookups_total Total number of pointer lookups go_memstats_mallocs_total Total number of mallocs go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place go_memstats_other_sys_bytes Number of bytes used for other system allocations go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator go_memstats_sys_bytes Number of bytes obtained from system go_threads Number of OS threads created promhttp_metric_handler_requests_in_flight Current number of scrapes being served promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code  "});index.add({'id':1,'href':'/clients/web/','title':"Phoenix",'content':"This is the next generation ownCloud frontend.\n"});index.add({'id':2,'href':'/ocis/development/','title':"Development",'content':"    Deployments Scenarios and Examples     Deployments Scenarios and Examples "});index.add({'id':3,'href':'/ocis/deployment/','title':"Deployment",'content':"    Deployments Scenarios and Examples  Setup oCIS Migrate an existing ownCloud 10       Deployments Scenarios and Examples This section handles deployments and operations for admins. If you are looking for a development setup, start with\nSetup oCIS oCIS deployments are super simple, yet there are many configrations possible for advanced setups.\n Basic setup - download and run Pick services and manage them individually SSL offloading with Traefik Use an external IDP  Migrate an existing ownCloud 10 You can run ownCloud 10 and oCIS together. This allows you to use new parts of oCIS already with ownCloud 10 and also to have a smooth transition for users from ownCloud 10 to oCIS.\n ownCloud 10 with oCIS IDP Switch on the new front end \u0026ldquo;oCIS web\u0026rdquo; with ownCloud 10 Run ownCloud 10 and oCIS in parallel - together Migrate users from ownCloud 10 to oCIS  "});index.add({'id':4,'href':'/ocis/','title':"oCIS",'content':" ownCloud Infinite Scale Welcome to oCIS! We develop a modern file-sync and share plattform, based on our knowledge and experience with the PHP ownCloud server project.\noCIS Server The oCIS server implementation follows go-lang best practices and is based on the go-micro framework and REVA. We love and stick to 12 Factor. oCIS is a micro-service based server, which allows scale-out of individual services to meet your specific performance requirements. We run a huge test suite, which was originated in ownCloud 10 and continues to grow.\nArchitecture Overview   mermaid.initialize({ flowchart: { useMaxWidth: true } });  graph TD ocis-proxy -- ocis-konnectd \u0026 ocis-phoenix \u0026 ocis-thumbnails \u0026 ocis-ocs \u0026 ocis-webdav ocis-phoenix -- ocis-reva-fronted ocis-reva-fronted -- ocis-reva-gateway ocis-konnectd -- ocis-glauth ocis-reva-gateway -- ocis-reva-users ocis-reva-gateway -- ocis-reva-authbasic ocis-reva-gateway -- ocis-reva-auth-bearer ocis-reva-gateway -- ocis-reva-sharing ocis-reva-gateway -- ocis-reva-storage-home-* ocis-reva-storage-home-* -- ocis-reva-storage-home-*-data ocis-reva-sharing -- redis "});index.add({'id':5,'href':'/integration/file_picker/','title':"File Picker",'content':"Easily integrate ownCloud into your own product.\n"});index.add({'id':6,'href':'/integration/file_picker/getting-started/','title':"Getting Started",'content':"    Components of the File picker  File picker Location picker       ownCloud File picker is a web component which can be integrated into existing web applications. It connects to an ownCloud server and enables a user to select resources which are then provided in a response of a fired event. Visit installation to see how to integrate the File picker into your product.\nComponents of the File picker The file picker can be used in two different variations: File picker and location picker.\nFile picker The file picker enables users to select multiple resources and is intended to bring resources from within ownCloud into your web applications.\nLocation picker The location picker allows only one folder to be selected and its main purpose is to enable users to save files into the connected ownCloud instance.\n"});index.add({'id':7,'href':'/integration/file_picker/installation/','title':"Installation",'content':"    Setup authorization Install File picker package Integrate in HTML page with vanilla JavaScript Integrate in Vue web application Set correct variation     Setup authorization The config for authorization is provided via a json file. Location of the file can be provided via a prop called configLocation. This requires full URL address (e.g. https://\u0026lt;your-server\u0026gt;/\u0026lt;path-to-the-config\u0026gt;). If the prop is not defined, the location will fallback to https://\u0026lt;your-server\u0026gt;/file-picker-config.json. The config can point to both oauth2 and OIDC. You can take a look at the following example to see how OIDC can be defined:\n{ \u0026#34;server\u0026#34;: \u0026#34;\u0026lt;owncloud-server\u0026gt;\u0026#34;, \u0026#34;openIdConnect\u0026#34;: { \u0026#34;metadata_url\u0026#34;: \u0026#34;\u0026lt;your-server\u0026gt;/.well-known/openid-configuration\u0026#34;, \u0026#34;authority\u0026#34;: \u0026#34;\u0026lt;your-server\u0026gt;\u0026#34;, \u0026#34;client_id\u0026#34;: \u0026#34;\u0026lt;client-id\u0026gt;\u0026#34;, \u0026#34;response_type\u0026#34;: \u0026#34;code\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;openid profile email\u0026#34; }, } Install File picker package To integrate File picker into your own product, you can install it via one of the following commands:\nnpm install @ownclouders/file-picker --save # OR yarn add @ownclouders/file-picker Integrate in HTML page with vanilla JavaScript When including File picker in an HTML page, it is important to include Vue.js as well. In this case, we will import it via unpkg. Without this, the component won\u0026rsquo;t work. Vue needs to be included also if you\u0026rsquo;re importing the File picker into a web application built with other framework than Vue (e.g. React, Angular).\nFor the purpose of this example, we will assume that you do not move installed packages and include the folder \u0026ldquo;node_modules\u0026rdquo; with installed packages in the same location as your index.html file on your server.\n... \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;File picker example\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;https://unpkg.com/vue\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;./node_modules/file-picker/dist/file-picker.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; ... \u0026lt;file-picker id=\u0026#34;file-picker\u0026#34; variation=\u0026#34;resource\u0026#34;\u0026gt;\u0026lt;/file-picker\u0026gt; Integrate in Vue web application There is a caveat when using the File picker inside an existing Vue application. Since the web component will be imported before Vue, we need to define it as a global variable on our own. This requires us to separate the import of Vue into a bootstrap file.\nvue.js:\nimport Vue from \u0026#39;vue\u0026#39; window.Vue = Vue main.js:\nimport Vue from \u0026#39;./vue\u0026#39; new Vue(...) When importing the component, we need to reach it under the .default key.\n\u0026lt;template\u0026gt; \u0026lt;file-picker variation=\u0026#34;location\u0026#34; /\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; export default: { components: { FilePicker: require(\u0026#39;@owncloud/file-picker\u0026#39;).default } } \u0026lt;/script\u0026gt; Set correct variation As described in Getting Started, File picker comes in two variations. To define which one should be used, you need to pass it to the component via its variation property. Valid values are:\n resource - File picker location - Location picker  "});index.add({'id':8,'href':'/integration/file_picker/accessing-resources/','title':"Accessing Resources",'content':"    Access resources     File picker is returning selected resources via event called selectResources. To access them, you need to set an event listener where you\u0026rsquo;ll be able to get them as part of the response of the callback function.\nAccess resources \u0026lt;file-picker id=\u0026#34;file-picker\u0026#34; variation=\u0026#34;resource\u0026#34;\u0026gt;\u0026lt;/file-picker\u0026gt; \u0026lt;script\u0026gt; const item = document.getElementById(\u0026#39;file-picker\u0026#39;) let resources = [] item.addEventListener(\u0026#39;selectResources\u0026#39;, event =\u0026gt; { resources = event.detail[0] }) \u0026lt;/script\u0026gt; "});index.add({'id':9,'href':'/extensions/proxy/about/','title':"About",'content':"This service provides an proxy service that routes requests to the correct services.\n"});index.add({'id':10,'href':'/extensions/accounts/','title':"Accounts",'content':"\nAbstract OCIS needs to be able to identify users. Whithout a non reassignable and persistend account ID share metadata cannot be reliably persisted. ocis-accounts allows exchanging oidc claims for a uuid. Using a uuid allows users to change the login, mail or even openid connect provider without breaking any persisted metadata that might have been attached to it.\n persists accounts uses graph api properties -ldap can be synced using the onpremise* attributes  Table of Contents    Configuration     Getting Started     Building     "});index.add({'id':11,'href':'/clients/web/getting-started/','title':"Getting Started",'content':"    Installation  Docker Binaries Source code   Setting up backend and running Running     Installation Docker TBD\nBinaries TBD\nSource code The source code is hosted at https://github.com/owncloud/phoenix Please refer to the build documentation for Phoenix.\nSetting up backend and running Phoenix can run against either ownCloud 10 as backend or OCIS. Depending which one you chose, please check the matching section:\n Setting up with ownCloud as backend Setting up with OCIS as backend  Running  Running with ownCloud as backend Running with OCIS as backend  "});index.add({'id':12,'href':'/extensions/konnectd/getting-started/','title':"Getting Started",'content':"    Installation  Docker Binaries   Usage  Server Health   Metrics     Installation So far we are offering two different variants for the installation. You can choose between Docker or pre-built binaries which are stored on our download mirrors and GitHub releases. Maybe we will also provide system packages for the major distributions later if we see the need for it.\nDocker Docker images for ocis-reva are hosted on https://hub.docker.com/r/owncloud/ocis-konnectd.\nThe latest tag always reflects the current master branch.\ndocker pull owncloud/ocis-konnectd Binaries The pre-built binaries for different platforms are downloadable at https://download.owncloud.com/ocis/ocis-konnectd/ . Specific releases are organized in separate folders. They are in sync which every release tag on GitHub. The binaries from the current master branch can be found in https://download.owncloud.com/ocis/ocis-konnectd/testing/\ncurl https://download.owncloud.com/ocis/ocis-konnectd/1.0.0-beta1/ocis-konnectd-1.0.0-beta1-darwin-amd64 --output ocis-konnectd chmod +x ocis-konnectd ./ocis-konnectd server Usage The program provides a few sub-commands on execution. The available configuration methods have already been mentioned above. Generally you can always see a formated help output if you execute the binary via ocis-konnectd --help.\nServer The server command is used to start the http and debug server on two addresses within a single process. The http server is serving the general webservice while the debug server is used for health check, readiness check and to server the metrics mentioned below. For further help please execute:\nocis-konnectd server --help Health The health command is used to execute a health check, if the exit code equals zero the service should be up and running, if the exist code is greater than zero the service is not in a healthy state. Generally this command is used within our Docker containers, it could also be used within Kubernetes.\nocis-konnectd health --help Metrics This service provides some Prometheus metrics through the debug endpoint, you can optionally secure the metrics endpoint by some random token, which got to be configured through one of the flag --debug-token or the environment variable KONNECTD_DEBUG_TOKEN mentioned above. By default the metrics endpoint is bound to http://0.0.0.0:9134/metrics.\n go_gc_duration_seconds A summary of the GC invocation durations go_gc_duration_seconds_sum A summary of the GC invocation durations go_gc_duration_seconds_count A summary of the GC invocation durations go_goroutines Number of goroutines that currently exist go_info Information about the Go environment go_memstats_alloc_bytes Number of bytes allocated and still in use go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table go_memstats_frees_total Total number of frees go_memstats_gc_cpu_fraction The fraction of this program\u0026rsquo;s available CPU time used by the GC since the program started go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use go_memstats_heap_idle_bytes Number of heap bytes waiting to be used go_memstats_heap_inuse_bytes Number of heap bytes that are in use go_memstats_heap_objects Number of allocated objects go_memstats_heap_released_bytes Number of heap bytes released to OS go_memstats_heap_sys_bytes Number of heap bytes obtained from system go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection go_memstats_lookups_total Total number of pointer lookups go_memstats_mallocs_total Total number of mallocs go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place go_memstats_other_sys_bytes Number of bytes used for other system allocations go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator go_memstats_sys_bytes Number of bytes obtained from system go_threads Number of OS threads created promhttp_metric_handler_requests_in_flight Current number of scrapes being served promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code  "});index.add({'id':13,'href':'/extensions/ocis_hello/getting-started/','title':"Getting Started",'content':"    Installation  Docker Binaries   Configuration  Envrionment variables  Global Server Health   Commandline flags  Global Server Health   Configuration file   Usage  Server Health   Metrics     Installation So far we are offering two different variants for the installation. You can choose between Docker or pre-built binaries which are stored on our download mirrors and GitHub releases. Maybe we will also provide system packages for the major distributions later if we see the need for it.\nDocker TBD\nBinaries TBD\nConfiguration We provide overall three different variants of configuration. The variant based on environment variables and commandline flags are split up into global values and command-specific values.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nGlobal  HELLO_CONFIG_FILE Path to config file, empty default value HELLO_LOG_LEVEL Set logging level, defaults to info HELLO_LOG_COLOR Enable colored logging, defaults to true HELLO_LOG_PRETTY Enable pretty logging, defaults to true  Server  HELLO_TRACING_ENABLED Enable sending traces, defaults to false HELLO_TRACING_TYPE Tracing backend type, defaults to jaeger HELLO_TRACING_ENDPOINT Endpoint for the agent, empty default value HELLO_TRACING_COLLECTOR Endpoint for the collector, empty default value HELLO_TRACING_SERVICE Service name for tracing, defaults to hello HELLO_DEBUG_ADDR Address to bind debug server, defaults to 0.0.0.0:9109 HELLO_DEBUG_TOKEN Token to grant metrics access, empty default value HELLO_DEBUG_PPROF Enable pprof debugging, defaults to false HELLO_DEBUG_ZPAGES Enable zpages debugging, defaults to false HELLO_HTTP_ADDR Address to bind http server, defaults to 0.0.0.0:9105 HELLO_HTTP_ROOT Root path of http server, defaults to / HELLO_GRPC_ADDR Address to bind grpc server, defaults to 0.0.0.0:9106 HELLO_ASSET_PATH Path to custom assets, empty default value  Health  HELLO_DEBUG_ADDR Address to debug endpoint, defaults to 0.0.0.0:9109  Commandline flags If you prefer to configure the service with commandline flags you can see the available variables below.\nGlobal  \u0026ndash;config-file Path to config file, empty default value \u0026ndash;log-level Set logging level, defaults to info \u0026ndash;log-color Enable colored logging, defaults to true \u0026ndash;log-pretty Enable pretty logging, defaults to true  Server  \u0026ndash;tracing-enabled Enable sending traces, defaults to false \u0026ndash;tracing-type Tracing backend type, defaults to jaeger \u0026ndash;tracing-endpoint Endpoint for the agent, empty default value \u0026ndash;tracing-collector Endpoint for the collector, empty default value \u0026ndash;tracing-service Service name for tracing, defaults to hello \u0026ndash;debug-addr Address to bind debug server, defaults to 0.0.0.0:9109 \u0026ndash;debug-token Token to grant metrics access, empty default value \u0026ndash;debug-pprof Enable pprof debugging, defaults to false \u0026ndash;debug-zpages Enable zpages debugging, defaults to false \u0026ndash;http-addr Address to bind http server, defaults to 0.0.0.0:9105 \u0026ndash;http-root Root path of http server, defaults to / \u0026ndash;grpc-addr Address to bind grpc server, defaults to 0.0.0.0:9106 \u0026ndash;asset-path Path to custom assets, empty default value  Health  \u0026ndash;debug-addr Address to debug endpoint, defaults to 0.0.0.0:9109  Configuration file So far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/hello.yml, ${HOME}/.ocis/hello.yml or $(pwd)/config/hello.yml.\nUsage The program provides a few sub-commands on execution. The available configuration methods have already been mentioned above. Generally you can always see a formated help output if you execute the binary via ocis-hello --help.\nServer The server command is used to start the http and debug server on two addresses within a single process. The http server is serving the general webservice while the debug server is used for health check, readiness check and to server the metrics mentioned below. For further help please execute:\nocis-hello server --help Health The health command is used to execute a health check, if the exit code equals zero the service should be up and running, if the exist code is greater than zero the service is not in a healthy state. Generally this command is used within our Docker containers, it could also be used within Kubernetes.\nocis-hello health --help Metrics This service provides some Prometheus metrics through the debug endpoint, you can optionally secure the metrics endpoint by some random token, which got to be configured through one of the flag --debug-token or the environment variable HELLO_DEBUG_TOKEN mentioned above. By default the metrics endpoint is bound to http://0.0.0.0:9109/metrics.\n go_gc_duration_seconds A summary of the GC invocation durations go_gc_duration_seconds_sum A summary of the GC invocation durations go_gc_duration_seconds_count A summary of the GC invocation durations go_goroutines Number of goroutines that currently exist go_info Information about the Go environment go_memstats_alloc_bytes Number of bytes allocated and still in use go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table go_memstats_frees_total Total number of frees go_memstats_gc_cpu_fraction The fraction of this program\u0026rsquo;s available CPU time used by the GC since the program started go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use go_memstats_heap_idle_bytes Number of heap bytes waiting to be used go_memstats_heap_inuse_bytes Number of heap bytes that are in use go_memstats_heap_objects Number of allocated objects go_memstats_heap_released_bytes Number of heap bytes released to OS go_memstats_heap_sys_bytes Number of heap bytes obtained from system go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection go_memstats_lookups_total Total number of pointer lookups go_memstats_mallocs_total Total number of mallocs go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place go_memstats_other_sys_bytes Number of bytes used for other system allocations go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator go_memstats_sys_bytes Number of bytes obtained from system go_threads Number of OS threads created promhttp_metric_handler_requests_in_flight Current number of scrapes being served promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code  "});index.add({'id':14,'href':'/extensions/ocs/getting-started/','title':"Getting Started",'content':"    Installation  Docker Binaries   Usage  Server Health   Metrics     Installation So far we are offering two different variants for the installation. You can choose between Docker or pre-built binaries which are stored on our download mirrors and GitHub releases. Maybe we will also provide system packages for the major distributions later if we see the need for it.\nDocker Docker images for ocis-ocs are hosted on https://hub.docker.com/r/owncloud/ocis-ocs.\nThe latest tag always reflects the current master branch.\ndocker pull owncloud/ocis-ocs Binaries The pre-built binaries for different platforms are downloadable at https://download.owncloud.com/ocis/ocs/ . Specific releases are organized in separate folders. They are in sync which every release tag on GitHub. The binaries from the current master branch can be found in https://download.owncloud.com/ocis/ocs/testing/\ncurl https://download.owncloud.com/ocis/ocis-ocs/1.0.0-beta1/ocis-ocs-1.0.0-beta1-darwin-amd64 --output ocis-ocs chmod +x ocis-ocs ./ocis-ocs server Usage The program provides a few sub-commands on execution. The available configuration methods have already been mentioned above. Generally you can always see a formated help output if you execute the binary via ocis-ocs --help.\nServer The server command is used to start the http and debug server on two addresses within a single process. The http server is serving the general webservice while the debug server is used for health check, readiness check and to server the metrics mentioned below. For further help please execute:\nocis-ocs server --help Health The health command is used to execute a health check, if the exit code equals zero the service should be up and running, if the exist code is greater than zero the service is not in a healthy state. Generally this command is used within our Docker containers, it could also be used within Kubernetes.\nocis-ocs health --help Metrics This service provides some Prometheus metrics through the debug endpoint, you can optionally secure the metrics endpoint by some random token, which got to be configured through one of the flag --debug-token or the environment variable OCS_DEBUG_TOKEN mentioned above. By default the metrics endpoint is bound to http://0.0.0.0:9114/metrics.\n go_gc_duration_seconds A summary of the GC invocation durations go_gc_duration_seconds_sum A summary of the GC invocation durations go_gc_duration_seconds_count A summary of the GC invocation durations go_goroutines Number of goroutines that currently exist go_info Information about the Go environment go_memstats_alloc_bytes Number of bytes allocated and still in use go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table go_memstats_frees_total Total number of frees go_memstats_gc_cpu_fraction The fraction of this program\u0026rsquo;s available CPU time used by the GC since the program started go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use go_memstats_heap_idle_bytes Number of heap bytes waiting to be used go_memstats_heap_inuse_bytes Number of heap bytes that are in use go_memstats_heap_objects Number of allocated objects go_memstats_heap_released_bytes Number of heap bytes released to OS go_memstats_heap_sys_bytes Number of heap bytes obtained from system go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection go_memstats_lookups_total Total number of pointer lookups go_memstats_mallocs_total Total number of mallocs go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place go_memstats_other_sys_bytes Number of bytes used for other system allocations go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator go_memstats_sys_bytes Number of bytes obtained from system go_threads Number of OS threads created promhttp_metric_handler_requests_in_flight Current number of scrapes being served promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code  "});index.add({'id':15,'href':'/extensions/glauth/','title':"GLAuth",'content':"This service provides a simple glauth world API which can be used by clients or other extensions.\n reiner proxy ldap f√ºr eos und firewall backend ist der accounts service  "});index.add({'id':16,'href':'/extensions/ocis-phoenix/','title':"oCIS Web",'content':"Note: Work in progress to rename Phoenix to oCIS Web.\nThis service embeds Phoenix to provide a UI for ownCloud Infinite Scale.\n"});index.add({'id':17,'href':'/extensions/ocs/','title':"Ocs",'content':"This service provides the OCS API which is required by some ownCloud clients.\n"});index.add({'id':18,'href':'/extensions/storage/','title':"Reva",'content':"This service provides an ocis extension that wraps reva and adds an opinionated configuration to it.\nIt uses the port range 9140-9179 to preconfigure several services.\n| port | service | +\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;\u0026mdash;+ | 9109 | health? | | 9140 | frontend | | 9141 | frontend debug | | 9142 | gateway | | 9143 | gateway debug | | 9144 | users | | 9145 | users debug | | 9146 | authbasic | | 9147 | authbasic debug | | 9148 | authbearer | | 9149 | authbearer debug | | 9150 | sharing | | 9151 | sharing debug | | 9152 | storage root | | 9153 | storage root debug | | 9154 | storage home | | 9155 | storage home debug | | 9156 | storage home data | | 9157 | storage home data debug | | 9158 | storage eos | | 9159 | storage eos debug | | 9160 | storage eos data | | 9161 | storage eos data debug | | 9162 | storage oc | | 9163 | storage oc debug | | 9164 | storage oc data | | 9165 | storage oc data debug | | 9166-9177 | reserved for s3, wnd, custom + data providers | | 9178 | storage public link | | 9179 | storage public link data |\n"});index.add({'id':19,'href':'/extensions/settings/','title':"Settings",'content':"Abstract When using oCIS, the requirement to store settings arises. This extension provides functionality for other extensions to register new settings within oCIS. It is responsible for storing the respective settings values as well.\nFor ease of use, this extension provides an ocis-web extension which allows users to change their settings values. Please refer to the ocis-web extension docs for running ocis-web extensions.\n  mermaid.initialize({ flowchart: { useMaxWidth: true } });  graph TD subgraph ow[ocis-web] ows[ocis-web-settings] owc[ocis-web-core] end ows ---|\"listSettingsBundles(),\nsaveSettingsValue(value)\"| os[ocis-settings] owc ---|\"listSettingsValues()\"| sdk[oC SDK] sdk --- sdks{ocis-settings\navailable?} sdks ---|\"yes\"| os sdks ---|\"no\"| defaults[Use set of\ndefault values] oa[oCIS extensions\ne.g. ocis-accounts] ---|\"saveSettingsBundle(bundle)\"| os The diagram shows how the settings service integrates into oCIS:\nSettings management:\n oCIS extensions can register settings bundles with the ocis-settings service. The settings frontend can be plugged into ocis-web, showing forms for changing settings values as a user. The forms are generated from the registered settings bundles.  Settings usage:\n Extensions can query ocis-settings for settings values of a user. The ownCloud SDK, used as a data abstraction layer for ocis-web, will query ocis-settings for settings values of a user, if it\u0026rsquo;s available. The SDK uses sensible defaults when ocis-settings is not part of the setup.  For compatibility with ownCloud 10, a migration of ownCloud 10 settings into the storage of ocis-settings will be available.\n"});index.add({'id':20,'href':'/extensions/store/','title':"Store",'content':"This service provides \u0026hellip;\n"});index.add({'id':21,'href':'/extensions/thumbnails/','title':"Thumbnails",'content':"This service provides an ocis extensions which generates thumbnails for image files.\n"});index.add({'id':22,'href':'/extensions/webdav/','title':"WebDaV",'content':"This service provides the WebDAV API which is required by some ownCloud clients.\n"});index.add({'id':23,'href':'/ocis/development/getting-started/','title':"Getting Started with Development",'content':"    Docker dev environment  Option 1: Plain docker Option 2: Docker compose   Verification     Docker dev environment Option 1: Plain docker To build and run your local ocis code with default storage driver\ndocker run --rm -ti --name ocis -v $PWD:/ocis -p 9200:9200 owncloud/eos-ocis-dev The eos-ocis-dev container will build and run ocis using the owncloud storage driver and store files in the container at /var/tmp/reva/data/\u0026lt;username\u0026gt;/files\nTo check the uploaded files start digging with: docker exec -it ocis ls -l /var/tmp/reva/\nOn MacOS do not mount a local folder to the /var/tmp/reva/ path. The fuse driver used by docker does not support extended attributes. See #182 for more details.  Option 2: Docker compose With the docker-compose.yml file in ocis repo you can also start ocis via compose:\ndocker-compose up -d ocis We are only starting the ocis container here.  Verification Check the services are running\n$ docker-compose exec ocis ./bin/ocis list +--------------------------+-----+ | EXTENSION | PID | +--------------------------+-----+ | accounts | 172 | | api | 204 | | glauth | 187 | | graph | 41 | | graph-explorer | 55 | | konnectd | 196 | | ocs | 59 | | phoenix | 29 | | proxy | 22 | | registry | 226 | | reva-auth-basic | 96 | | reva-auth-bearer | 104 | | reva-frontend | 485 | | reva-gateway | 78 | | reva-sharing | 286 | | reva-storage-eos | 129 | | reva-storage-eos-data | 134 | | reva-storage-home | 442 | | reva-storage-home-data | 464 | | reva-storage-oc | 149 | | reva-storage-oc-data | 155 | | reva-storage-public-link | 168 | | reva-users | 420 | | settings | 23 | | thumbnails | 201 | | web | 218 | | webdav | 63 | +--------------------------+-----+ "});index.add({'id':24,'href':'/extensions/proxy/getting-started/','title':"Getting Started",'content':"    Installation  Docker Binaries   Usage  Server       Installation So far we are offering two different variants for the installation. You can choose between Docker or pre-built binaries which are stored on our download mirrors and GitHub releases. Maybe we will also provide system packages for the major distributions later if we see the need for it.\nDocker Docker images for ocis-reva are hosted on https://hub.docker.com/r/owncloud/ocis-proxy.\nThe latest tag always reflects the current master branch.\ndocker pull owncloud/ocis-proxy Binaries The pre-built binaries for different platforms are downloadable at https://download.owncloud.com/ocis/ocis-proxy/ . Specific releases are organized in separate folders. They are in sync which every release tag on GitHub. The binaries from the current master branch can be found in https://download.owncloud.com/ocis/ocis-proxy/testing/\ncurl https://download.owncloud.com/ocis/ocis-proxy/1.0.0-beta1/ocis-proxy-1.0.0-beta1-darwin-amd64 --output ocis-proxy chmod +x ocis-proxy ./ocis-proxy server Usage The program provides a few sub-commands on execution. The available configuration methods have already been mentioned above. Generally you can always see a formated help output if you execute the binary via ocis-proxy --help.\nServer The server command is used to start the http server. For further help please execute:\nocis-proxy server --help "});index.add({'id':25,'href':'/ocis/deployment/basic-remote-setup/','title':"Basic Remote Setup",'content':"    Use the binary  Add your hostname to the idp config Start the ocis fullstack server   Use Docker Compose     Out of the box the ocis single binary and the owncloud/ocis docker image are configured to run on localhost for quick testing and development.\nIf you need to access ocis on a VM or a remote machine e.g. when testing a mobile client you need to configure ocis to run on a different host.\nUse the binary If you start the ocis fullstack for the first time with ./bin/ocis server it will generate a file identifier-registration.yml in the config folder relative to its location. This file is used to configure the clients for the built-in Identity Provider.\nOutdated version\nThe identifier-registration.yml file will only be generated if there is no such file in place. You could miss updates on this file. Run make clean to delete the file and keep the development environment tidy otherwise as well.  Add your hostname to the idp config Let us assume your-host is your remote domain name or IP adress. Add your host to the identifier-registration.yml like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # OpenID Connect client registry.clients:- id:phoenixname:ownCloudwebappapplication_type:webinsecure:yestrusted:yesredirect_uris:- http://localhost:9100/- http://localhost:9100/oidc-callback.html- http://localhost:9100/oidc-silent-redirect.html- https://localhost:9200/- https://localhost:9200/oidc-callback.html- https://localhost:9200/oidc-silent-redirect.html- https://your-server:9200/- https://your-server:9200/oidc-callback.html- https://your-server:9200/oidc-silent-redirect.htmlorigins:- http://localhost:9100- https://localhost:9200- https://your-server:9200  In this example we do not change the default port (9200). But this could be changed to another port.\nStart the ocis fullstack server You need to configure your-host in some services to provide the needed public resources. When using the owncloud storage driver (which is the default) oCIS currently needs a running Redis Server reachable locally on the machine at the default port (localhost:6379). You can change this using the following option REVA_STORAGE_OWNCLOUD_REDIS_ADDR=some-host:6379.\nPROXY_HTTP_ADDR=0.0.0.0:9200 \\ KONNECTD_ISS=https://your-server:9200 \\ REVA_OIDC_ISSUER=https://your-server:9200 \\ PHOENIX_OIDC_AUTHORITY=https://your-server:9200 \\ PHOENIX_WEB_CONFIG_SERVER=https://your-server:9200 \\ PHOENIX_OIDC_METADATA_URL=https://your-server:9200/.well-known/openid-configuration \\ REVA_DATAGATEWAY_URL=https://your-server:9200/data \\ REVA_FRONTEND_URL=https://your-server:9200 \\ PROXY_TRANSPORT_TLS_KEY=./certs/your-host.key \\ PROXY_TRANSPORT_TLS_CERT=./certs/your-host.crt \\ KONNECTD_TLS=0 \\ ./bin/ocis server For more configuration options check the configuration secion in ocis and every ocis extension.\nTLS Certificate\nIn this example, we are replacing the default self signed cert with a CA signed one to avoid the certificate warning when accessing the login page.  Use Docker Compose We are using our docker compose playground as a repository to share snippets that make our test setups easier and more aligned.\nYou can start oCIS with docker very easily on a different host using this snippet.\nLet us assume your local IP is 192.168.103.195\ngit clone https://github.com/owncloud-docker/compose-playground.git cd compose-playground/compose/ocis sed -i -e \u0026#39;s/your-url/192.168.103.195/g\u0026#39; config/identifier-registration.yml cat \u0026lt;\u0026lt; EOF \u0026gt; .env OCIS_BASE_URL=192.168.103.195 OCIS_HTTP_PORT=9200 OCIS_DOCKER_TAG=latest EOF docker-compose -f ocis.yml -f ../cache/redis-ocis.yml up -d curl -k https://192.168.103.195:9200/status.php "});index.add({'id':26,'href':'/extensions/webdav/configuration/','title':"Configuration",'content':"    Configuration  Configuration using config files Envrionment variables Commandline flags   Root Command Sub Commands  webdav health webdav version webdav server       Configuration oCIS Single Binary is not responsible for configuring extensions. Instead, each extension could either be configured by environment variables, cli flags or config files.\nEach extension has its dedicated documentation page (e.g. https://owncloud.github.io/extensions/ocis_proxy/configuration) which lists all possible configurations. Config files and environment variables are picked up if you use the ./bin/ocis server command within the oCIS single binary. Command line flags must be set explicitly on the extensions subcommands.\nConfiguration using config files Out of the box extensions will attempt to read configuration details from:\n/etc/ocis $HOME/.ocis ./config For this configuration to be picked up, have a look at your extension root command and look for which default config name it has assigned. i.e: ocis-proxy reads proxy.json | yaml | toml ....\nSo far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/ocis.yml, ${HOME}/.ocis/ocis.yml or $(pwd)/config/ocis.yml.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nCommandline flags If you prefer to configure the service with commandline flags you can see the available variables below. Command line flags are only working when calling the subcommand directly.\nRoot Command Serve WebDAV API for oCIS\nUsage: webdav [global options] command [command options] [arguments...]\n \u0026ndash;config-file | $WEBDAV_CONFIG_FILE Path to config file. \u0026ndash;log-level | $WEBDAV_LOG_LEVEL Set logging level. Default: info. \u0026ndash;log-pretty | $WEBDAV_LOG_PRETTY Enable pretty logging. Default: true. \u0026ndash;log-color | $WEBDAV_LOG_COLOR Enable colored logging. Default: true.  Sub Commands webdav health Check health status\nUsage: webdav health [command options] [arguments...]\n \u0026ndash;debug-addr | $WEBDAV_DEBUG_ADDR Address to debug endpoint. Default: 0.0.0.0:9119.  webdav version Print the versions of the running instances\nUsage: webdav version [command options] [arguments...]\n \u0026ndash;http-namespace | $WEBDAV_HTTP_NAMESPACE Set the base namespace for service discovery. Default: com.owncloud.web. \u0026ndash;service-name | $WEBDAV_SERVICE_NAME Service name. Default: webdav.  webdav server Start integrated server\nUsage: webdav server [command options] [arguments...]\n \u0026ndash;tracing-enabled | $WEBDAV_TRACING_ENABLED Enable sending traces. \u0026ndash;tracing-type | $WEBDAV_TRACING_TYPE Tracing backend type. Default: jaeger. \u0026ndash;tracing-endpoint | $WEBDAV_TRACING_ENDPOINT Endpoint for the agent. \u0026ndash;tracing-collector | $WEBDAV_TRACING_COLLECTOR Endpoint for the collector. \u0026ndash;tracing-service | $WEBDAV_TRACING_SERVICE Service name for tracing. Default: webdav. \u0026ndash;debug-addr | $WEBDAV_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9119. \u0026ndash;debug-token | $WEBDAV_DEBUG_TOKEN Token to grant metrics access. \u0026ndash;debug-pprof | $WEBDAV_DEBUG_PPROF Enable pprof debugging. \u0026ndash;debug-zpages | $WEBDAV_DEBUG_ZPAGES Enable zpages debugging. \u0026ndash;http-addr | $WEBDAV_HTTP_ADDR Address to bind http server. Default: 0.0.0.0:9115. \u0026ndash;http-namespace | $WEBDAV_HTTP_NAMESPACE Set the base namespace for service discovery. Default: com.owncloud.web. \u0026ndash;service-name | $WEBDAV_SERVICE_NAME Service name. Default: webdav. \u0026ndash;http-root | $WEBDAV_HTTP_ROOT Root path of http server. Default: /.  "});index.add({'id':27,'href':'/extensions/proxy/configuration/','title':"Configuration",'content':"    Configuration  Configuration using config files Envrionment variables Commandline flags   Root Command Sub Commands  ocis-proxy health ocis-proxy version ocis-proxy server       Configuration oCIS Single Binary is not responsible for configuring extensions. Instead, each extension could either be configured by environment variables, cli flags or config files.\nEach extension has its dedicated documentation page (e.g. https://owncloud.github.io/extensions/ocis_proxy/configuration) which lists all possible configurations. Config files and environment variables are picked up if you use the ./bin/ocis server command within the oCIS single binary. Command line flags must be set explicitly on the extensions subcommands.\nConfiguration using config files Out of the box extensions will attempt to read configuration details from:\n/etc/ocis $HOME/.ocis ./config For this configuration to be picked up, have a look at your extension root command and look for which default config name it has assigned. i.e: ocis-proxy reads proxy.json | yaml | toml ....\nSo far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/ocis.yml, ${HOME}/.ocis/ocis.yml or $(pwd)/config/ocis.yml.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nCommandline flags If you prefer to configure the service with commandline flags you can see the available variables below. Command line flags are only working when calling the subcommand directly.\nRoot Command proxy for Reva/oCIS\nUsage: ocis-proxy [global options] command [command options] [arguments...]\n \u0026ndash;config-file | $PROXY_CONFIG_FILE Path to config file. \u0026ndash;log-level | $PROXY_LOG_LEVEL Set logging level. Default: info. \u0026ndash;log-pretty | $PROXY_LOG_PRETTY Enable pretty logging. Default: true. \u0026ndash;log-color | $PROXY_LOG_COLOR Enable colored logging. Default: true.  Sub Commands ocis-proxy health Check health status\nUsage: ocis-proxy health [command options] [arguments...]\n \u0026ndash;debug-addr | $PROXY_DEBUG_ADDR Address to debug endpoint. Default: 0.0.0.0:9109.  ocis-proxy version Print the versions of the running instances\nUsage: ocis-proxy version [command options] [arguments...]\n \u0026ndash;service-namespace | $PROXY_SERVICE_NAMESPACE Set the base namespace for the service namespace. Default: com.owncloud.web. \u0026ndash;service-name | $PROXY_SERVICE_NAME Service name. Default: proxy.  ocis-proxy server Start integrated server\nUsage: ocis-proxy server [command options] [arguments...]\n \u0026ndash;tracing-enabled | $PROXY_TRACING_ENABLED Enable sending traces. \u0026ndash;tracing-type | $PROXY_TRACING_TYPE Tracing backend type. Default: jaeger. \u0026ndash;tracing-endpoint | $PROXY_TRACING_ENDPOINT Endpoint for the agent. \u0026ndash;tracing-collector | $PROXY_TRACING_COLLECTOR Endpoint for the collector. Default: http://localhost:14268/api/traces. \u0026ndash;tracing-service | $PROXY_TRACING_SERVICE Service name for tracing. Default: proxy. \u0026ndash;debug-addr | $PROXY_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9205. \u0026ndash;debug-token | $PROXY_DEBUG_TOKEN Token to grant metrics access. \u0026ndash;debug-pprof | $PROXY_DEBUG_PPROF Enable pprof debugging. \u0026ndash;debug-zpages | $PROXY_DEBUG_ZPAGES Enable zpages debugging. \u0026ndash;http-addr | $PROXY_HTTP_ADDR Address to bind http server. Default: 0.0.0.0:9200. \u0026ndash;http-root | $PROXY_HTTP_ROOT Root path of http server. Default: /. \u0026ndash;asset-path | $PROXY_ASSET_PATH Path to custom assets. \u0026ndash;service-namespace | $PROXY_SERVICE_NAMESPACE Set the base namespace for the service namespace. Default: com.owncloud.web. \u0026ndash;service-name | $PROXY_SERVICE_NAME Service name. Default: proxy. \u0026ndash;transport-tls-cert | $PROXY_TRANSPORT_TLS_CERT Certificate file for transport encryption. \u0026ndash;transport-tls-key | $PROXY_TRANSPORT_TLS_KEY Secret file for transport encryption. \u0026ndash;tls | $PROXY_TLS Use TLS (disable only if proxy is behind a TLS-terminating reverse-proxy).. Default: true. \u0026ndash;jwt-secret | $PROXY_JWT_SECRET Used to create JWT to talk to reva, should equal reva\u0026rsquo;s jwt-secret. Default: Pive-Fumkiu4. \u0026ndash;reva-gateway-addr | $PROXY_REVA_GATEWAY_ADDR REVA Gateway Endpoint. Default: 127.0.0.1:9142. \u0026ndash;oidc-issuer | $PROXY_OIDC_ISSUER OIDC issuer. Default: https://localhost:9200. \u0026ndash;oidc-insecure | $PROXY_OIDC_INSECURE OIDC allow insecure communication. Default: true. \u0026ndash;autoprovision-accounts | $PROXY_AUTOPROVISION_ACCOUNTS create accounts from OIDC access tokens to learn new users. Default: false.  "});index.add({'id':28,'href':'/extensions/storage/configuration/','title':"Configuration",'content':"    Configuration  Configuration using config files Envrionment variables Commandline flags   Root Command Sub Commands  storage storage-root storage storage-metadata storage sharing storage storage-eos-data storage gateway storage auth-bearer storage health storage storage-public-link storage storage-eos storage storage-home-data storage storage-home storage storage storage storage-oc-data storage storage-oc storage auth-basic storage users storage frontend       Configuration oCIS Single Binary is not responsible for configuring extensions. Instead, each extension could either be configured by environment variables, cli flags or config files.\nEach extension has its dedicated documentation page (e.g. https://owncloud.github.io/extensions/ocis_proxy/configuration) which lists all possible configurations. Config files and environment variables are picked up if you use the ./bin/ocis server command within the oCIS single binary. Command line flags must be set explicitly on the extensions subcommands.\nConfiguration using config files Out of the box extensions will attempt to read configuration details from:\n/etc/ocis $HOME/.ocis ./config For this configuration to be picked up, have a look at your extension root command and look for which default config name it has assigned. i.e: ocis-proxy reads proxy.json | yaml | toml ....\nSo far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/ocis.yml, ${HOME}/.ocis/ocis.yml or $(pwd)/config/ocis.yml.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nCommandline flags If you prefer to configure the service with commandline flags you can see the available variables below. Command line flags are only working when calling the subcommand directly.\nRoot Command Storage service for oCIS\nUsage: storage [global options] command [command options] [arguments...]\n \u0026ndash;config-file | $STORAGE_CONFIG_FILE Path to config file. \u0026ndash;log-level | $STORAGE_LOG_LEVEL Set logging level. Default: info. \u0026ndash;log-pretty | $STORAGE_LOG_PRETTY Enable pretty logging. \u0026ndash;log-color | $STORAGE_LOG_COLOR Enable colored logging.  Sub Commands storage storage-root Start storage-root service\nUsage: storage storage-root [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_STORAGE_ROOT_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9153. \u0026ndash;network | $STORAGE_STORAGE_ROOT_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_STORAGE_ROOT_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: grpc. \u0026ndash;addr | $STORAGE_STORAGE_ROOT_ADDR Address to bind storage service. Default: 0.0.0.0:9152. \u0026ndash;url | $STORAGE_STORAGE_ROOT_URL URL to use for the storage service. Default: localhost:9152. \u0026ndash;driver | $STORAGE_STORAGE_ROOT_DRIVER storage driver for root mount: eg. local, eos, owncloud, ocis or s3. Default: local. \u0026ndash;mount-path | $STORAGE_STORAGE_ROOT_MOUNT_PATH mount path. Default: /. \u0026ndash;mount-id | $STORAGE_STORAGE_ROOT_MOUNT_ID mount id. Default: 123e4567-e89b-12d3-a456-426655440001. \u0026ndash;expose-data-server | $STORAGE_STORAGE_ROOT_EXPOSE_DATA_SERVER exposes a dedicated data server. \u0026ndash;data-server-url | $STORAGE_STORAGE_ROOT_DATA_SERVER_URL data server url.  storage storage-metadata Start storage-metadata service\nUsage: storage storage-metadata [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_STORAGE_METADATA_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9217. \u0026ndash;network | $STORAGE_STORAGE_METADATA_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;provider-addr | $STORAGE_STORAGE_METADATA_PROVIDER_ADDR Address to bind storage service. Default: 0.0.0.0:9215. \u0026ndash;data-server-url | $STORAGE_STORAGE_METADATA_DATA_SERVER_URL URL of the data-server the storage-provider uses. Default: http://localhost:9216. \u0026ndash;data-server-addr | $STORAGE_STORAGE_METADATA_DATA_SERVER_ADDR Address to bind the metadata data-server to. Default: 0.0.0.0:9216. \u0026ndash;storage-provider-driver | $STORAGE_STORAGE_METADATA_PROVIDER_DRIVER storage driver for metadata mount: eg. local, eos, owncloud, ocis or s3. Default: local. \u0026ndash;data-provider-driver | $STORAGE_STORAGE_METADATA_DATA_PROVIDER_DRIVER storage driver for data-provider mount: eg. local, eos, owncloud, ocis or s3. Default: local. \u0026ndash;storage-root | $STORAGE_STORAGE_METADATA_ROOT the path to the metadata storage root. Default: /var/tmp/ocis/metadata.  storage sharing Start sharing service\nUsage: storage sharing [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_SHARING_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9151. \u0026ndash;network | $STORAGE_SHARING_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_SHARING_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: grpc. \u0026ndash;addr | $STORAGE_SHARING_ADDR Address to bind storage service. Default: 0.0.0.0:9150. \u0026ndash;url | $STORAGE_SHARING_URL URL to use for the storage service. Default: localhost:9150. \u0026ndash;user-driver | $STORAGE_SHARING_USER_DRIVER driver to use for the UserShareProvider. Default: json. \u0026ndash;user-json-file | $STORAGE_SHARING_USER_JSON_FILE file used to persist shares for the UserShareProvider. Default: /var/tmp/ocis/shares.json. \u0026ndash;public-driver | $STORAGE_SHARING_PUBLIC_DRIVER driver to use for the PublicShareProvider. Default: json.  storage storage-eos-data Start storage-eos-data service\nUsage: storage storage-eos-data [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_STORAGE_OC_DATA_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9161. \u0026ndash;network | $STORAGE_STORAGE_EOS_DATA_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_STORAGE_EOS_DATA_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: http. \u0026ndash;addr | $STORAGE_STORAGE_EOS_DATA_ADDR Address to bind storage service. Default: 0.0.0.0:9160. \u0026ndash;url | $STORAGE_STORAGE_EOS_DATA_URL URL to use for the storage service. Default: localhost:9160. \u0026ndash;driver | $STORAGE_STORAGE_EOS_DATA_DRIVER storage driver for eos data mount: eg. local, eos, owncloud, ocis or s3. Default: eos. \u0026ndash;prefix | $STORAGE_STORAGE_EOS_DATA_PREFIX prefix for the http endpoint, without leading slash. Default: data. \u0026ndash;temp-folder | $STORAGE_STORAGE_EOS_DATA_TEMP_FOLDER temp folder. Default: /var/tmp/. \u0026ndash;gateway-url | $STORAGE_GATEWAY_URL URL to use for the storage gateway service. Default: localhost:9142. \u0026ndash;users-url | $STORAGE_USERS_URL URL to use for the storage service. Default: localhost:9144.  storage gateway Start gateway\nUsage: storage gateway [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_GATEWAY_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9143. \u0026ndash;transfer-secret | $STORAGE_TRANSFER_SECRET Transfer secret for datagateway. Default: replace-me-with-a-transfer-secret. \u0026ndash;network | $STORAGE_GATEWAY_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_GATEWAY_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: grpc. \u0026ndash;addr | $STORAGE_GATEWAY_ADDR Address to bind storage service. Default: 0.0.0.0:9142. \u0026ndash;url | $STORAGE_GATEWAY_URL URL to use for the storage service. Default: localhost:9142. \u0026ndash;commit-share-to-storage-grant | $STORAGE_GATEWAY_COMMIT_SHARE_TO_STORAGE_GRANT Commit shares to the share manager. Default: true. \u0026ndash;commit-share-to-storage-ref | $STORAGE_GATEWAY_COMMIT_SHARE_TO_STORAGE_REF Commit shares to the storage. Default: true. \u0026ndash;share-folder | $STORAGE_GATEWAY_SHARE_FOLDER mount shares in this folder of the home storage provider. Default: Shares. \u0026ndash;disable-home-creation-on-login | $STORAGE_GATEWAY_DISABLE_HOME_CREATION_ON_LOGIN Disable creation of home folder on login. \u0026ndash;storage-registry-driver | $STORAGE_STORAGE_REGISTRY_DRIVER driver of the storage registry. Default: static. \u0026ndash;storage-home-provider | $STORAGE_STORAGE_HOME_PROVIDER mount point of the storage provider for user homes in the global namespace. Default: /home. \u0026ndash;frontend-url | $STORAGE_FRONTEND_URL URL to use for the storage service. Default: https://localhost:9200. \u0026ndash;datagateway-url | $STORAGE_DATAGATEWAY_URL URL to use for the storage datagateway. Default: https://localhost:9200/data. \u0026ndash;users-url | $STORAGE_USERS_URL URL to use for the storage service. Default: localhost:9144. \u0026ndash;auth-basic-url | $STORAGE_AUTH_BASIC_URL URL to use for the storage service. Default: localhost:9146. \u0026ndash;auth-bearer-url | $STORAGE_AUTH_BEARER_URL URL to use for the storage service. Default: localhost:9148. \u0026ndash;sharing-url | $STORAGE_SHARING_URL URL to use for the storage service. Default: localhost:9150. \u0026ndash;storage-root-url | $STORAGE_STORAGE_ROOT_URL URL to use for the storage service. Default: localhost:9152. \u0026ndash;storage-root-mount-path | $STORAGE_STORAGE_ROOT_MOUNT_PATH mount path. Default: /. \u0026ndash;storage-root-mount-id | $STORAGE_STORAGE_ROOT_MOUNT_ID mount id. Default: 1284d238-aa92-42ce-bdc4-0b0000009152. \u0026ndash;storage-home-url | $STORAGE_STORAGE_HOME_URL URL to use for the storage service. Default: localhost:9154. \u0026ndash;storage-home-mount-path | $STORAGE_STORAGE_HOME_MOUNT_PATH mount path. Default: /home. \u0026ndash;storage-home-mount-id | $STORAGE_STORAGE_HOME_MOUNT_ID mount id. Default: 1284d238-aa92-42ce-bdc4-0b0000009154. \u0026ndash;storage-eos-url | $STORAGE_STORAGE_EOS_URL URL to use for the storage service. Default: localhost:9158. \u0026ndash;storage-eos-mount-path | $STORAGE_STORAGE_EOS_MOUNT_PATH mount path. Default: /eos. \u0026ndash;storage-eos-mount-id | $STORAGE_STORAGE_EOS_MOUNT_ID mount id. Default: 1284d238-aa92-42ce-bdc4-0b0000009158. \u0026ndash;storage-oc-url | $STORAGE_STORAGE_OC_URL URL to use for the storage service. Default: localhost:9162. \u0026ndash;storage-oc-mount-path | $STORAGE_STORAGE_OC_MOUNT_PATH mount path. Default: /oc. \u0026ndash;storage-oc-mount-id | $STORAGE_STORAGE_OC_MOUNT_ID mount id. Default: 1284d238-aa92-42ce-bdc4-0b0000009162. \u0026ndash;public-link-url | $STORAGE_STORAGE_PUBLIC_LINK_URL URL to use for the public links service. Default: localhost:9178. \u0026ndash;storage-public-link-mount-path | $STORAGE_STORAGE_PUBLIC_LINK_MOUNT_PATH mount path. Default: /public/.  storage auth-bearer Start authprovider for bearer auth\nUsage: storage auth-bearer [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_AUTH_BEARER_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9149. \u0026ndash;oidc-issuer | $STORAGE_OIDC_ISSUER OIDC issuer. Default: https://localhost:9200. \u0026ndash;oidc-insecure | $STORAGE_OIDC_INSECURE OIDC allow insecure communication. Default: true. \u0026ndash;oidc-id-claim | $STORAGE_OIDC_ID_CLAIM OIDC id claim. Default: preferred_username. \u0026ndash;oidc-uid-claim | $STORAGE_OIDC_UID_CLAIM OIDC uid claim. \u0026ndash;oidc-gid-claim | $STORAGE_OIDC_GID_CLAIM OIDC gid claim. \u0026ndash;network | $STORAGE_AUTH_BEARER_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_AUTH_BEARER_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: grpc. \u0026ndash;addr | $STORAGE_AUTH_BEARER_ADDR Address to bind storage service. Default: 0.0.0.0:9148. \u0026ndash;url | $STORAGE_AUTH_BEARER_URL URL to use for the storage service. Default: localhost:9148.  storage health Check health status\nUsage: storage health [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_DEBUG_ADDR Address to debug endpoint. Default: 0.0.0.0:9109.  storage storage-public-link Start storage-public-link service\nUsage: storage storage-public-link [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_STORAGE_PUBLIC_LINK_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9179. \u0026ndash;network | $STORAGE_STORAGE_PUBLIC_LINK_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_STORAGE_PUBLIC_LINK_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: grpc. \u0026ndash;addr | $STORAGE_STORAGE_PUBLIC_LINK_ADDR Address to bind storage service. Default: 0.0.0.0:9178. \u0026ndash;url | $STORAGE_STORAGE_PUBLIC_LINK_URL Address to bind storage service. Default: localhost:9178. \u0026ndash;mount-path | $STORAGE_STORAGE_PUBLIC_LINK_MOUNT_PATH mount path. Default: /public/. \u0026ndash;gateway-url | $STORAGE_GATEWAY_URL URL to use for the storage gateway service. Default: localhost:9142.  storage storage-eos Start storage-eos service\nUsage: storage storage-eos [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_STORAGE_EOS_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9159. \u0026ndash;network | $STORAGE_STORAGE_EOS_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_STORAGE_EOS_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: grpc. \u0026ndash;addr | $STORAGE_STORAGE_EOS_ADDR Address to bind storage service. Default: 0.0.0.0:9158. \u0026ndash;url | $STORAGE_STORAGE_EOS_URL URL to use for the storage service. Default: localhost:9158. \u0026ndash;driver | $STORAGE_STORAGE_EOS_DRIVER storage driver for eos mount: eg. local, eos, owncloud, ocis or s3. Default: eos. \u0026ndash;mount-path | $STORAGE_STORAGE_EOS_MOUNT_PATH mount path. Default: /eos. \u0026ndash;mount-id | $STORAGE_STORAGE_EOS_MOUNT_ID mount id. Default: 1284d238-aa92-42ce-bdc4-0b0000009158. \u0026ndash;expose-data-server | $STORAGE_STORAGE_EOS_EXPOSE_DATA_SERVER exposes a dedicated data server. Default: false. \u0026ndash;data-server-url | $STORAGE_STORAGE_EOS_DATA_SERVER_URL data server url. Default: http://localhost:9160/data.  storage storage-home-data Start storage-home-data service\nUsage: storage storage-home-data [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_STORAGE_HOME_DATA_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9157. \u0026ndash;network | $STORAGE_STORAGE_HOME_DATA_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_STORAGE_HOME_DATA_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: http. \u0026ndash;addr | $STORAGE_STORAGE_HOME_DATA_ADDR Address to bind storage service. Default: 0.0.0.0:9156. \u0026ndash;url | $STORAGE_STORAGE_HOME_DATA_URL URL to use for the storage service. Default: localhost:9156. \u0026ndash;driver | $STORAGE_STORAGE_HOME_DATA_DRIVER storage driver for home data mount: eg. local, eos, owncloud, ocis or s3. Default: owncloud. \u0026ndash;prefix | $STORAGE_STORAGE_HOME_DATA_PREFIX prefix for the http endpoint, without leading slash. Default: data. \u0026ndash;temp-folder | $STORAGE_STORAGE_HOME_DATA_TEMP_FOLDER temp folder. Default: /var/tmp/. \u0026ndash;enable-home | $STORAGE_STORAGE_HOME_ENABLE_HOME enable the creation of home directories. Default: true. \u0026ndash;gateway-url | $STORAGE_GATEWAY_URL URL to use for the storage gateway service. Default: localhost:9142. \u0026ndash;users-url | $STORAGE_USERS_URL URL to use for the storage service. Default: localhost:9144.  storage storage-home Start storage-home service\nUsage: storage storage-home [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_STORAGE_HOME_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9155. \u0026ndash;network | $STORAGE_STORAGE_HOME_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_STORAGE_HOME_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: grpc. \u0026ndash;addr | $STORAGE_STORAGE_HOME_ADDR Address to bind storage service. Default: 0.0.0.0:9154. \u0026ndash;url | $STORAGE_STORAGE_HOME_URL URL to use for the storage service. Default: localhost:9154. \u0026ndash;driver | $STORAGE_STORAGE_HOME_DRIVER storage driver for home mount: eg. local, eos, owncloud, ocis or s3. Default: owncloud. \u0026ndash;mount-path | $STORAGE_STORAGE_HOME_MOUNT_PATH mount path. Default: /home. \u0026ndash;mount-id | $STORAGE_STORAGE_HOME_MOUNT_ID mount id. Default: 1284d238-aa92-42ce-bdc4-0b0000009162. \u0026ndash;expose-data-server | $STORAGE_STORAGE_HOME_EXPOSE_DATA_SERVER exposes a dedicated data server. Default: false. \u0026ndash;data-server-url | $STORAGE_STORAGE_HOME_DATA_SERVER_URL data server url. Default: http://localhost:9156/data. \u0026ndash;enable-home | $STORAGE_STORAGE_HOME_ENABLE_HOME enable the creation of home directories. Default: true. \u0026ndash;users-url | $STORAGE_USERS_URL URL to use for the storage service. Default: localhost:9144.  storage storage Storage service for oCIS\nUsage: storage storage [command options] [arguments...]\n \u0026ndash;config-file | $STORAGE_CONFIG_FILE Path to config file. \u0026ndash;log-level | $STORAGE_LOG_LEVEL Set logging level. Default: info. \u0026ndash;log-pretty | $STORAGE_LOG_PRETTY Enable pretty logging. \u0026ndash;log-color | $STORAGE_LOG_COLOR Enable colored logging.  storage storage-oc-data Start storage-oc-data service\nUsage: storage storage-oc-data [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_STORAGE_OC_DATA_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9165. \u0026ndash;network | $STORAGE_STORAGE_OC_DATA_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_STORAGE_OC_DATA_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: http. \u0026ndash;addr | $STORAGE_STORAGE_OC_DATA_ADDR Address to bind storage service. Default: 0.0.0.0:9164. \u0026ndash;url | $STORAGE_STORAGE_OC_DATA_URL URL to use for the storage service. Default: localhost:9164. \u0026ndash;driver | $STORAGE_STORAGE_OC_DATA_DRIVER storage driver for oc data mount: eg. local, eos, owncloud, ocis or s3. Default: owncloud. \u0026ndash;prefix | $STORAGE_STORAGE_OC_DATA_PREFIX prefix for the http endpoint, without leading slash. Default: data. \u0026ndash;temp-folder | $STORAGE_STORAGE_OC_DATA_TEMP_FOLDER temp folder. Default: /var/tmp/. \u0026ndash;gateway-url | $STORAGE_GATEWAY_URL URL to use for the storage gateway service. Default: localhost:9142. \u0026ndash;users-url | $STORAGE_USERS_URL URL to use for the storage service. Default: localhost:9144.  storage storage-oc Start storage-oc service\nUsage: storage storage-oc [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_STORAGE_OC_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9163. \u0026ndash;network | $STORAGE_STORAGE_OC_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_STORAGE_OC_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: grpc. \u0026ndash;addr | $STORAGE_STORAGE_OC_ADDR Address to bind storage service. Default: 0.0.0.0:9162. \u0026ndash;url | $STORAGE_STORAGE_OC_URL URL to use for the storage service. Default: localhost:9162. \u0026ndash;driver | $STORAGE_STORAGE_OC_DRIVER storage driver for oc mount: eg. local, eos, owncloud, ocis or s3. Default: owncloud. \u0026ndash;mount-path | $STORAGE_STORAGE_OC_MOUNT_PATH mount path. Default: /oc. \u0026ndash;mount-id | $STORAGE_STORAGE_OC_MOUNT_ID mount id. Default: 1284d238-aa92-42ce-bdc4-0b0000009162. \u0026ndash;expose-data-server | $STORAGE_STORAGE_OC_EXPOSE_DATA_SERVER exposes a dedicated data server. Default: false. \u0026ndash;data-server-url | $STORAGE_STORAGE_OC_DATA_SERVER_URL data server url. Default: http://localhost:9164/data. \u0026ndash;users-url | $STORAGE_USERS_URL URL to use for the storage service. Default: localhost:9144.  storage auth-basic Start authprovider for basic auth\nUsage: storage auth-basic [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_AUTH_BASIC_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9147. \u0026ndash;auth-driver | $STORAGE_AUTH_DRIVER auth driver: \u0026lsquo;demo\u0026rsquo;, \u0026lsquo;json\u0026rsquo; or \u0026lsquo;ldap\u0026rsquo;. Default: ldap. \u0026ndash;auth-json | $STORAGE_AUTH_JSON Path to users.json file. \u0026ndash;network | $STORAGE_AUTH_BASIC_NETWORK Network to use for the storage auth-basic service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_AUTH_BASIC_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: grpc. \u0026ndash;addr | $STORAGE_AUTH_BASIC_ADDR Address to bind storage service. Default: 0.0.0.0:9146. \u0026ndash;url | $STORAGE_AUTH_BASIC_URL URL to use for the storage service. Default: localhost:9146.  storage users Start users service\nUsage: storage users [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_SHARING_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9145. \u0026ndash;network | $STORAGE_USERS_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_USERS_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: grpc. \u0026ndash;addr | $STORAGE_USERS_ADDR Address to bind storage service. Default: 0.0.0.0:9144. \u0026ndash;url | $STORAGE_USERS_URL URL to use for the storage service. Default: localhost:9144. \u0026ndash;driver | $STORAGE_USERS_DRIVER user driver: \u0026lsquo;demo\u0026rsquo;, \u0026lsquo;json\u0026rsquo;, \u0026lsquo;ldap\u0026rsquo;, or \u0026lsquo;rest\u0026rsquo;. Default: ldap. \u0026ndash;json-config | $STORAGE_USERS_JSON Path to users.json file. \u0026ndash;rest-client-id | $STORAGE_REST_CLIENT_ID User rest driver Client ID. \u0026ndash;rest-client-secret | $STORAGE_REST_CLIENT_SECRET User rest driver Client Secret. \u0026ndash;rest-redis-address | $STORAGE_REST_REDIS_ADDRESS Address for redis server. Default: localhost:6379. \u0026ndash;rest-redis-username | $STORAGE_REST_REDIS_USERNAME Username for redis server. \u0026ndash;rest-redis-password | $STORAGE_REST_REDIS_PASSWORD Password for redis server. \u0026ndash;rest-id-provider | $STORAGE_REST_ID_PROVIDER The OIDC Provider. \u0026ndash;rest-api-base-url | $STORAGE_REST_API_BASE_URL Base API Endpoint. \u0026ndash;rest-oidc-token-endpoint | $STORAGE_REST_OIDC_TOKEN_ENDPOINT Endpoint to generate token to access the API. \u0026ndash;rest-target-api | $STORAGE_REST_TARGET_API The target application.  storage frontend Start frontend service\nUsage: storage frontend [command options] [arguments...]\n \u0026ndash;debug-addr | $STORAGE_FRONTEND_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9141. \u0026ndash;transfer-secret | $STORAGE_TRANSFER_SECRET Transfer secret for datagateway. Default: replace-me-with-a-transfer-secret. \u0026ndash;webdav-namespace | $WEBDAV_NAMESPACE Namespace prefix for the /webdav endpoint. Default: /home/. \u0026ndash;dav-files-namespace | $DAV_FILES_NAMESPACE Namespace prefix for the webdav /dav/files endpoint. Default: /oc/. \u0026ndash;network | $STORAGE_FRONTEND_NETWORK Network to use for the storage service, can be \u0026lsquo;tcp\u0026rsquo;, \u0026lsquo;udp\u0026rsquo; or \u0026lsquo;unix\u0026rsquo;. Default: tcp. \u0026ndash;protocol | $STORAGE_FRONTEND_PROTOCOL protocol for storage service, can be \u0026lsquo;http\u0026rsquo; or \u0026lsquo;grpc\u0026rsquo;. Default: http. \u0026ndash;addr | $STORAGE_FRONTEND_ADDR Address to bind storage service. Default: 0.0.0.0:9140. \u0026ndash;url | $STORAGE_FRONTEND_URL URL to use for the storage service. Default: https://localhost:9200. \u0026ndash;datagateway-prefix | $STORAGE_FRONTEND_DATAGATEWAY_PREFIX datagateway prefix. Default: data. \u0026ndash;ocdav-prefix | $STORAGE_FRONTEND_OCDAV_PREFIX owncloud webdav endpoint prefix. \u0026ndash;ocs-prefix | $STORAGE_FRONTEND_OCS_PREFIX open collaboration services endpoint prefix. Default: ocs. \u0026ndash;gateway-url | $STORAGE_GATEWAY_URL URL to use for the storage gateway service. Default: localhost:9142. \u0026ndash;upload-disable-tus | $STORAGE_FRONTEND_UPLOAD_DISABLE_TUS Disables TUS upload mechanism. Default: false. \u0026ndash;upload-http-method-override | $STORAGE_FRONTEND_UPLOAD_HTTP_METHOD_OVERRIDE Specify an HTTP method (ex: POST) that clients should to use when uploading instead of PATCH.  "});index.add({'id':29,'href':'/extensions/konnectd/configuration/','title':"Configuration",'content':"    Configuration  Configuration using config files Envrionment variables Commandline flags   Root Command Sub Commands  ocis-konnectd health ocis-konnectd version ocis-konnectd server       Configuration oCIS Single Binary is not responsible for configuring extensions. Instead, each extension could either be configured by environment variables, cli flags or config files.\nEach extension has its dedicated documentation page (e.g. https://owncloud.github.io/extensions/ocis_proxy/configuration) which lists all possible configurations. Config files and environment variables are picked up if you use the ./bin/ocis server command within the oCIS single binary. Command line flags must be set explicitly on the extensions subcommands.\nConfiguration using config files Out of the box extensions will attempt to read configuration details from:\n/etc/ocis $HOME/.ocis ./config For this configuration to be picked up, have a look at your extension root command and look for which default config name it has assigned. i.e: ocis-proxy reads proxy.json | yaml | toml ....\nSo far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/ocis.yml, ${HOME}/.ocis/ocis.yml or $(pwd)/config/ocis.yml.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nCommandline flags If you prefer to configure the service with commandline flags you can see the available variables below. Command line flags are only working when calling the subcommand directly.\nRoot Command Serve Konnectd API for oCIS\nUsage: ocis-konnectd [global options] command [command options] [arguments...]\n \u0026ndash;config-file | $KONNECTD_CONFIG_FILE Path to config file. \u0026ndash;log-level | $KONNECTD_LOG_LEVEL Set logging level. Default: info. \u0026ndash;log-pretty | $KONNECTD_LOG_PRETTY Enable pretty logging. Default: true. \u0026ndash;log-color | $KONNECTD_LOG_COLOR Enable colored logging. Default: true.  Sub Commands ocis-konnectd health Check health status\nUsage: ocis-konnectd health [command options] [arguments...]\n \u0026ndash;debug-addr | $KONNECTD_DEBUG_ADDR Address to debug endpoint. Default: 0.0.0.0:9134.  ocis-konnectd version Print the versions of the running instances\nUsage: ocis-konnectd version [command options] [arguments...]\n \u0026ndash;http-namespace | $KONNECTD_HTTP_NAMESPACE Set the base namespace for service discovery. Default: com.owncloud.web. \u0026ndash;name | $KONNECTD_NAME Service name. Default: konnectd.  ocis-konnectd server Start integrated server\nUsage: ocis-konnectd server [command options] [arguments...]\n \u0026ndash;tracing-enabled | $KONNECTD_TRACING_ENABLED Enable sending traces. \u0026ndash;tracing-type | $KONNECTD_TRACING_TYPE Tracing backend type. Default: jaeger. \u0026ndash;tracing-endpoint | $KONNECTD_TRACING_ENDPOINT Endpoint for the agent. \u0026ndash;tracing-collector | $KONNECTD_TRACING_COLLECTOR Endpoint for the collector. \u0026ndash;tracing-service | $KONNECTD_TRACING_SERVICE Service name for tracing. Default: konnectd. \u0026ndash;debug-addr | $KONNECTD_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9134. \u0026ndash;debug-token | $KONNECTD_DEBUG_TOKEN Token to grant metrics access. \u0026ndash;debug-pprof | $KONNECTD_DEBUG_PPROF Enable pprof debugging. \u0026ndash;debug-zpages | $KONNECTD_DEBUG_ZPAGES Enable zpages debugging. \u0026ndash;http-addr | $KONNECTD_HTTP_ADDR Address to bind http server. Default: 0.0.0.0:9130. \u0026ndash;http-root | $KONNECTD_HTTP_ROOT Root path of http server. Default: /. \u0026ndash;http-namespace | $KONNECTD_HTTP_NAMESPACE Set the base namespace for service discovery. Default: com.owncloud.web. \u0026ndash;name | $KONNECTD_NAME Service name. Default: konnectd. \u0026ndash;identity-manager | $KONNECTD_IDENTITY_MANAGER Identity manager (one of ldap,kc,cookie,dummy). Default: ldap. \u0026ndash;transport-tls-cert | $KONNECTD_TRANSPORT_TLS_CERT Certificate file for transport encryption. \u0026ndash;transport-tls-key | $KONNECTD_TRANSPORT_TLS_KEY Secret file for transport encryption. \u0026ndash;iss | $KONNECTD_ISS OIDC issuer URL. Default: https://localhost:9200. \u0026ndash;signing-kid | $KONNECTD_SIGNING_KID Value of kid field to use in created tokens (uniquely identifying the signing-private-key). \u0026ndash;validation-keys-path | $KONNECTD_VALIDATION_KEYS_PATH Full path to a folder containg PEM encoded private or public key files used for token validaton (file name without extension is used as kid). \u0026ndash;encryption-secret | $KONNECTD_ENCRYPTION_SECRET Full path to a file containing a %d bytes secret key. \u0026ndash;signing-method | $KONNECTD_SIGNING_METHOD JWT default signing method. Default: PS256. \u0026ndash;uri-base-path | $KONNECTD_URI_BASE_PATH Custom base path for URI endpoints. \u0026ndash;sign-in-uri | $KONNECTD_SIGN_IN_URI Custom redirection URI to sign-in form. \u0026ndash;signed-out-uri | $KONNECTD_SIGN_OUT_URI Custom redirection URI to signed-out goodbye page. \u0026ndash;authorization-endpoint-uri | $KONNECTD_ENDPOINT_URI Custom authorization endpoint URI. \u0026ndash;endsession-endpoint-uri | $KONNECTD_ENDSESSION_ENDPOINT_URI Custom endsession endpoint URI. \u0026ndash;asset-path | $KONNECTD_ASSET_PATH Path to custom assets. \u0026ndash;identifier-client-path | $KONNECTD_IDENTIFIER_CLIENT_PATH Path to the identifier web client base folder. Default: /var/tmp/konnectd. \u0026ndash;identifier-registration-conf | $KONNECTD_IDENTIFIER_REGISTRATION_CONF Path to a identifier-registration.yaml configuration file. Default: ./config/identifier-registration.yaml. \u0026ndash;identifier-scopes-conf | $KONNECTD_IDENTIFIER_SCOPES_CONF Path to a scopes.yaml configuration file. \u0026ndash;insecure | $KONNECTD_INSECURE Disable TLS certificate and hostname validation. \u0026ndash;tls | $KONNECTD_TLS Use TLS (disable only if konnectd is behind a TLS-terminating reverse-proxy).. Default: false. \u0026ndash;allow-client-guests | $KONNECTD_ALLOW_CLIENT_GUESTS Allow sign in of client controlled guest users. \u0026ndash;allow-dynamic-client-registration | $KONNECTD_ALLOW_DYNAMIC_CLIENT_REGISTRATION Allow dynamic OAuth2 client registration. \u0026ndash;disable-identifier-webapp | $KONNECTD_DISABLE_IDENTIFIER_WEBAPP Disable built-in identifier-webapp to use a frontend hosted elsewhere.. Default: true.  "});index.add({'id':30,'href':'/ocis/configuration/','title':"Configuration",'content':"    Configuration  Configuration using config files Envrionment variables Commandline flags   Root Command Sub Commands  ocis kill ocis server ocis run ocis health ocis list List of available Extension subcommands  ocis konnectd ocis storage-frontend ocis accounts ocis storage-storage-root ocis storage-gateway ocis storage-storage-home ocis storage-storage-public-link ocis store ocis glauth ocis storage-auth-bearer ocis storage-sharing ocis webdav ocis storage-storage-oc-data ocis thumbnails ocis proxy ocis settings ocis storage-auth-basic ocis storage-storage-metadata ocis ocs ocis storage-storage-eos ocis storage-storage-eos-data ocis storage-storage-home-data ocis storage-storage-oc ocis storage-users ocis phoenix         Configuration oCIS Single Binary is not responsible for configuring extensions. Instead, each extension could either be configured by environment variables, cli flags or config files.\nEach extension has its dedicated documentation page (e.g. https://owncloud.github.io/extensions/ocis_proxy/configuration) which lists all possible configurations. Config files and environment variables are picked up if you use the ./bin/ocis server command within the oCIS single binary. Command line flags must be set explicitly on the extensions subcommands.\nConfiguration using config files Out of the box extensions will attempt to read configuration details from:\n/etc/ocis $HOME/.ocis ./config For this configuration to be picked up, have a look at your extension root command and look for which default config name it has assigned. i.e: ocis-proxy reads proxy.json | yaml | toml ....\nSo far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/ocis.yml, ${HOME}/.ocis/ocis.yml or $(pwd)/config/ocis.yml.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nCommandline flags If you prefer to configure the service with commandline flags you can see the available variables below. Command line flags are only working when calling the subcommand directly.\nRoot Command ownCloud Infinite Scale Stack\nUsage: ocis [global options] command [command options] [arguments...]\n \u0026ndash;config-file | $OCIS_CONFIG_FILE Path to config file. \u0026ndash;log-level | $OCIS_LOG_LEVEL Set logging level. Default: info. \u0026ndash;log-pretty | $OCIS_LOG_PRETTY Enable pretty logging. Default: true. \u0026ndash;log-color | $OCIS_LOG_COLOR Enable colored logging. Default: true.  Sub Commands ocis kill Kill an extension by name\nUsage: ocis kill [command options] [arguments...]\nocis server Start fullstack server\nUsage: ocis server [command options] [arguments...]\n \u0026ndash;tracing-enabled | $OCIS_TRACING_ENABLED Enable sending traces. \u0026ndash;tracing-type | $OCIS_TRACING_TYPE Tracing backend type. Default: jaeger. \u0026ndash;tracing-endpoint | $OCIS_TRACING_ENDPOINT Endpoint for the agent. Default: localhost:6831. \u0026ndash;tracing-collector | $OCIS_TRACING_COLLECTOR Endpoint for the collector. Default: http://localhost:14268/api/traces. \u0026ndash;tracing-service | $OCIS_TRACING_SERVICE Service name for tracing. Default: ocis. \u0026ndash;debug-addr | $OCIS_DEBUG_ADDR Address to bind debug server. Default: 0.0.0.0:9010. \u0026ndash;debug-token | $OCIS_DEBUG_TOKEN Token to grant metrics access. \u0026ndash;debug-pprof | $OCIS_DEBUG_PPROF Enable pprof debugging. \u0026ndash;debug-zpages | $OCIS_DEBUG_ZPAGES Enable zpages debugging. \u0026ndash;http-addr | $OCIS_HTTP_ADDR Address to bind http server. Default: 0.0.0.0:9000. \u0026ndash;http-root | $OCIS_HTTP_ROOT Root path of http server. Default: /. \u0026ndash;grpc-addr | $OCIS_GRPC_ADDR Address to bind grpc server. Default: 0.0.0.0:9001.  ocis run Runs an extension\nUsage: ocis run [command options] [arguments...]\nocis health Check health status\nUsage: ocis health [command options] [arguments...]\n \u0026ndash;debug-addr | $OCIS_DEBUG_ADDR Address to debug endpoint. Default: 0.0.0.0:9010.  ocis list Lists running ocis extensions\nUsage: ocis list [command options] [arguments...]\nList of available Extension subcommands There are more subcommands to start the individual extensions. Please check the documentation about their usage and options in the dedicated section of the documentation.\nocis konnectd Start konnectd server\nocis storage-frontend Start storage frontend\nocis accounts Start accounts server\nocis storage-storage-root Start storage root storage\nocis storage-gateway Start storage gateway\nocis storage-storage-home Start storage storage service for home mount\nocis storage-storage-public-link Start storage public link storage\nocis store Start a go-micro store\nocis glauth Start glauth server\nocis storage-auth-bearer Start storage auth-bearer service\nocis storage-sharing Start storage sharing service\nocis webdav Start webdav server\nocis storage-storage-oc-data Start storage storage data provider for oc mount\nocis thumbnails Start thumbnails server\nocis proxy Start proxy server\nocis settings Start settings server\nocis storage-auth-basic Start storage auth-basic service\nocis storage-storage-metadata Start storage storage service for metadata mount\nocis ocs Start ocs server\nocis storage-storage-eos Start storage storage service for eos mount\nocis storage-storage-eos-data Start storage storage data provider for eos mount\nocis storage-storage-home-data Start storage storage data provider for home mount\nocis storage-storage-oc Start storage storage service for oc mount\nocis storage-users Start storage users service\nocis phoenix Start phoenix server\n"});index.add({'id':31,'href':'/extensions/accounts/configuration/','title':"Configuration",'content':"    Configuration  Configuration using config files Envrionment variables Commandline flags ocis-reva server ocis-reva ocis-accounts       Configuration oCIS Single Binary is not responsible for configuring extensions. Instead, each extension could either be configured by environment variables, cli flags or config files.\nEach extension has its dedicated documentation page (e.g. https://owncloud.github.io/extensions/ocis_proxy/configuration) which lists all possible configurations. Config files and environment variables are picked up if you use the ./bin/ocis server command within the oCIS single binary. Command line flags must be set explicitly on the extensions subcommands.\nConfiguration using config files Out of the box extensions will attempt to read configuration details from:\n/etc/ocis $HOME/.ocis ./config For this configuration to be picked up, have a look at your extension root command and look for which default config name it has assigned. i.e: ocis-proxy reads proxy.json | yaml | toml ....\nSo far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/ocis.yml, ${HOME}/.ocis/ocis.yml or $(pwd)/config/ocis.yml.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nCommandline flags If you prefer to configure the service with commandline flags you can see the available variables below. Command line flags are only working when calling the subcommand directly.\nocis-reva server Start ocis accounts service\nUsage: ocis-reva server [command options] [arguments...]\n \u0026ndash;http-namespace | $ACCOUNTS_HTTP_NAMESPACE Set the base namespace for the http namespace. Default: com.owncloud.web. \u0026ndash;http-addr | $ACCOUNTS_HTTP_ADDR Address to bind http server. Default: localhost:9181. \u0026ndash;http-root | $ACCOUNTS_HTTP_ROOT Root path of http server. Default: /. \u0026ndash;grpc-namespace | $ACCOUNTS_GRPC_NAMESPACE Set the base namespace for the grpc namespace. Default: com.owncloud.api. \u0026ndash;grpc-addr | $ACCOUNTS_GRPC_ADDR Address to bind grpc server. Default: localhost:9180. \u0026ndash;name | $ACCOUNTS_NAME service name. Default: accounts. \u0026ndash;accounts-data-path | $ACCOUNTS_DATA_PATH accounts folder. Default: /var/tmp/ocis-accounts. \u0026ndash;asset-path | $HELLO_ASSET_PATH Path to custom assets.  ocis-reva ocis-accounts Provide accounts and groups for oCIS\nUsage: ocis-reva ocis-accounts [command options] [arguments...]\n \u0026ndash;log-level | $ACCOUNTS_LOG_LEVEL Set logging level. Default: info. \u0026ndash;log-pretty | $ACCOUNTS_LOG_PRETTY Enable pretty logging. Default: true. \u0026ndash;log-color | $ACCOUNTS_LOG_COLOR Enable colored logging. Default: true.  "});index.add({'id':32,'href':'/extensions/ocis_hello/building/','title':"Building",'content':"    Frontend Backend     As this project is built with Go and NodeJS, so you need to install that first. The installation of Go and NodeJS is out of the scope of this document, please follow the official documentation for Go, NodeJS and Yarn, to build this project you have to install Go \u0026gt;= v1.13. After the installation of the required tools you need to get the sources:\ngit clone https://github.com/owncloud/ocis-hello.git cd ocis-hello All required tool besides Go itself and make are bundled or getting automatically installed within the GOPATH. All commands to build this project are part of our Makefile and respectively our package.json.\nFrontend yarn install yarn build The above commands will install the required build dependencies and build the whole frontend bundle. This bundle will we embeded into the binary later on.\nBackend make generate make build The above commands will embed the frontend bundle into the binary. Finally you should have the binary within the bin/ folder now, give it a try with ./bin/ocis-hello -h to see all available options.\n"});index.add({'id':33,'href':'/clients/web/building/','title':"Building from source",'content':"    Building Phoenix Updating dependencies Cleaning up the workspace Buildling the documentation  Setting up Viewing the documentation Deploying the documentation       Building Phoenix  Run yarn install to install core dependencies Run yarn install-all to install dependencies of all apps and core Run yarn dist to build Phoenix and all apps included in the apps folder  Updating dependencies  Run yarn upgrade-all to update core and app dependencies  Cleaning up the workspace  Run yarn clean-all to remove node_modules and dist folder  Buildling the documentation Setting up  Install hugo Run make docs  Viewing the documentation To view the rendered docs in the browser run:\ncd hugo hugo -D server Then open \u0026ldquo;http://localhost:1313/\u0026rdquo;\nWhen making changes to the docs, run make docs again and the server will pick up the changes and reload the page automatically\nDeploying the documentation The documentation is automatically deployed from the master branch to https://owncloud.github.io/phoenix/\n"});index.add({'id':34,'href':'/extensions/accounts/getting-started/','title':"Getting Started",'content':"    Installation  Docker Binaries   Configuration  Envrionment variables  Server   Commandline flags Configuration file   Usage  Server       Installation So far we are offering two different variants for the installation. You can choose between Docker or pre-built binaries which are stored on our download mirrors and GitHub releases. Maybe we will also provide system packages for the major distributions later if we see the need for it.\nDocker TBD\nBinaries TBD\nConfiguration We provide overall three different variants of configuration. The variant based on environment variables and commandline flags are split up into global values and command-specific values.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nServer  OCIS_ACCOUNTS_NAME Name of the accounts service. It will be part of the namespace. OCIS_ACCOUNTS_NAMESPACE Namespace of the accounts service. OCIS_ACCOUNTS_ADDRESS Endpoint for the grpc service endpoint.  Commandline flags If you prefer to configure the service with commandline flags you can see the available variables below.\nConfiguration file So far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/accounts.yml, ${HOME}/.ocis/accounts.yml or $(pwd)/config/accounts.yml.\nUsage The program provides a few sub-commands on execution. The available configuration methods have already been mentioned above. Generally you can always see a formated help output if you execute the binary via ocis-accounts --help.\nServer The server command is used to start the grpc server. For further help please execute:\nocis-accounts server --help "});index.add({'id':35,'href':'/extensions/glauth/getting-started/','title':"Getting Started",'content':"    Installation  Docker Binaries   Configuration  Envrionment variables  Global Server Health   Commandline flags  Global Server Health   Configuration file   Usage  Server Health   Metrics     Installation So far we are offering two different variants for the installation. You can choose between Docker or pre-built binaries which are stored on our download mirrors and GitHub releases. Maybe we will also provide system packages for the major distributions later if we see the need for it.\nDocker TBD\nBinaries TBD\nConfiguration We provide overall three different variants of configuration. The variant based on environment variables and commandline flags are split up into global values and command-specific values.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nGlobal  GLAUTH_CONFIG_FILE Path to config file, empty default value GLAUTH_LOG_LEVEL Set logging level, defaults to info GLAUTH_LOG_COLOR Enable colored logging, defaults to true GLAUTH_LOG_PRETTY Enable pretty logging, defaults to true  Server  GLAUTH_TRACING_ENABLED Enable sending traces, defaults to false GLAUTH_TRACING_TYPE Tracing backend type, defaults to jaeger GLAUTH_TRACING_ENDPOINT Endpoint for the agent, empty default value GLAUTH_TRACING_COLLECTOR Endpoint for the collector, empty default value GLAUTH_TRACING_SERVICE Service name for tracing, defaults to glauth GLAUTH_DEBUG_ADDR Address to bind debug server, defaults to 0.0.0.0:9124 GLAUTH_DEBUG_TOKEN Token to grant metrics access, empty default value GLAUTH_DEBUG_PPROF Enable pprof debugging, defaults to false GLAUTH_DEBUG_ZPAGES Enable zpages debugging, defaults to false GLAUTH_HTTP_ADDR Address to bind http server, defaults to 0.0.0.0:9120 GLAUTH_HTTP_NAMESPACE The http namespace GLAUTH_HTTP_ROOT Root path of http server, defaults to /  Health  GLAUTH_DEBUG_ADDR Address to debug endpoint, defaults to 0.0.0.0:9124  Commandline flags If you prefer to configure the service with commandline flags you can see the available variables below.\nGlobal  \u0026ndash;config-file Path to config file, empty default value \u0026ndash;log-level Set logging level, defaults to info \u0026ndash;log-color Enable colored logging, defaults to true \u0026ndash;log-pretty Enable pretty logging, defaults to true  Server  \u0026ndash;tracing-enabled Enable sending traces, defaults to false \u0026ndash;tracing-type Tracing backend type, defaults to jaeger \u0026ndash;tracing-endpoint Endpoint for the agent, empty default value \u0026ndash;tracing-collector Endpoint for the collector, empty default value \u0026ndash;tracing-service Service name for tracing, defaults to glauth \u0026ndash;debug-addr Address to bind debug server, defaults to 0.0.0.0:9124 \u0026ndash;debug-token Token to grant metrics access, empty default value \u0026ndash;debug-pprof Enable pprof debugging, defaults to false \u0026ndash;debug-zpages Enable zpages debugging, defaults to false \u0026ndash;http-addr Address to bind http server, defaults to 0.0.0.0:9120 \u0026ndash;http-namespace Namespace for internal services communication, defaults to com.owncloud.web \u0026ndash;http-root Root path of http server, defaults to /  Health  \u0026ndash;debug-addr Address to debug endpoint, defaults to 0.0.0.0:9124  Configuration file So far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/glauth.yml, ${HOME}/.ocis/glauth.yml or $(pwd)/config/glauth.yml.\nUsage The program provides a few sub-commands on execution. The available configuration methods have already been mentioned above. Generally you can always see a formated help output if you execute the binary via ocis-glauth --help.\nServer The server command is used to start the http and debug server on two addresses within a single process. The http server is serving the general webservice while the debug server is used for health check, readiness check and to server the metrics mentioned below. For further help please execute:\nocis-glauth server --help Health The health command is used to execute a health check, if the exit code equals zero the service should be up and running, if the exist code is greater than zero the service is not in a healthy state. Generally this command is used within our Docker containers, it could also be used within Kubernetes.\nocis-glauth health --help Metrics This service provides some Prometheus metrics through the debug endpoint, you can optionally secure the metrics endpoint by some random token, which got to be configured through one of the flag --debug-token or the environment variable GLAUTH_DEBUG_TOKEN mentioned above. By default the metrics endpoint is bound to http://0.0.0.0:9124/metrics.\n go_gc_duration_seconds A summary of the GC invocation durations go_gc_duration_seconds_sum A summary of the GC invocation durations go_gc_duration_seconds_count A summary of the GC invocation durations go_goroutines Number of goroutines that currently exist go_info Information about the Go environment go_memstats_alloc_bytes Number of bytes allocated and still in use go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table go_memstats_frees_total Total number of frees go_memstats_gc_cpu_fraction The fraction of this program\u0026rsquo;s available CPU time used by the GC since the program started go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use go_memstats_heap_idle_bytes Number of heap bytes waiting to be used go_memstats_heap_inuse_bytes Number of heap bytes that are in use go_memstats_heap_objects Number of allocated objects go_memstats_heap_released_bytes Number of heap bytes released to OS go_memstats_heap_sys_bytes Number of heap bytes obtained from system go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection go_memstats_lookups_total Total number of pointer lookups go_memstats_mallocs_total Total number of mallocs go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place go_memstats_other_sys_bytes Number of bytes used for other system allocations go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator go_memstats_sys_bytes Number of bytes obtained from system go_threads Number of OS threads created promhttp_metric_handler_requests_in_flight Current number of scrapes being served promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code  "});index.add({'id':36,'href':'/extensions/ocis-phoenix/getting-started/','title':"Getting Started",'content':"    Installation  Docker Binaries   Configuration  Envrionment variables  Global Server Health   Commandline flags  Global Server Health   Configuration file   Usage  Server Health   Metrics     Installation So far we are offering two different variants for the installation. You can choose between Docker or pre-built binaries which are stored on our download mirrors and GitHub releases. Maybe we will also provide system packages for the major distributions later if we see the need for it.\nDocker TBD\nBinaries TBD\nConfiguration We provide overall three different variants of configuration. The variant based on environment variables and commandline flags are split up into global values and command-specific values.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nGlobal  PHOENIX_CONFIG_FILE Path to config file, empty default value PHOENIX_LOG_LEVEL Set logging level, defaults to info PHOENIX_LOG_COLOR Enable colored logging, defaults to true PHOENIX_LOG_PRETTY Enable pretty logging, defaults to true  Server  PHOENIX_TRACING_ENABLED Enable sending traces, defaults to false PHOENIX_TRACING_TYPE Tracing backend type, defaults to jaeger PHOENIX_TRACING_ENDPOINT Endpoint for the agent, empty default value PHOENIX_TRACING_COLLECTOR Endpoint for the collector, empty default value PHOENIX_TRACING_SERVICE Service name for tracing, defaults to phoenix PHOENIX_DEBUG_ADDR Address to bind debug server, defaults to 0.0.0.0:9104 PHOENIX_DEBUG_TOKEN Token to grant metrics access, empty default value PHOENIX_DEBUG_PPROF Enable pprof debugging, defaults to false PHOENIX_DEBUG_ZPAGES Enable zpages debugging, defaults to false PHOENIX_HTTP_ADDR Address to bind http server, defaults to 0.0.0.0:9100 PHOENIX_HTTP_ROOT Root path of http server, defaults to / PHOENIX_ASSET_PATH Path to custom assets, empty default value PHOENIX_WEB_CONFIG Path to phoenix config, empty default value PHOENIX_WEB_CONFIG_SERVER Server URL, defaults to http://localhost:9135 PHOENIX_WEB_CONFIG_THEME Theme, defaults to owncloud PHOENIX_WEB_CONFIG_VERSION Version, defaults to 0.1.0 PHOENIX_APPS Use multiple times to provide multiple apps PHOENIX_EXTERNAL_APPS Not supported yet, specify a config.json file via PHOENIX_WEB_CONFIG PHOENIX_OIDC_METADATA_URL OpenID Connect metadata URL, defaults to http://localhost:9130/.well-known/openid-configuration PHOENIX_OIDC_AUTHORITY OpenID Connect authority, defaults to http://localhost:9130 PHOENIX_OIDC_CLIENT_ID OpenID Connect client ID, defaults to phoenix PHOENIX_OIDC_RESPONSE_TYPE OpenID Connect response type, defaults to code PHOENIX_OIDC_SCOPE OpenID Connect scope, defaults to openid profile email  In case you want to render any additional properties in the config.json you can provide a custom config.json using eg. PHOENIX_WEB_CONFIG=/path/to/config.json ocis-phoenix server\nHealth  PHOENIX_DEBUG_ADDR Address to debug endpoint, defaults to 0.0.0.0:9104  Commandline flags If you prefer to configure the service with commandline flags you can see the available variables below.\nGlobal  \u0026ndash;config-file Path to config file, empty default value \u0026ndash;log-level Set logging level, defaults to info \u0026ndash;log-color Enable colored logging, defaults to true \u0026ndash;log-pretty Enable pretty logging, defaults to true  Server  \u0026ndash;tracing-enabled Enable sending traces, defaults to false \u0026ndash;tracing-type Tracing backend type, defaults to jaeger \u0026ndash;tracing-endpoint Endpoint for the agent, empty default value \u0026ndash;tracing-collector Endpoint for the collector, empty default value \u0026ndash;tracing-service Service name for tracing, defaults to phoenix \u0026ndash;debug-addr Address to bind debug server, defaults to 0.0.0.0:9104 \u0026ndash;debug-token Token to grant metrics access, empty default value \u0026ndash;debug-pprof Enable pprof debugging, defaults to false \u0026ndash;debug-zpages Enable zpages debugging, defaults to false \u0026ndash;http-addr Address to bind http server, defaults to 0.0.0.0:9100 \u0026ndash;http-root Root path of http server, defaults to / \u0026ndash;asset-path Path to custom assets, empty default value \u0026ndash;web-config Path to phoenix config, empty default value \u0026ndash;web-config-server Server URL, defaults to http://localhost:9135 \u0026ndash;web-config-theme Theme, defaults to owncloud \u0026ndash;web-config-version Version, defaults to 0.1.0 \u0026ndash;web-config-app Provide multiple apps, defaults to \u0026quot;\u0026quot;. Usage: phoenix --web-config-app files --web-config-app pdf-viewer \u0026ndash;oidc-metadata-url OpenID Connect metadata URL, defaults to http://localhost:9130/.well-known/openid-configuration \u0026ndash;oidc-authority OpenID Connect authority, defaults to http://localhost:9130 \u0026ndash;oidc-client-id OpenID Connect client ID, defaults to phoenix \u0026ndash;oidc-response-type OpenID Connect response type, defaults to code \u0026ndash;oidc-scope OpenID Connect scope, defaults to openid profile email  In case you want to render any additional properties in the config.json you can provide a custom config.json using eg. ocis-phoenix server --web-config=/path/to/config.json\nHealth  \u0026ndash;debug-addr Address to debug endpoint, defaults to 0.0.0.0:9104  Configuration file So far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/phoenix.yml, ${HOME}/.ocis/phoenix.yml or $(pwd)/config/phoenix.yml.\nUsage The program provides a few sub-commands on execution. The available configuration methods have already been mentioned above. Generally you can always see a formated help output if you execute the binary via ocis-phoenix --help.\nServer The server command is used to start the http and debug server on two addresses within a single process. The http server is serving the general webservice while the debug server is used for health check, readiness check and to server the metrics mentioned below. For further help please execute:\nocis-phoenix server --help Health The health command is used to execute a health check, if the exit code equals zero the service should be up and running, if the exist code is greater than zero the service is not in a healthy state. Generally this command is used within our Docker containers, it could also be used within Kubernetes.\nocis-phoenix health --help Metrics This service provides some Prometheus metrics through the debug endpoint, you can optionally secure the metrics endpoint by some random token, which got to be configured through one of the flag --debug-token or the environment variable PHOENIX_DEBUG_TOKEN mentioned above. By default the metrics endpoint is bound to http://0.0.0.0:9104/metrics.\n go_gc_duration_seconds A summary of the GC invocation durations go_gc_duration_seconds_sum A summary of the GC invocation durations go_gc_duration_seconds_count A summary of the GC invocation durations go_goroutines Number of goroutines that currently exist go_info Information about the Go environment go_memstats_alloc_bytes Number of bytes allocated and still in use go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table go_memstats_frees_total Total number of frees go_memstats_gc_cpu_fraction The fraction of this program\u0026rsquo;s available CPU time used by the GC since the program started go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use go_memstats_heap_idle_bytes Number of heap bytes waiting to be used go_memstats_heap_inuse_bytes Number of heap bytes that are in use go_memstats_heap_objects Number of allocated objects go_memstats_heap_released_bytes Number of heap bytes released to OS go_memstats_heap_sys_bytes Number of heap bytes obtained from system go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection go_memstats_lookups_total Total number of pointer lookups go_memstats_mallocs_total Total number of mallocs go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place go_memstats_other_sys_bytes Number of bytes used for other system allocations go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator go_memstats_sys_bytes Number of bytes obtained from system go_threads Number of OS threads created promhttp_metric_handler_requests_in_flight Current number of scrapes being served promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code  "});index.add({'id':37,'href':'/extensions/store/getting-started/','title':"Getting Started",'content':"    Installation  Docker Binaries   Configuration  Envrionment variables  Global Server Health   Commandline flags  Global Server Health   Configuration file   Usage  Server Health   Metrics     Installation So far we are offering two different variants for the installation. You can choose between Docker or pre-built binaries which are stored on our download mirrors and GitHub releases. Maybe we will also provide system packages for the major distributions later if we see the need for it.\nDocker TBD\nBinaries TBD\nConfiguration We provide overall three different variants of configuration. The variant based on environment variables and commandline flags are split up into global values and command-specific values.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nGlobal  STORE_CONFIG_FILE Path to config file, empty default value STORE_LOG_LEVEL Set logging level, defaults to info STORE_LOG_COLOR Enable colored logging, defaults to true STORE_LOG_PRETTY Enable pretty logging, defaults to true  Server  STORE_TRACING_ENABLED Enable sending traces, defaults to false STORE_TRACING_TYPE Tracing backend type, defaults to jaeger STORE_TRACING_ENDPOINT Endpoint for the agent, empty default value STORE_TRACING_COLLECTOR Endpoint for the collector, empty default value STORE_TRACING_SERVICE Service name for tracing, defaults to store STORE_DEBUG_ADDR Address to bind debug server STORE_DEBUG_TOKEN Token to grant metrics access, empty default value STORE_DEBUG_PPROF Enable pprof debugging, defaults to false STORE_DEBUG_ZPAGES Enable zpages debugging, defaults to false STORE_HTTP_ADDR Address to bind http server, defaults to 0.0.0.0:9461 STORE_HTTP_NAMESPACE The http namespace STORE_HTTP_ROOT Root path of http server, defaults to /  Health  STORE_DEBUG_ADDR Address to debug endpoint  Commandline flags If you prefer to configure the service with commandline flags you can see the available variables below.\nGlobal  \u0026ndash;config-file Path to config file, empty default value \u0026ndash;log-level Set logging level, defaults to info \u0026ndash;log-color Enable colored logging, defaults to true \u0026ndash;log-pretty Enable pretty logging, defaults to true  Server  \u0026ndash;tracing-enabled Enable sending traces, defaults to false \u0026ndash;tracing-type Tracing backend type, defaults to jaeger \u0026ndash;tracing-endpoint Endpoint for the agent, empty default value \u0026ndash;tracing-collector Endpoint for the collector, empty default value \u0026ndash;tracing-service Service name for tracing, defaults to store \u0026ndash;debug-addr Address to bind debug server \u0026ndash;debug-token Token to grant metrics access, empty default value \u0026ndash;debug-pprof Enable pprof debugging, defaults to false \u0026ndash;debug-zpages Enable zpages debugging, defaults to false \u0026ndash;http-addr Address to bind http server, defaults to 0.0.0.0:9461 \u0026ndash;http-namespace Namespace for internal services communication, defaults to com.owncloud.web \u0026ndash;http-root Root path of http server, defaults to /  Health  \u0026ndash;debug-addr Address to debug endpoint  Configuration file So far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/store.yml, ${HOME}/.ocis/store.yml or $(pwd)/config/store.yml.\nUsage The program provides a few sub-commands on execution. The available configuration methods have already been mentioned above. Generally you can always see a formated help output if you execute the binary via ocis-store --help.\nServer The server command is used to start the http and debug server on two addresses within a single process. The http server is serving the general webservice while the debug server is used for health check, readiness check and to server the metrics mentioned below. For further help please execute:\nocis-store server --help Health The health command is used to execute a health check, if the exit code equals zero the service should be up and running, if the exist code is greater than zero the service is not in a healthy state. Generally this command is used within our Docker containers, it could also be used within Kubernetes.\nocis-store health --help Metrics This service provides some Prometheus metrics through the debug endpoint, you can optionally secure the metrics endpoint by some random token, which got to be configured through one of the flag --debug-token or the environment variable STORE_DEBUG_TOKEN mentioned above. By default the metrics endpoint is bound to http://0.0.0.0:9460/metrics.\n go_gc_duration_seconds A summary of the GC invocation durations go_gc_duration_seconds_sum A summary of the GC invocation durations go_gc_duration_seconds_count A summary of the GC invocation durations go_goroutines Number of goroutines that currently exist go_info Information about the Go environment go_memstats_alloc_bytes Number of bytes allocated and still in use go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table go_memstats_frees_total Total number of frees go_memstats_gc_cpu_fraction The fraction of this program\u0026rsquo;s available CPU time used by the GC since the program started go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use go_memstats_heap_idle_bytes Number of heap bytes waiting to be used go_memstats_heap_inuse_bytes Number of heap bytes that are in use go_memstats_heap_objects Number of allocated objects go_memstats_heap_released_bytes Number of heap bytes released to OS go_memstats_heap_sys_bytes Number of heap bytes obtained from system go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection go_memstats_lookups_total Total number of pointer lookups go_memstats_mallocs_total Total number of mallocs go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place go_memstats_other_sys_bytes Number of bytes used for other system allocations go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator go_memstats_sys_bytes Number of bytes obtained from system go_threads Number of OS threads created promhttp_metric_handler_requests_in_flight Current number of scrapes being served promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code  "});index.add({'id':38,'href':'/extensions/thumbnails/getting-started/','title':"Getting Started",'content':"    Installation  Docker Binaries   Configuration  Envrionment variables  Global Server Health   Commandline flags  Global Server Health   Configuration file   Usage  Server Health   Metrics     Installation So far we are offering two different variants for the installation. You can choose between Docker or pre-built binaries which are stored on our download mirrors and GitHub releases. Maybe we will also provide system packages for the major distributions later if we see the need for it.\nDocker TBD\nBinaries TBD\nConfiguration We provide overall three different variants of configuration. The variant based on environment variables and commandline flags are split up into global values and command-specific values.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nGlobal  THUMBNAILS_CONFIG_FILE Path to config file, empty default value THUMBNAILS_LOG_LEVEL Set logging level, defaults to info THUMBNAILS_LOG_COLOR Enable colored logging, defaults to true THUMBNAILS_LOG_PRETTY Enable pretty logging, defaults to true  Server  THUMBNAILS_TRACING_ENABLED Enable sending traces, defaults to false THUMBNAILS_TRACING_TYPE Tracing backend type, defaults to jaeger THUMBNAILS_TRACING_ENDPOINT Endpoint for the agent, empty default value THUMBNAILS_TRACING_COLLECTOR Endpoint for the collector, empty default value THUMBNAILS_TRACING_SERVICE Service name for tracing, defaults to ocis-thumbnails THUMBNAILS_DEBUG_ADDR Address to bind debug server, defaults to 0.0.0.0:9114 THUMBNAILS_DEBUG_TOKEN Token to grant metrics access, empty default value THUMBNAILS_DEBUG_PPROF Enable pprof debugging, defaults to false THUMBNAILS_DEBUG_ZPAGES Enable zpages debugging, defaults to false THUMBNAILS_GRPC_NAME Name of the service, defaults to thumbnails THUMBNAILS_GRPC_ADDR Address to bind grpc server, defaults to 0.0.0.0:9185 THUMBNAILS_GRPC_NAMESPACE Set the base namespace for the grpc namespace\u0026rdquo;, defaults to com.owncloud.api THUMBNAILS_FILESYSTEMSTORAGE_ROOT Root path of the filesystem storage directory, defaults to \u0026lt;os tempdir\u0026gt;/ocis-thumbnails/ THUMBNAILS_WEBDAVSOURCE_BASEURL Base url for a webdav api, defaults to https://localhost:9200/remote.php/webdav/ THUMBNAILS_RESOLUTIONS List of resolutions supported by the service, defaults to `[\u0026ldquo;16x16\u0026rdquo;, \u0026ldquo;32x32\u0026rdquo;, \u0026ldquo;64x64\u0026rdquo;, \u0026ldquo;128x128\u0026rdquo;]  Health  THUMBNAILS_DEBUG_ADDR Address to debug endpoint, defaults to 0.0.0.0:9189  Commandline flags If you prefer to configure the service with commandline flags you can see the available variables below.\nGlobal  \u0026ndash;config-file Path to config file, empty default value \u0026ndash;log-level Set logging level, defaults to info \u0026ndash;log-color Enable colored logging, defaults to true \u0026ndash;log-pretty Enable pretty logging, defaults to true  Server  \u0026ndash;tracing-enabled Enable sending traces, defaults to false \u0026ndash;tracing-type Tracing backend type, defaults to jaeger \u0026ndash;tracing-endpoint Endpoint for the agent, empty default value \u0026ndash;tracing-collector Endpoint for the collector, empty default value \u0026ndash;tracing-service Service name for tracing, defaults to thumbnails \u0026ndash;debug-addr Address to bind debug server, defaults to 0.0.0.0:9189 \u0026ndash;debug-token Token to grant metrics access, empty default value \u0026ndash;debug-pprof Enable pprof debugging, defaults to false \u0026ndash;debug-zpages Enable zpages debugging, defaults to false \u0026ndash;grpc-name Name of the service, defaults to thumbnails \u0026ndash;grpc-addr Address to bind grpc server, defaults to 0.0.0.0:9185 \u0026ndash;grpc-namespace Set the base namespace for the grpc namespace\u0026rdquo;, defaults to com.owncloud.api \u0026ndash;filesystemstorage-root Root path of the filesystem storage directory, defaults to \u0026lt;os tempdir\u0026gt;/ocis-thumbnails/ \u0026ndash;webdavsource-baseurl Base url for a webdav api, defaults to https://localhost:9200/remote.php/webdav/ \u0026ndash;thumbnail-resolution List of resolutions supported by the service, defaults to `[\u0026ldquo;16x16\u0026rdquo;, \u0026ldquo;32x32\u0026rdquo;, \u0026ldquo;64x64\u0026rdquo;, \u0026ldquo;128x128\u0026rdquo;]  Health  \u0026ndash;debug-addr Address to debug endpoint, defaults to 0.0.0.0:9189  Configuration file So far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/thumbnails.yml, ${HOME}/.ocis/thumbnails.yml or $(pwd)/config/thumbnails.yml.\nUsage The program provides a few sub-commands on execution. The available configuration methods have already been mentioned above. Generally you can always see a formated help output if you execute the binary via ocis-thumbnails --help.\nServer The server command is used to start the http and debug server on two addresses within a single process. The http server is serving the general webservice while the debug server is used for health check, readiness check and to server the metrics mentioned below. For further help please execute:\n{{ Name }} server --help Health The health command is used to execute a health check, if the exit code equals zero the service should be up and running, if the exist code is greater than zero the service is not in a healthy state. Generally this command is used within our Docker containers, it could also be used within Kubernetes.\n{{ Name }} health --help Metrics This service provides some Prometheus metrics through the debug endpoint, you can optionally secure the metrics endpoint by some random token, which got to be configured through one of the flag --debug-token or the environment variable THUMBNAILS_DEBUG_TOKEN mentioned above. By default the metrics endpoint is bound to http://0.0.0.0:9114/metrics.\n go_gc_duration_seconds A summary of the GC invocation durations go_gc_duration_seconds_sum A summary of the GC invocation durations go_gc_duration_seconds_count A summary of the GC invocation durations go_goroutines Number of goroutines that currently exist go_info Information about the Go environment go_memstats_alloc_bytes Number of bytes allocated and still in use go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table go_memstats_frees_total Total number of frees go_memstats_gc_cpu_fraction The fraction of this program\u0026rsquo;s available CPU time used by the GC since the program started go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use go_memstats_heap_idle_bytes Number of heap bytes waiting to be used go_memstats_heap_inuse_bytes Number of heap bytes that are in use go_memstats_heap_objects Number of allocated objects go_memstats_heap_released_bytes Number of heap bytes released to OS go_memstats_heap_sys_bytes Number of heap bytes obtained from system go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection go_memstats_lookups_total Total number of pointer lookups go_memstats_mallocs_total Total number of mallocs go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place go_memstats_other_sys_bytes Number of bytes used for other system allocations go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator go_memstats_sys_bytes Number of bytes obtained from system go_threads Number of OS threads created promhttp_metric_handler_requests_in_flight Current number of scrapes being served promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code  "});index.add({'id':39,'href':'/extensions/webdav/getting-started/','title':"Getting Started",'content':"      Installation  Docker Binaries   Configuration  Envrionment variables  Global Server Health   Commandline flags  Global Server Health   Configuration file   Usage  Server Health   Metrics       Installation So far we are offering two different variants for the installation. You can choose between Docker or pre-built binaries which are stored on our download mirrors and GitHub releases. Maybe we will also provide system packages for the major distributions later if we see the need for it.\nDocker TBD\nBinaries TBD\nConfiguration We provide overall three different variants of configuration. The variant based on environment variables and commandline flags are split up into global values and command-specific values.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nGlobal  WEBDAV_CONFIG_FILE Path to config file, empty default value WEBDAV_LOG_LEVEL Set logging level, defaults to info WEBDAV_LOG_COLOR Enable colored logging, defaults to true WEBDAV_LOG_PRETTY Enable pretty logging, defaults to true  Server  WEBDAV_TRACING_ENABLED Enable sending traces, defaults to false WEBDAV_TRACING_TYPE Tracing backend type, defaults to jaeger WEBDAV_TRACING_ENDPOINT Endpoint for the agent, empty default value WEBDAV_TRACING_COLLECTOR Endpoint for the collector, empty default value WEBDAV_TRACING_SERVICE Service name for tracing, defaults to webdav WEBDAV_DEBUG_ADDR Address to bind debug server, defaults to 0.0.0.0:9119 WEBDAV_DEBUG_TOKEN Token to grant metrics access, empty default value WEBDAV_DEBUG_PPROF Enable pprof debugging, defaults to false WEBDAV_DEBUG_ZPAGES Enable zpages debugging, defaults to false WEBDAV_HTTP_ADDR Address to bind http server, defaults to 0.0.0.0:9115 WEBDAV_HTTP_ROOT Root path of http server, defaults to /  Health  WEBDAV_DEBUG_ADDR Address to debug endpoint, defaults to 0.0.0.0:9119  Commandline flags If you prefer to configure the service with commandline flags you can see the available variables below.\nGlobal  \u0026ndash;config-file Path to config file, empty default value \u0026ndash;log-level Set logging level, defaults to info \u0026ndash;log-color Enable colored logging, defaults to true \u0026ndash;log-pretty Enable pretty logging, defaults to true  Server  \u0026ndash;tracing-enabled Enable sending traces, defaults to false \u0026ndash;tracing-type Tracing backend type, defaults to jaeger \u0026ndash;tracing-endpoint Endpoint for the agent, empty default value \u0026ndash;tracing-collector Endpoint for the collector, empty default value \u0026ndash;tracing-service Service name for tracing, defaults to webdav \u0026ndash;debug-addr Address to bind debug server, defaults to 0.0.0.0:9119 \u0026ndash;debug-token Token to grant metrics access, empty default value \u0026ndash;debug-pprof Enable pprof debugging, defaults to false \u0026ndash;debug-zpages Enable zpages debugging, defaults to false \u0026ndash;http-addr Address to bind http server, defaults to 0.0.0.0:9115 \u0026ndash;http-namespace Namespace for internal services communication, defaults to com.owncloud.web \u0026ndash;http-root Root path of http server, defaults to /  Health  \u0026ndash;debug-addr Address to debug endpoint, defaults to 0.0.0.0:9119  Configuration file So far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/webdav.yml, ${HOME}/.ocis/webdav.yml or $(pwd)/config/webdav.yml.\nUsage The program provides a few sub-commands on execution. The available configuration methods have already been mentioned above. Generally you can always see a formated help output if you execute the binary via ocis-webdav --help.\nServer The server command is used to start the http and debug server on two addresses within a single process. The http server is serving the general webservice while the debug server is used for health check, readiness check and to server the metrics mentioned below. For further help please execute:\nocis-webdav server --help Health The health command is used to execute a health check, if the exit code equals zero the service should be up and running, if the exist code is greater than zero the service is not in a healthy state. Generally this command is used within our Docker containers, it could also be used within Kubernetes.\nocis-webdav health --help Metrics This service provides some Prometheus metrics through the debug endpoint, you can optionally secure the metrics endpoint by some random token, which got to be configured through one of the flag --debug-token or the environment variable WEBDAV_DEBUG_TOKEN mentioned above. By default the metrics endpoint is bound to http://0.0.0.0:9119/metrics.\n go_gc_duration_seconds A summary of the GC invocation durations go_gc_duration_seconds_sum A summary of the GC invocation durations go_gc_duration_seconds_count A summary of the GC invocation durations go_goroutines Number of goroutines that currently exist go_info Information about the Go environment go_memstats_alloc_bytes Number of bytes allocated and still in use go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table go_memstats_frees_total Total number of frees go_memstats_gc_cpu_fraction The fraction of this program\u0026rsquo;s available CPU time used by the GC since the program started go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use go_memstats_heap_idle_bytes Number of heap bytes waiting to be used go_memstats_heap_inuse_bytes Number of heap bytes that are in use go_memstats_heap_objects Number of allocated objects go_memstats_heap_released_bytes Number of heap bytes released to OS go_memstats_heap_sys_bytes Number of heap bytes obtained from system go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection go_memstats_lookups_total Total number of pointer lookups go_memstats_mallocs_total Total number of mallocs go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place go_memstats_other_sys_bytes Number of bytes used for other system allocations go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator go_memstats_sys_bytes Number of bytes obtained from system go_threads Number of OS threads created promhttp_metric_handler_requests_in_flight Current number of scrapes being served promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code  "});index.add({'id':40,'href':'/extensions/settings/getting-started/','title':"Getting Started",'content':"    Installation  Docker Binaries   Configuration  Envrionment variables  Global Server Health   Commandline flags  Global Server Health   Configuration file   Usage  Server Health   Metrics     Installation So far we are offering two different variants for the installation. You can choose between Docker or pre-built binaries which are stored on our download mirrors and GitHub releases. Maybe we will also provide system packages for the major distributions later if we see the need for it.\nDocker TBD\nBinaries TBD\nConfiguration We provide overall three different variants of configuration. The variant based on environment variables and commandline flags are split up into global values and command-specific values.\nEnvrionment variables If you prefer to configure the service with environment variables you can see the available variables below.\nGlobal  SETTINGS_CONFIG_FILE Path to config file, empty default value SETTINGS_LOG_LEVEL Set logging level, defaults to info SETTINGS_LOG_COLOR Enable colored logging, defaults to true SETTINGS_LOG_PRETTY Enable pretty logging, defaults to true  Server  SETTINGS_TRACING_ENABLED Enable sending traces, defaults to false SETTINGS_TRACING_TYPE Tracing backend type, defaults to jaeger SETTINGS_TRACING_ENDPOINT Endpoint for the agent, empty default value SETTINGS_TRACING_COLLECTOR Endpoint for the collector, empty default value SETTINGS_TRACING_SERVICE Service name for tracing, defaults to settings SETTINGS_DEBUG_ADDR Address to bind debug server, defaults to 0.0.0.0:9194 SETTINGS_DEBUG_TOKEN Token to grant metrics access, empty default value SETTINGS_DEBUG_PPROF Enable pprof debugging, defaults to false SETTINGS_DEBUG_ZPAGES Enable zpages debugging, defaults to false SETTINGS_HTTP_ADDR Address to bind http server, defaults to 0.0.0.0:9190 SETTINGS_HTTP_NAMESPACE The http namespace SETTINGS_HTTP_ROOT Root path of http server, defaults to /  Health  SETTINGS_DEBUG_ADDR Address to debug endpoint, defaults to 0.0.0.0:9194  Commandline flags If you prefer to configure the service with commandline flags you can see the available variables below.\nGlobal  \u0026ndash;config-file Path to config file, empty default value \u0026ndash;log-level Set logging level, defaults to info \u0026ndash;log-color Enable colored logging, defaults to true \u0026ndash;log-pretty Enable pretty logging, defaults to true  Server  \u0026ndash;tracing-enabled Enable sending traces, defaults to false \u0026ndash;tracing-type Tracing backend type, defaults to jaeger \u0026ndash;tracing-endpoint Endpoint for the agent, empty default value \u0026ndash;tracing-collector Endpoint for the collector, empty default value \u0026ndash;tracing-service Service name for tracing, defaults to settings \u0026ndash;debug-addr Address to bind debug server, defaults to 0.0.0.0:9194 \u0026ndash;debug-token Token to grant metrics access, empty default value \u0026ndash;debug-pprof Enable pprof debugging, defaults to false \u0026ndash;debug-zpages Enable zpages debugging, defaults to false \u0026ndash;http-addr Address to bind http server, defaults to 0.0.0.0:9190 \u0026ndash;http-namespace Namespace for internal services communication, defaults to com.owncloud.web \u0026ndash;http-root Root path of http server, defaults to /  Health  \u0026ndash;debug-addr Address to debug endpoint, defaults to 0.0.0.0:9194  Configuration file So far we support the file formats JSON and YAML, if you want to get a full example configuration just take a look at our repository, there you can always see the latest configuration format. These example configurations include all available options and the default values. The configuration file will be automatically loaded if it\u0026rsquo;s placed at /etc/ocis/settings.yml, ${HOME}/.ocis/settings.yml or $(pwd)/config/settings.yml.\nUsage The program provides a few sub-commands on execution. The available configuration methods have already been mentioned above. Generally you can always see a formated help output if you execute the binary via ocis-settings --help.\nServer The server command is used to start the http and debug server on two addresses within a single process. The http server is serving the general webservice while the debug server is used for health check, readiness check and to server the metrics mentioned below. For further help please execute:\nocis-settings server --help Health The health command is used to execute a health check, if the exit code equals zero the service should be up and running, if the exist code is greater than zero the service is not in a healthy state. Generally this command is used within our Docker containers, it could also be used within Kubernetes.\nocis-settings health --help Metrics This service provides some Prometheus metrics through the debug endpoint, you can optionally secure the metrics endpoint by some random token, which got to be configured through one of the flag --debug-token or the environment variable SETTINGS_DEBUG_TOKEN mentioned above. By default the metrics endpoint is bound to http://0.0.0.0:9194/metrics.\n go_gc_duration_seconds A summary of the GC invocation durations go_gc_duration_seconds_sum A summary of the GC invocation durations go_gc_duration_seconds_count A summary of the GC invocation durations go_goroutines Number of goroutines that currently exist go_info Information about the Go environment go_memstats_alloc_bytes Number of bytes allocated and still in use go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table go_memstats_frees_total Total number of frees go_memstats_gc_cpu_fraction The fraction of this program\u0026rsquo;s available CPU time used by the GC since the program started go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use go_memstats_heap_idle_bytes Number of heap bytes waiting to be used go_memstats_heap_inuse_bytes Number of heap bytes that are in use go_memstats_heap_objects Number of allocated objects go_memstats_heap_released_bytes Number of heap bytes released to OS go_memstats_heap_sys_bytes Number of heap bytes obtained from system go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection go_memstats_lookups_total Total number of pointer lookups go_memstats_mallocs_total Total number of mallocs go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place go_memstats_other_sys_bytes Number of bytes used for other system allocations go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator go_memstats_sys_bytes Number of bytes obtained from system go_threads Number of OS threads created promhttp_metric_handler_requests_in_flight Current number of scrapes being served promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code  "});index.add({'id':41,'href':'/clients/web/releasing/','title':"Releasing",'content':"    Releasing Phoenix  Package Hierarchy  Releasing Phoenix Frontend Next steps         Releasing Phoenix The next generation Web Frontend is shipped as an ocis Extension. The ocis-phoenix extension is also embedded in the single binary and part of the ocis server command.\nThis repository contains the assets and these must be released first before being bundled into ocis-phoenix.\nPackage Hierarchy  ocis  ocis-phoenix  ocis-pkg phoenix      Releasing Phoenix Frontend  Create a branch release-$version in https://github.com/owncloud/phoenix. Create a folder in changelog for the release version and date mkdir $major.$minor.$patchVersion_YYYY-MM-DD. Move all changelog items from the changelog/unreleased/ folder to the $major.$minor.$patchVersion_YYYY-MM-DD folder. Commit your changes. After merging, wait for the CI to run on the merge commit. Go to the Releases section and click \u0026ldquo;Draft a new Release\u0026rdquo;. Use v$major.$minor.$patch as a tag (the v prefix is important) and publish it. The tag and the Release artifacts will be created automatically.  Next steps The next steps are usually to update the Phoenix assets in the ocis-phoenix repository.\n"});index.add({'id':42,'href':'/ocis/deployment/bridge/','title':"Bridge",'content':"    Current status How to do it  Install the owncloud 10 graphapi app Enable the graphapi app Start ocis-glauth  Grab it! Run it! Check it is up and running   Start ocis-phoenix  Get it! Run it!   Start ocis-konnectd  Get it! Set environment variables   Configure clients  Run it! Check it is up and running   Patch owncloud Install the owncloud 10 openidconnect app   Next steps     We are planning to build a bridge from ownCloud 10 to ocis. The idea is to have a reverse proxy infront of ownCloud 10 that will forward requests to ownCloud 10 or ocis-reva, depending on the migration status of the logged in user.\nThis document is a work in progress of the current setup.\nCurrent status Using ocis and the ownCloud 10 openidconnect and graphapi plugins it is possible today to introduce openid connect based authentication to existing instances. That is a prerequisite for migrating to ocis.\nHow to do it Install the owncloud 10 graphapi app In an owncloud 10 apps folder\n$ git clone git@github.com:owncloud/graphapi.git $ cd graphapi $ composer install Enable the graphapi app occ a:e graphapi No configuration necessary. You can test with curl:\n$ curl https://cloud.example.com/index.php/apps/graphapi/v1.0/users -u admin | jq Enter host password for user \u0026#39;admin\u0026#39;: % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 694 100 694 0 0 4283 0 --:--:-- --:--:-- --:--:-- 4283 { \u0026#34;value\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;displayName\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;mail\u0026#34;: null }, { \u0026#34;id\u0026#34;: \u0026#34;demo\u0026#34;, \u0026#34;displayName\u0026#34;: \u0026#34;Demo\u0026#34;, \u0026#34;mail\u0026#34;: null }, ... ], \u0026#34;@odata.nextLink\u0026#34;: \u0026#34;https://oc.butonic.de/apps/graphapi/v1.0/users?$top=10\u0026amp;$skip=10\u0026#34; }  Note: The MS graph api actually asks for Bearer auth, but in order to check users passwords during an LDAP bind we are exploiting ownClouds authentication implementation that will grant access when Basic auth is used. An LDAP Bind you may ask? Read on!\n Start ocis-glauth We are going to use the above ownCloud 10 and graphapi app to turn it into the datastore for an LDAP proxy.\nGrab it! In an ocis folder\n$ git clone git@github.com:owncloud/ocis-glauth.git $ cd ocis-glauth $ make This should give you a bin/ocis-glauth binary. Try listing the help with bin/ocis-glauth --help.\nRun it! You need to point ocis-glauth to your owncloud domain:\n$ bin/ocis-glauth --log-level debug server --backend-datastore owncloud --backend-server https://cloud.example.com --backend-basedn dc=example,dc=com --log-level debug is only used to generate more verbose output --backend-datastore owncloud switches to tho owncloud datastore --backend-server https://cloud.example.com is the url to an ownCloud instance with an enabled graphapi app --backend-basedn dc=example,dc=com is used to construct the LDAP dn. The user admin will become cn=admin,dc=example,dc=com.\nCheck it is up and running You should now be able to list accounts from your ownCloud 10 oc_accounts table using:\n$ ldapsearch -x -H ldap://localhost:9125 -b dc=example,dc=com -D \u0026#34;cn=admin,dc=example,dc=com\u0026#34; -W \u0026#39;(objectclass=posixaccount)\u0026#39; Groups should work as well:\n$ ldapsearch -x -H ldap://localhost:9125 -b dc=example,dc=com -D \u0026#34;cn=admin,dc=example,dc=com\u0026#34; -W \u0026#39;(objectclass=posixgroup)\u0026#39;  Note: This is currently a readonly implementation and minimal to the usecase of authenticating users with konnectd.\n Start ocis-phoenix Get it! In an ocis folder\n$ git clone git@github.com:owncloud/ocis-phoenix.git $ cd ocis-phoenix $ make This should give you a bin/ocis-phoenix binary. Try listing the help with bin/ocis-phoenix --help.\nRun it! Point ocis-phoenix to your owncloud domain and tell it where to find the openid connect issuing authority:\n$ bin/ocis-phoenix server --web-config-server https://cloud.example.com --oidc-authority https://192.168.1.100:9130 --oidc-metadata-url https://192.168.1.100:9130/.well-known/openid-configuration --oidc-client-id ocis ocis-phoenix needs to know\n --web-config-server https://cloud.example.com is ownCloud url with webdav and ocs endpoints (oc10 or ocis) --oidc-authority https://192.168.1.100:9130 the openid connect issuing authority, in our case oidc-konnectd, running on port 9130 --oidc-metadata-url https://192.168.1.100:9130/.well-known/openid-configuration the openid connect configuration endpoint, typically the issuer host with .well-known/openid-configuration, but there are cases when another endpoint is used, eg. ping identity provides multiple endpoints to separate domains --oidc-client-id ocis the client id we will register later with ocis-konnectd in the identifier-registration.yaml  Start ocis-konnectd Get it! In an ocis folder\n$ git clone git@github.com:owncloud/ocis-konnectd.git $ cd ocis-konnectd $ make This should give you a bin/ocis-konnectd binary. Try listing the help with bin/ocis-konnectd --help.\nSet environment variables Konnectd needs environment variables to configure the LDAP server:\nexport LDAP_URI=ldap://192.168.1.100:9125 export LDAP_BINDDN=\u0026#34;cn=admin,dc=example,dc=com\u0026#34; export LDAP_BINDPW=\u0026#34;its-a-secret\u0026#34; export LDAP_BASEDN=\u0026#34;dc=example,dc=com\u0026#34; export LDAP_SCOPE=sub export LDAP_LOGIN_ATTRIBUTE=uid export LDAP_EMAIL_ATTRIBUTE=mail export LDAP_NAME_ATTRIBUTE=givenName export LDAP_UUID_ATTRIBUTE=uid export LDAP_UUID_ATTRIBUTE_TYPE=text export LDAP_FILTER=\u0026#34;(objectClass=posixaccount)\u0026#34; Don\u0026rsquo;t forget to use an existing user and the correct password.\nConfigure clients Now we need to configure a client we can later use to configure the ownCloud 10 openidconnect app. In the assets/identifier-registration.yaml have:\n---# OpenID Connect client registry.clients:- id:ocisname:ownCloudInfiniteScaleinsecure:yesapplication_type:webredirect_uris:- https://cloud.example.com/apps/openidconnect/redirect- http://localhost:9100/oidc-callback.html- http://localhost:9100- http://localhost:9100/You will need the insecure: yes if you are using self signed certificates.\nReplace cloud.example.com in the redirect URI with your ownCloud 10 host and port. Replace localhost:9100 in the redirect URIs with your the ocis-phoenix host and port.\nRun it! You can now bring up ocis-connectd with:\n$ bin/ocis-konnectd server --iss https://192.168.1.100:9130 --identifier-registration-conf assets/identifier-registration.yaml --signing-kid gen1-2020-02-27 ocis-konnectd needs to know\n --iss https://192.168.1.100:9130 the issuer, which must be a reachable https endpoint. For testing an ip works. HTTPS is NOT optional. This url is exposed in the https://192.168.1.100:9130/.well-known/openid-configuration endpoint and clients need to be able to connect to it --identifier-registration-conf assets/identifier-registration.yaml the identifier-registration.yaml you created --signing-kid gen1-2020-02-27 a signature key id, otherwise the jwks key has no name, which might cause problems with clients. a random key is ok, but it should change when the actual signing key changes.  Check it is up and running  Try getting the configuration:  $ curl https://192.168.1.100:9130/.well-known/openid-configuration Check if the login works at https://192.168.1.100:9130/signin/v1/identifier   Note: If you later get a Unable to find a key for (algorithm, kid):PS256, ) Error make sure you did set a --signing-kid when starting ocis-konnectd by checking it is present in https://192.168.1.100:9130/konnect/v1/jwks.json\n Patch owncloud While the UserSession in ownCloud 10 is currently used to test all available IAuthModule implementations, it immediately logs out the user when an exception occurs. However, existing owncloud 10 instances use the oauth2 app to create Bearer tokens for mobile and desktop clients.\nTo give the openidconnect app a chance to verify the tokens we need to change the code a bit. See https://github.com/owncloud/core/pull/37043 for a possible solution.\n Note: The PR is hot \u0026hellip; as in younger than this list of steps. And it messes with authentication. Use with caution.\n Install the owncloud 10 openidconnect app In an owncloud 10 apps folder\n$ git clone git@github.com:owncloud/openidconnect.git $ cd openidconnect $ composer install After enabling the app configure it in config/oidc.config.php\n$CONFIG = [ \u0026#39;openid-connect\u0026#39; =\u0026gt; [ \u0026#39;provider-url\u0026#39; =\u0026gt; \u0026#39;https://192.168.1.100:9130\u0026#39;, \u0026#39;client-id\u0026#39; =\u0026gt; \u0026#39;ocis\u0026#39;, \u0026#39;loginButtonName\u0026#39; =\u0026gt; \u0026#39;OpenId Connect @ Konnectd\u0026#39;, ], \u0026#39;debug\u0026#39; =\u0026gt; true, // if using self signed certificates // allow the different domains access to the ocs and wabdav endpoints: \u0026#39;cors.allowed-domains\u0026#39; =\u0026gt; [ \u0026#39;https://cloud.example.com\u0026#39;, \u0026#39;http://localhost:9100\u0026#39;, ], ]; In the above configuration replace\n provider-url with the URL to your ocis-konnectd issuer https://cloud.example.com with the URL to your ownCloud 10 instance http://localhost:9100 with the URL to your phoenix instance   Note: By default the openidconnect app will use the email of the user to match the user from the oidc userinfo endpoint with the ownCloud account. So make sure your users have a unique primary email.\n Next steps Aside from the above todos these are the next stepo\n tie it all together behind ocis-proxy create an ocis bridge command that runs all the ocis services in one step with a properly preconfigured ocis-konnectd identifier-registration.yaml file for phoenix and the owncloud 10 openidconnect app, as well as a randomized --signing-kid.  "});index.add({'id':43,'href':'/ocis/development/building/','title':"Build ocis",'content':"Build requirements All required tools besides go and make are bundled or getting automatically installed within the GOPATH. All commands to build this project are part of our Makefile.\nThe installation of Go is out of the scope of this document, please follow the official documentation for Go, to build this project you have to install Go \u0026gt;= v1.13.\nGet the sources git clone https://github.com/owncloud/ocis.git cd ocis Build the ocis binary The ocis binary source is in the ocis/ocis folder. In this folder you can build the ocis binary:\nmake generate make build Finally, you should have the binary within the bin/ folder now, give it a try with ./bin/ocis -h to see all available options.\nBuild a local ocis docker image If you are developing on a local branch based on docker / docker-compose setup, here is how to build a new ocis image. In the root folder:\ndocker build -t owncloud/ocis:dev . Then you can test as usual via\ndocker run --rm -ti owncloud/ocis:dev "});index.add({'id':44,'href':'/ocis/eos/','title':"EOS",'content':"    Docker dev environment for eos storage  1. Start eos \u0026amp; ocis containers 2. LDAP support 3. Home storage 4. Home data provider   Verification Further exploration Cleaning up Troubleshooting  Docker-compose exits right away Where are the logs ? How do I update a service in the ocis container? Creation and upload of files does not work Uploading big files appears to hang Running out of space quickly       OCIS can be configured to run on top of eos. While the eos documentation does cover a lot of topics it leaves out some details that you may have to either pull from various docker containers, the forums or even the source itself.\nThis document is a work in progress of the current setup.\nDocker dev environment for eos storage We begin with the docker-compose.yml found in https://github.com/owncloud/ocis/ and switch it to eos-storage.\n1. Start eos \u0026amp; ocis containers Start the eos cluster and ocis via the compose stack.\ndocker-compose up -d The first time the ocis container starts up, it will compile ocis from scratch which can take a while. To follow progress, run docker-compose logs -f --tail=10 ocis  2. LDAP support Configure the OS to resolve users and groups using ldap\ndocker-compose exec -d ocis /start-ldap Check that the OS in the ocis container can now resolve einstein or the other demo users\n$ docker-compose exec ocis id einstein uid=20000(einstein) gid=30000(users) groups=30000(users),30001(sailing-lovers),30002(violin-haters),30007(physics-lovers) If the user is not found at first you might need to wait a few more minutes in case the ocis container is still compiling.  We also need to restart the reva-users service so it picks up the changed environment. Without a restart it is not able to resolve users from LDAP.\ndocker-compose exec ocis ./bin/ocis kill reva-users docker-compose exec ocis ./bin/ocis run reva-users 3. Home storage Kill the home storage. By default it uses the owncloud storage driver. We need to switch it to the eoshome driver and make it use the storage id of the eos storage provider:\ndocker-compose exec ocis ./bin/ocis kill reva-storage-home docker-compose exec -e REVA_STORAGE_HOME_DRIVER=eoshome -e REVA_STORAGE_HOME_MOUNT_ID=1284d238-aa92-42ce-bdc4-0b0000009158 ocis ./bin/ocis run reva-storage-home 4. Home data provider Kill the home data provider. By default it uses the owncloud storage driver. We need to switch it to the eoshome driver and make it use the storage id of the eos storage provider:\ndocker-compose exec ocis ./bin/ocis kill reva-storage-home-data docker-compose exec -e REVA_STORAGE_HOME_DATA_DRIVER=eoshome ocis ./bin/ocis run reva-storage-home-data The difference between the home storage and the home data provider are that the former is responsible for metadata changes while the latter is responsible for actual data transfer. The home storage uses the cs3 api to manage a folder hierarchy, while the home data provider is responsible for moving bytes to and from the storage.  Verification Login with einstein / relativity, upload a file to einsteins home and verify the file is there using\ndocker-compose exec ocis eos ls -l /eos/dockertest/reva/users/4/4c510ada-c86b-4815-8820-42cdf82c3d51/ -rw-r--r-- 1 einstein users 10 Jul 1 15:24 newfile.txt If the problem persists, please check the troubleshooting section about uploads.\nFurther exploration EOS has a built in shell that you can enter using\n$ docker-compose exec mgm-master eos # --------------------------------------------------------------------------- # EOS Copyright (C) 2011-2019 CERN/Switzerland # This program comes with ABSOLUTELY NO WARRANTY; for details type `license\u0026#39;. # This is free software, and you are welcome to redistribute it # under certain conditions; type `license\u0026#39; for details. # --------------------------------------------------------------------------- EOS_INSTANCE=eostest EOS_SERVER_VERSION=4.6.5 EOS_SERVER_RELEASE=1 EOS_CLIENT_VERSION=4.6.5 EOS_CLIENT_RELEASE=1 EOS Console [root://localhost] |/\u0026gt; help access Access Interface accounting Accounting Interface acl Acl Interface archive Archive Interface attr Attribute Interface backup Backup Interface clear Clear the terminal cd Change directory chmod Mode Interface chown Chown Interface config Configuration System console Run Error Console cp Cp command debug Set debug level exit Exit from EOS console file File Handling fileinfo File Information find Find files/directories newfind Find files/directories (new implementation) fs File System configuration fsck File System Consistency Checking fuse Fuse Mounting fusex Fuse(x) Administration geosched Geoscheduler Interface group Group configuration health Health information about system help Display this text info Retrieve file or directory information inspector Interact with File Inspector io IO Interface json Toggle JSON output flag for stdout license Display Software License ls List a directory ln Create a symbolic link map Path mapping interface member Check Egroup membership mkdir Create a directory motd Message of the day mv Rename file or directory node Node configuration ns Namespace Interface pwd Print working directory quit Exit from EOS console quota Quota System configuration reconnect Forces a re-authentication of the shell recycle Recycle Bin Functionality rmdir Remove a directory rm Remove a file role Set the client role route Routing interface rtlog Get realtime log output from mgm \u0026amp; fst servers silent Toggle silent flag for stdout space Space configuration stagerrm Remove disk replicas of a file if it has tape replicas stat Run \u0026#39;stat\u0026#39; on a file or directory squash Run \u0026#39;squashfs\u0026#39; utility function test Run performance test timing Toggle timing flag for execution time measurement touch Touch a file token Token interface tracker Interact with File Tracker transfer Transfer Interface version Verbose client/server version vid Virtual ID System Configuration whoami Determine how we are mapped on server side who Statistics about connected users ? Synonym for \u0026#39;help\u0026#39; .q Exit from EOS console EOS Console [root://localhost] |/\u0026gt; But this is a different adventure. See the links at the top of this page for other sources of information on eos.\nCleaning up To clean up and start completely from scratch, run docker-compose down -v. Then delete the local \u0026ldquo;bin\u0026rdquo; folder as root which contains the ocis binaries compiled by the \u0026ldquo;ocis\u0026rdquo; docker.\nTroubleshooting Docker-compose exits right away When running docker-compose up -d ocis exits right away.\nYou can check the error code using docker-compose ps and investigate further by running only ocis again using docker-compose up ocis (without -d so you can see what is going on in the foreground). One reason might be that the binary was already built but does not match the container env. Try running make clean before running docker-compose up ocis so it gets built inside the container.\nWhere are the logs ? The ocis logs can be accessed using docker-compose logs ocis. Add -f for following.\nHow do I update a service in the ocis container?  docker-compose exec ocis make clean build to update the binary docker-compose exec ocis ./bin/ocis kill \u0026lt;service\u0026gt; to kill the service docker-compose exec ocis ./bin/ocis run \u0026lt;service\u0026gt; to start the service. Do not forget to set any env vars, eg. docker-compose exec -e REVA_STORAGE_EOS_LAYOUT=\u0026quot;{{substr 0 1 .Id.OpaqueId}}/{{.Id.OpaqueId}}\u0026quot; -e REVA_STORAGE_HOME_DRIVER=eoshome ocis ./bin/ocis run reva-storage-home  Creation and upload of files does not work If the upload did not work, please check the status of the eos space using the command docker-compose exec mgm-master eos fs ls. In case the default space appears as offline, run docker-compose exec mgm-master eos space set default on.\nUploading big files appears to hang Please note that the uploads first go into the \u0026ldquo;ocis\u0026rdquo; docker and land in its \u0026ldquo;/tmp\u0026rdquo; folder, then gets copied over to the EOS docker using xrdcopy. This is why uploading first transfers all bytes and then seem to hang for a while during the final copy.\nRunning out of space quickly The EOS dockers are configured with replication, so every file uploaded there will be replicated 4 times, so make sure there is enough physical space on disk when testing.\nAlso please note that older failed uploads might still be present in the \u0026ldquo;/tmp\u0026rdquo; directory of the \u0026ldquo;ocis\u0026rdquo; container.\n"});index.add({'id':45,'href':'/extensions/konnectd/building/','title':"Building",'content':"    Backend     As this project is built with Go, so you need to install that first. The installation of Go is out of the scope of this document, please follow the official documentation for Go, to build this project you have to install Go \u0026gt;= v1.13. After the installation of the required tools you need to get the sources:\ngit clone https://github.com/owncloud/ocis-konnectd.git cd ocis-konnectd All required tool besides Go itself and make are bundled or getting automatically installed within the GOPATH. All commands to build this project are part of our Makefile.\nBackend make generate make build Finally you should have the binary within the bin/ folder now, give it a try with ./bin/ocis-konnectd -h to see all available options and subcommands.\n"});index.add({'id':46,'href':'/extensions/accounts/building/','title':"Building",'content':"    Backend     As this project is built with Go, so you need to install that first. The installation of Go is out of the scope of this document, please follow the official documentation for Go, to build this project you have to install Go \u0026gt;= v1.13. After the installation of the required tools you need to get the sources:\ngit clone https://github.com/owncloud/ocis-accounts.git cd ocis-accounts All required tool besides Go itself and make are bundled or getting automatically installed within the GOPATH. All commands to build this project are part of our Makefile.\nBackend make generate make build Finally you should have the binary within the bin/ folder now, give it a try with ./bin/ocis-accounts -h to see all available options and subcommands.\n"});index.add({'id':47,'href':'/extensions/glauth/building/','title':"Building",'content':"    Backend     As this project is built with Go, so you need to install that first. The installation of Go is out of the scope of this document, please follow the official documentation for Go, to build this project you have to install Go \u0026gt;= v1.13. After the installation of the required tools you need to get the sources:\ngit clone https://github.com/owncloud/ocis-glauth.git cd ocis-glauth All required tool besides Go itself and make are bundled or getting automatically installed within the GOPATH. All commands to build this project are part of our Makefile.\nBackend make generate make build Finally you should have the binary within the bin/ folder now, give it a try with ./bin/ocis-glauth -h to see all available options.\n"});index.add({'id':48,'href':'/extensions/ocis-phoenix/building/','title':"Building",'content':"Backend cd ocis-phoenix make generate make build The above commands will download a Phoenix release and embed it into the binary. Finally you should have the binary within the bin/ folder now, give it a try with ./bin/ocis-phoenix -h to see all available options.\n"});index.add({'id':49,'href':'/extensions/ocs/building/','title':"Building",'content':"    Backend     As this project is built with Go, so you need to install that first. The installation of Go is out of the scope of this document, please follow the official documentation for Go, to build this project you have to install Go \u0026gt;= v1.12. After the installation of the required tools you need to get the sources:\ngit clone https://github.com/owncloud/ocis-ocs.git cd ocis-ocs All required tool besides Go itself and make are bundled or getting automatically installed within the GOPATH. All commands to build this project are part of our Makefile.\nBackend make generate make build Finally you should have the binary within the bin/ folder now, give it a try with ./bin/ocis-ocs -h to see all available options.\n"});index.add({'id':50,'href':'/extensions/proxy/building/','title':"Building",'content':"    Backend     As this project is built with Go, so you need to install that first. The installation of Go is out of the scope of this document, please follow the official documentation for Go, to build this project you have to install Go \u0026gt;= v1.13. After the installation of the required tools you need to get the sources:\ngit clone https://github.com/owncloud/ocis-proxy.git cd ocis-proxy All required tool besides Go itself and make are bundled or getting automatically installed within the GOPATH. All commands to build this project are part of our Makefile.\nBackend make generate make build Finally you should have the binary within the bin/ folder now, give it a try with ./bin/ocis-proxy -h to see all available options and subcommands.\n"});index.add({'id':51,'href':'/extensions/settings/building/','title':"Building",'content':"    Backend     As this project is built with Go, so you need to install that first. The installation of Go is out of the scope of this document, please follow the official documentation for Go, to build this project you have to install Go \u0026gt;= v1.12. After the installation of the required tools you need to get the sources:\ngit clone https://github.com/owncloud/ocis-settings.git cd ocis-settings All required tool besides Go itself and make are bundled or getting automatically installed within the GOPATH. All commands to build this project are part of our Makefile.\nBackend make generate make build Finally you should have the binary within the bin/ folder now, give it a try with ./bin/ocis-settings -h to see all available options.\n"});index.add({'id':52,'href':'/extensions/storage/building/','title':"Building",'content':"As this project is built with Go, so you need to install that first. The installation of Go is out of the scope of this document, please follow the official documentation for Go.To build this project you have to install Go \u0026gt;= v1.13. After the installation of the required tools you need to get the sources:\ngit clone https://github.com/owncloud/ocis.git cd ocis/storage All required tool besides Go itself and make are bundled or getting automatically installed within the GOPATH. All commands to build this project are part of our Makefile.\nBackend make build The above command should produce the binary within the bin/ folder now, give it a try with ./bin/ocis-reva -h to see all available options.\n"});index.add({'id':53,'href':'/extensions/store/building/','title':"Building",'content':"    Backend     As this project is built with Go, so you need to install that first. The installation of Go is out of the scope of this document, please follow the official documentation for Go, to build this project you have to install Go \u0026gt;= v1.12. After the installation of the required tools you need to get the sources:\ngit clone https://github.com/owncloud/ocis-store.git cd ocis-store All required tool besides Go itself and make are bundled or getting automatically installed within the GOPATH. All commands to build this project are part of our Makefile.\nBackend make generate make build Finally you should have the binary within the bin/ folder now, give it a try with ./bin/ocis-store -h to see all available options.\n"});index.add({'id':54,'href':'/extensions/thumbnails/building/','title':"Building",'content':"    Backend     As this project is built with Go, so you need to install that first. The installation of Go is out of the scope of this document, please follow the official documentation for Go, to build this project you have to install Go \u0026gt;= v1.12. After the installation of the required tools you need to get the sources:\ngit clone https://github.com/owncloud/ocis-thubnails.git cd {{ Name }} All required tool besides Go itself and make are bundled or getting automatically installed within the Gopath. All commands to build this project are part of our Makefile.\nBackend make generate make build Finally you should have the binary within the bin/ folder now, give it a try with ./bin/ocis-thumbnails -h to see all available options.\n"});index.add({'id':55,'href':'/extensions/webdav/building/','title':"Building",'content':"      Backend       As this project is built with Go, so you need to install that first. The installation of Go is out of the scope of this document, please follow the official documentation for Go, to build this project you have to install Go \u0026gt;= v1.12. After the installation of the required tools you need to get the sources:\ngit clone https://github.com/owncloud/ocis-webdav.git cd ocis-webdav All required tool besides Go itself and make are bundled or getting automatically installed within the GOPATH. All commands to build this project are part of our Makefile.\nBackend make generate make build Finally you should have the binary within the bin/ folder now, give it a try with ./bin/ocis-webdav -h to see all available options.\n"});index.add({'id':56,'href':'/extensions/storage/users/','title':"Users",'content':"Demo driver This is a simple user driver for testing. It contains three users:\neinstein:relativity marie:radioactivty richard:superfluidity In order to use the demo driver you need to export the relevant environment variable:\nexport STORAGE_USERS_DRIVER=demo JSON driver In order to switch from the ldap driver to JSON based users you need to export the relevant environment variables:\nexport STORAGE_USERS_DRIVER=json export STORAGE_USERS_JSON=/path/to/users.json For the format of the users.json have a look at the reva examples\nLDAP driver This is the default user driver.\nIf the below defaults don\u0026rsquo;t match your environment change them accordingly:\nexport STORAGE_LDAP_HOSTNAME=localhost export STORAGE_LDAP_PORT=9126 export STORAGE_LDAP_BASE_DN=\u0026#39;dc=example,dc=org\u0026#39; export STORAGE_LDAP_USERFILTER=\u0026#39;(\u0026amp;(objectclass=posixAccount)(cn=%s))\u0026#39; export STORAGE_LDAP_GROUPFILTER=\u0026#39;(\u0026amp;(objectclass=posixGroup)(cn=%s))\u0026#39; export STORAGE_LDAP_BIND_DN=\u0026#39;cn=reva,ou=sysusers,dc=example,dc=org\u0026#39; export STORAGE_LDAP_BIND_PASSWORD=reva export STORAGE_LDAP_SCHEMA_UID=uid export STORAGE_LDAP_SCHEMA_MAIL=mail export STORAGE_LDAP_SCHEMA_DISPLAYNAME=sn export STORAGE_LDAP_SCHEMA_CN=cn Then restart the bin/storage users and bin/storage auth-basic services for the changes to take effect.\n"});index.add({'id':57,'href':'/extensions/storage/storages/','title':"Storages",'content':"Storage commands storage has multiple storage provider commands to preconfigure different default configurations for the reva storage provider service. While you could rerun storage storage-oc multiple times with different flags to get multiple instances we are giving the different commands the necessary default configuration to allow the ocis binary to simply start them and not deal with configuration.\nStorage providers To manage the file tree ocis uses storage storage providers that are accessing the underlying storage using a storage driver. The driver can be used to change the implementation of a storage aspect to better reflect the actual underlying storage capabilities. As an example a move operation on a POSIX filesystem (theoretically) is an atomic operation. When trying to implement a file tree on top of S3 there is no native move operation that can be used. A naive implementation might fall back on a COPY and DELETE. Some S3 implementations provide a COPY operation that uses an existing key as the source, so the file at least does not need to be reuploaded. In the worst case scenario, which is renaming a folder with hundreds of thousands of objects, a reupload for every file has to be made. Instead of hiding this complexity a better choice might be to disable renaming of files or at least folders on S3. There are however implementations of filesystems on top of S3 that store the tree metadata in dedicated objects or use a completely different persistence mechanism like a distributed key value store to implement the file tree aspect of a storage.\nWhile the storage provider is responsible for managing the tree, file up and download is delegated to a dedicated data provider. See below.  Storage aspects A lot of different storage technologies exist, ranging from general purpose file systems with POSIX semantics to software defined storage with multiple APIs. Choosing any of them is making a tradeoff decision. Or, if a storage technology is already in place it automatically predetermines the capabilities that can be made available. Not all storage systems are created equal.\nUnfortunately, no POSIX filesystem natively supports all storage aspects that ownCloud 10 requires:\nA hierarchical file tree An important aspect of a filesystem is organizing files and directories in a file hierarchy, or tree. It allows you to create, move and delete nodes. Beside the name a node also has well known metadata like size and mtime that are persisted in the tree as well.\nFolders are not directories There is a difference between folder and directory: a directory is a file system concept. A folder is a metaphor for the concept of a physical file folder. There are also virtual folders or smart folders like the recent files folder which are no file system directories. So, every directory and every virtual folder is a folder, but not every folder is a directory. See the folder metaphor in wikipedia. Also see the activity history below.  Id based lookup While traditionally nodes in the tree are reached by traversing the path the tree persistence should be prepared to look up a node by an id. Think of an inode in a POSIX filesystem. If this operation needs to be cached for performance reasons keep in mind that cache invalidation is hard and crawling all files to update the inode to path mapping takes O(n), not O(1).\nETag propagation For the state based sync a client can discover changes by recursively descending the tree and comparing the ETag for every node. If the storage technology supports propagating ETag changes up the tree, only the root node of a tree needs to be checked to determine if a discovery needs to be started and which nodes need to be traversed. This allows using the storage technology itself to persist all metadata that is necessary for sync, without additional services or caches.\nSubtree size accounting The tree can keep track of how many bytes are stored in a folder. Similar to ETag propagation a change in file size is propagated up the hierarchy.\nETag and Size propagation When propagating the ETag (mtime) and size changes up the tree the question is where to stop. If all changes need to be propagated to the root of a storage then the root or busy folders will become a hotspot. There are two things to keep in mind: 1. propagation only happens up to the root of a single space (a user private drive or a single group drive), 2. no cross storage propagation. The latter was used in oc10 to let clients detect when a file in a received shared folder changed. This functionality is moving to the storage registry which caches the ETag for every root so clients can discover if and which storage changed.  Rename Depending on the underlying storage technology some operations may either be slow, up to a point where it makes more sense to disable them entirely. One example is a folder rename: on S3 a simple folder rename translates to a copy and delete operation for every child of the renamed folder. There is an exception though: this restriction only applies if the S3 storage is treated like a filesystem, where the keys are the path and the value is the file content. There are smarter ways to implement file systems on top of S3, but again: there is always a tradeoff.\nS3 has no rename Technically, S3 has no rename operation at all. By design, the location of the value is determined by the key, so it always has to do a copy and delete. Another example is the redis RENAME operation: while being specified as O(1) it executes an implicit DEL operation, so if the deleted key contains a very big value it may cause high latency\u0026hellip;  Arbitrary metadata persistence In addition to well known metadata like name size and mtime, users might be able to add arbitrary metadata like tags, comments or dublin core. In POSIX filesystems this maps to extended attributes.\nGrant persistence The CS3 API uses grants to describe access permissions. Storage systems have a wide range of permissions granularity and not all grants may be supported by every storage driver. POSIX ACLs for example have no expiry. If the storage system does not support certain grant properties, e.g. expiry, then the storage driver may choose to implement them in a different way. Expiries could be persisted in a different way and checked periodically to remove the grants. Again: every decision is a tradeoff.\nTrash persistence After deleting a node the storage allows listing the deleted nodes and has an undo mechanism for them.\nVersions persistence A user can restore a previous version of a file.\nSnapshots are not versions Modern POSIX filesystems support snapshotting of volumes. This is different from keeping track of versions to a file or folder, but might be another implementation strategy for a storage driver to allow users to restore content.  Activity History The storage keeps an activity history, tracking the different actions that have been performed. This does not only include file changes but also metadata changes like renames and permission changes.\nStorage drivers Reva currently has four storage driver implementations that can be used for storage providers an well as data providers.\nLocal Storage Driver The minimal storage driver for a POSIX based filesystem. It literally supports none of the storage aspect other than basic file tree management. Sharing can - to a degree - be implemented using POSIX ACLs.\n tree provided by a POSIX filesystem  inefficient path by id lookup, currently uses the file path as id, so ids are not stable  can store a uuid in extended attributes and use a cache to look them up, similar to the ownCloud driver   no native ETag propagation, five options are available:  built in propagation (changes bypassing ocis are not picked up until a rescan) built in inotify (requires 48 bytes of RAM per file, needs to keep track of every file and folder) external inotify (same RAM requirement, but could be triggered by external tools, e.g. a workflow engine) kernel audit log (use the linux kernel audit to capture file events on the storage and offload them to a queue) fuse filesystem overlay   no subtree accounting, same options as for ETag propagation efficient rename arbitrary metadata using extended attributes   grant persistence  using POSIX ACLs  requires an LDAP server to make guest accounts available in the OS  OCIS has glauth which contains all users an existing LDAP could be used if guests ar provisioned in another way     using extended attributes to implement expiry or sharing that does not require OS level integration fuse filesystem overlay   no native trash  could use the The FreeDesktop.org Trash specification fuse filesystem overlay   no native versions, multiple options possible  git for folders rcs for single files rsnapshot for hourly / daily / weekly / monthly backups \u0026hellip; but this is not versioning as known from oc10 design new freedesktop spec, basically what is done in oc10 without the limitations or borrow ideas from the freedesktop trash spec fuse filesystem overlay    To provide the other storage aspects we plan to implement a FUSE overlay filesystem which will add the different aspects on top of local filesystems like ext4, btrfs or xfs. It should work on NFSv45 as well, although NFSv4 supports RichACLs and we will explore how to leverage them to implement sharing at a future date. The idea is to use the storages native capabilities to deliver the best user experience. But again: that means making the right tradeoffs.\nOwnCloud Storage Driver This is the current default storage driver. While it implements the file tree (using redis, including id based lookup), ETag propagation, trash, versions and sharing (including expiry) using the data directory layout of ownCloud 10 it has known limitations that cannot be fixed without changing the actual layout on disk.\nTo setup it up properly in a distributed fashion, the storage-home and the storage-oc need to share the same underlying FS. Their \u0026ldquo;data\u0026rdquo; counterparts also need access to the same shared FS. For a simple docker-compose setup, you can create a volume which will be used by the \u0026ldquo;storage-storage-home\u0026rdquo;, \u0026ldquo;storage-storage-home-data\u0026rdquo;, \u0026ldquo;storage-storage-oc\u0026rdquo; and \u0026ldquo;storage-storage-oc-data\u0026rdquo; containers. Using the owncloud/ocis docker image, the volume would need to be hooked in the /var/tmp/ocis folder insde the containers.\n tree provided by a POSIX filesystem  file layout is mapped to the old ownCloud 10 layout  the root of tree for a user on disk is prefixed with /path/to/data/\u0026lt;username\u0026gt;/files/   efficient path by id lookup  all files and folders get assigned a uuid in the extended attributes when starting the storage provider it will walk all files to populate a redis kv store for uuid to path lookup slow to boot trees with lots of nodes   build in ETag propagation  ETags are calculated based on mtime mtime is propagated by the storage driver changes bypassing ocis are not picked up until a restart of the storage provider   no subtree accounting, same options as for local storage efficient rename  TODO update the kv store for path lookup, this is an O(n) operation   arbitrary metadata using extended attributes   grant persistence  using custom ACLs that are stored as extended attributes  a grant corresponds to one extended attribute of 40-100 bytes, effectively limiting the number of shares to ~100-40 extended attributes have varying limitations, based on the underlying filesystem  the linux kernel imposes a limit of 255bytes per name and 64KiB per value ext2/3/4: total bytes for all attributes of a file is limited to 4KiB (a filesystem block) xfs: limit of 64KiB per value btrfs: total bytes used for the name, value, and implementation overhead bytes 16KiB (the default filesystem nodesize value)     does not require OS level integration   built in trash  trashed files are moved to /path/to/data/\u0026lt;username\u0026gt;/files_trashbin/ trashed files are appended a timestamp .d\u0026lt;unixtime\u0026gt;, which breaks trashing of files that reach the filesystems specific name limit   built in versions  file versions are stored in /path/to/data/\u0026lt;username\u0026gt;/files_versions/ file versions are appended a timestamp .d\u0026lt;unixtime\u0026gt;, which breaks versioning of files that reach the filesystems specific name limit    EOS Storage Driver The CERN eos storage has evolved with ownCloud and natively supports id based lookup, ETag propagation, subtree size accounting, sharing, trash and versions. To use it you need to change the default configuration of the storage storage-home command (or have a look at the Makefile ÃÄ eos-start` target):\nexport STORAGE_STORAGE_HOME_DRIVER=eos export STORAGE_STORAGE_EOS_NAMESPACE=/eos export STORAGE_STORAGE_EOS_MASTER_URL=\u0026#34;root://eos-mgm1.eoscluster.cern.ch:1094\u0026#34; export STORAGE_STORAGE_EOS_ENABLE_HOME=true export STORAGE_STORAGE_EOS_LAYOUT=\u0026#34;dockertest/{{.Username}}\u0026#34; Running it locally also requires the eos and xrootd binaries. Running it using make eos-start will use CentOS based containers that already have the necessary packages installed.\nPull requests to add explicit storage storage-(s3|custom|...) commands with working defaults are welcome.  S3 Storage Driver A naive driver that treats the keys in an S3 capable storage as / delimited path names. While it does not support MOVE or ETag propagation it can be used to read and write files. Better integration with native capabilities like versioning is possible but depends on the Use Case. Several storage solutions that provide an S3 interface also support some form of notifications that can be used to implement ETag propagation.\nData Providers Clients using the CS3 API use an InitiateFileDownload and ]InitiateUpload](https://cs3org.github.io/cs3apis/#cs3.storage.provider.v1beta1.InitiateFileUploadRequest) request at the storage gateway to obtain a URL endpoint that can be used to either GET the file content or upload content using the resumable tus.io protocol.\nThe data provider uses the same storage driver as the storage provider but can be scaled independently.\nThe dataprovider allows uploading the file to a quarantine area where further data analysis may happen before making the file accessible again. One use case for this is anti virus scanning for files coming from untrusted sources.\nFuture work FUSE overlay filesystem We are planning to further separate the concerns and use a local storage provider with a FUSE filesystem overlaying the actual POSIX storage that can be used to capture deletes and writes that might happen outside of ocis/reva.\nIt would allow us to extend the local storage driver with missing storage aspects while keeping a tree like filesystem that end users are used to see when sshing into the machine.\nUpload to Quarantine area Antivirus scanning of random files uploaded from untrusted sources and executing metadata extraction or thumbnail generation should happen in a sandboxed system to prevent malicious users from gaining any information about the system. By spawning a new container with access to only the uploaded data we can further limit the attack surface.\n"});index.add({'id':58,'href':'/extensions/storage/testing/','title':"Testing",'content':"API Acceptance tests We are using the ownCloud 10 API acceptance testsuite against ocis. To set this up you need the owncloud 10 core repo, a ldap server that the acceptance tests can use to manage users, a redis server for file-versions and the ocis-reva code.\nGetting the tests All you need to do to get the acceptance tests is check out the core repo:\ngit clone https://github.com/owncloud/core.git Run a ldap server in a docker container The ownCloud 10 acceptance tests will need write permission. You can start a suitable ldap server in a docker container with:\ndocker run --hostname ldap.my-company.com \\ -e LDAP_TLS_VERIFY_CLIENT=never \\ -e LDAP_DOMAIN=owncloud.com \\ -e LDAP_ORGANISATION=ownCloud \\ -e LDAP_ADMIN_PASSWORD=admin \\ --name docker-slapd \\ -p 127.0.0.1:389:389 \\ -p 636:636 -d osixia/openldap Run a redis server in a docker container File versions need a redis server. Start one with docker by using:\ndocker run -e REDIS_DATABASES=1 -p 6379:6379 -d webhippie/redis:latest\nRun ocis-reva with that ldap server storage provides multiple subcommands. To configure them all via env vars you can export these environment variables.\nexport STORAGE_USERS_DRIVER=ldap export STORAGE_LDAP_HOSTNAME=localhost export STORAGE_LDAP_PORT=636 export STORAGE_LDAP_BASE_DN=\u0026#39;dc=owncloud,dc=com\u0026#39; export STORAGE_LDAP_USERFILTER=\u0026#39;(\u0026amp;(objectclass=posixAccount)(cn=%s))\u0026#39; export STORAGE_LDAP_GROUPFILTER=\u0026#39;(\u0026amp;(objectclass=posixGroup)(cn=%s))\u0026#39; export STORAGE_LDAP_BIND_DN=\u0026#39;cn=admin,dc=owncloud,dc=com\u0026#39; export STORAGE_LDAP_BIND_PASSWORD=admin export STORAGE_LDAP_SCHEMA_UID=uid export STORAGE_LDAP_SCHEMA_MAIL=mail export STORAGE_LDAP_SCHEMA_DISPLAYNAME=displayName export STORAGE_LDAP_SCHEMA_CN=cn export STORAGE_FRONTEND_URL=http://localhost:9140 # needed because the proxy is not started export STORAGE_DATAGATEWAY_URL=http://localhost:9140/data # needed because the proxy is not started Then you need to start the ocis-reva services\nbin/storage frontend \u0026amp; \\ bin/storage gateway \u0026amp; \\ bin/storage auth-basic \u0026amp; \\ bin/storage auth-bearer \u0026amp; \\ bin/storage sharing \u0026amp; \\ bin/storage storage-home \u0026amp; \\ bin/storage storage-home-data \u0026amp; \\ bin/storage storage-oc \u0026amp; \\ bin/storage storage-oc-data \u0026amp; \\ bin/storage users \u0026amp; Run the API acceptance tests In the ownCloud 10 core repo run\nmake test-acceptance-api \\ TEST_SERVER_URL=http://localhost:9140 \\ TEST_EXTERNAL_USER_BACKENDS=true \\ TEST_OCIS=true \\ OCIS_REVA_DATA_ROOT=/var/tmp/reva/ \\ BEHAT_FILTER_TAGS=\u0026#39;~@notToImplementOnOCIS\u0026amp;\u0026amp;~@toImplementOnOCIS\u0026amp;\u0026amp;~@preview-extension-required\u0026#39; \\ SKELETON_DIR=apps/testing/data/apiSkeleton Make sure to adjust the settings TEST_SERVER_URL,OCIS_REVA_DATA_ROOT and SKELETON_DIR according to your environment.\nThis will run all tests that are relevant to OCIS.\nTo run a single test add BEHAT_FEATURE=\u0026lt;feature file\u0026gt; and specify the path to the feature file and an optional line number. For example: BEHAT_FEATURE='tests/acceptance/features/apiWebdavUpload1/uploadFile.feature:12'\nuse existing tests for BDD As a lot of scenarios are written for oC10, we can use those tests for Behaviour driven development in ocis. Every scenario that does not work in OCIS with OC storage, is listed in tests/acceptance/expected-failures-on-OC-storage.txt with a link to the related issue. Similarly, scenarios that do not work in OCIS with EOS storage are listed in tests/acceptance/expected-failures-on-EOS-storage.txt. Scenarios from the oC10 API acceptance tests are run in the ordinary acceptance test pipeline in CI. The scenarios that fail are checked against the expected failures. If there are any differences then the CI pipeline fails.\nAdditionally, some issues have scenarios that demonstrate the current buggy behaviour in ocis(reva). Those scenarios are in this ocis-reva repository in tests/acceptance/features/apiOcisSpecific. Have a look into the documentation to understand why we are writing those tests. Also, ocis behaves partly differently with EOS-Storage and OC-Storage. There are scenarios that do not work in OCIS when run on EOS-storage, but works when on OC-Storage, and vice-versa. For those kind of scenarios,  @skipOnOcis-EOS-Storage and @skipOnOcis-OC-Storage tags are used. For instance, for a scenario that fails on EOS-Storage but passes on OC-Storage, we use @skipOnOcis-EOS-Storage tag to let it run on OC-Storage, where it works as expected, instead of skipping the test completely.\nIf you want to work on a specific issue\n  adjust the core commit id to the latest commit in core so that CI will run the latest test code and scenarios from core. For that change coreCommit in the config section:\nconfig = { 'apiTests': { 'coreBranch': 'master', 'coreCommit': 'a06b1bd5ba8e5244bfaf7fa04f441961e6fb0daa', 'numberOfParts': 2 } }    locally run each of the tests marked with that issue in the expected failures file:\nE.g.:\nmake test-acceptance-api \\ TEST_SERVER_URL=http://localhost:9140 \\ TEST_EXTERNAL_USER_BACKENDS=true \\ TEST_OCIS=true \\ OCIS_REVA_DATA_ROOT=/var/tmp/reva/ \\ BEHAT_FEATURE=\u0026#39;tests/acceptance/features/apiComments/comments.feature:123\u0026#39;   the tests will fail, try to understand how and why they are failing\n  fix the code\n  go back to 2. and repeat till the tests are passing.\n  remove those tests from the expected failures file.\n  run each of the local tests that were demonstrating the buggy behavior. They should fail.\n  delete each of the local tests that were demonstrating the buggy behavior.\n  make a PR that has the fixed code, relevant lines removed from the expected failures file and bug demonstration tests deleted.\nIf the changes also affect the ocis repository make sure the changes get ported over there. That will need the fixed code in storage to be applied to ocis along with the test-related changes.\n  Notes  in a normal case the test-code cleans up users after the test-run, but if a test-run is interrupted (e.g. by CTRL+C) users might have been left on the LDAP server. In that case rerunning the tests requires wiping the users in the ldap server, otherwise the tests will fail when trying to populate the users. This can be done by simply running docker stop docker-slapd \u0026amp;\u0026amp; docker rm docker-slapd and restarting the LDAP server container the tests usually create users in the OU TestUsers with usernames specified in the feature file. If not defined in the feature file, most users have the password 123456, defined by regularUserPassword in behat.yml, but other passwords are also used, see \\FeatureContext::getPasswordForUser() for mapping and \\FeatureContext::__construct for the password definitions.  "});index.add({'id':59,'href':'/ocis/development/testing/','title':"Testing",'content':"Acceptance tests We are using the ownCloud 10 acceptance testsuite against ocis. To set this up you need the owncloud 10 core repo, a ldap server that the acceptance tests can use to manage users, a redis server for file-versions and the ocis code.\nGetting the tests All you need to do to get the acceptance tests is check out the core repo:\ngit clone https://github.com/owncloud/core.git Run a redis server in a docker container File versions need a redis server. Start one with docker by using:\ndocker run -e REDIS_DATABASES=1 -p 6379:6379 -d webhippie/redis:latest\nRun ocis To start ocis:\nbin/ocis server Run the acceptance tests First we will need to clone the testing app in owncloud which contains the skeleton files required for running the tests. In the ownCloud 10 core clone the testing app with the following command:\ngit clone https://github.com/owncloud/testing apps/testing Then run the api acceptance tests with the following command:\nmake test-acceptance-api \\ TEST_SERVER_URL=https://localhost:9200 \\ TEST_OCIS=true \\ OCIS_REVA_DATA_ROOT=/var/tmp/reva/ \\ SKELETON_DIR=apps/testing/data/apiSkeleton \\ BEHAT_FILTER_TAGS=\u0026#39;~@notToImplementOnOCIS\u0026amp;\u0026amp;~@toImplementOnOCIS\u0026#39; Make sure to adjust the settings TEST_SERVER_URL and OCIS_REVA_DATA_ROOT according to your environment.\nThis will run all tests that are relevant to OCIS.\nTo run a single test add BEHAT_FEATURE=\u0026lt;feature file\u0026gt;\nuse existing tests for BDD As a lot of scenarios are written for oC10, we can use those tests for Behaviour driven development in ocis. Every scenario that does not work in OCIS with OC storage, is listed in tests/acceptance/expected-failures-on-OC-storage.txt with a link to the related issue.\nThose scenarios are run in the ordinary acceptance test pipeline in CI. The scenarios that fail are checked against the expected failures. If there are any differences then the CI pipeline fails. Similarly, scenarios that do not work in OCIS with EOS storage are listed in tests/acceptance/expected-failures-on-EOS-storage.txt. Additionally, some issues have scenarios that demonstrate the current buggy behaviour in ocis(reva). Those scenarios are in this ocis repository in tests/acceptance/features/apiOcisSpecific. Have a look into the documentation to understand why we are writing those tests.\nIf you want to work on a specific issue\n  adjust the core commit id to the latest commit in core so that CI will run the latest test code and scenarios from core. For that change coreCommit in the config section:\nconfig = { 'apiTests': { 'coreBranch': 'master', 'coreCommit': 'a06b1bd5ba8e5244bfaf7fa04f441961e6fb0daa', 'numberOfParts': 2 } }    locally run each of the tests marked with that issue in the expected failures file\nE.g.:\nmake test-acceptance-api \\ TEST_SERVER_URL=https://localhost:9200 \\ TEST_OCIS=true \\ OCIS_REVA_DATA_ROOT=/var/tmp/reva/ \\ BEHAT_FEATURE=\u0026#39;tests/acceptance/features/apiComments/comments.feature:123\u0026#39;   the tests will fail, try to understand how and why they are failing\n  fix the code\n  go back to 2. and repeat till the tests are passing.\n  remove those tests from the expected failures file\n  run each of the local tests that were demonstrating the buggy behavior. They should fail.\n  delete each of the local tests that were demonstrating the buggy behavior.\n  make a PR that has the fixed code, relevant lines removed from the expected failures file and bug demonstration tests deleted.\nIf the changes also affect the ocis-reva repository make sure the changes get ported over there.\n  Notes  in a normal case the test-code cleans up users after the test-run, but if a test-run is interrupted (e.g. by CTRL+C) users might have been left on the LDAP server. In that case rerunning the tests requires wiping the users in the ldap server, otherwise the tests will fail when trying to populate the users. the tests usually create users in the OU TestUsers with usernames specified in the feature file. If not defined in the feature file, most users have the password 123456, defined by regularUserPassword in behat.yml, but other passwords are also used, see \\FeatureContext::getPasswordForUser() for mapping and \\FeatureContext::__construct for the password definitions.  "});index.add({'id':60,'href':'/clients/web/backend-oc10/','title':"Setup with ownCloud 10",'content':"    Prerequisites Setting up the ownCloud Server  Adjusting config.php Setting up OAuth2 Setting up Phoenix   Running Phoenix Running acceptance tests     Prerequisites Decide on which host and port Phoenix will be served, for example https://phoenix-host:8300/phoenix-path/. In this document, we will refer to the following:\n \u0026lt;phoenix-url\u0026gt; as the full URL, for example https://phoenix-host:8300/phoenix-path/ \u0026lt;phoenix-domain\u0026gt; as the protocol, domain and port, for example: https://phoenix-host:8300  Setting up the ownCloud Server Make sure you have an ownCloud Server already installed.\nAdjusting config.php Add the following entries to config/config.php:\n tell ownCloud where Phoenix is located:  \u0026#39;phoenix.baseUrl\u0026#39; =\u0026gt; \u0026#39;\u0026lt;phoenix-url\u0026gt;\u0026#39;,  add a CORS domain entry for Phoenix in config.php:  \u0026#39;cors.allowed-domains\u0026#39; =\u0026gt; [\u0026#39;\u0026lt;phoenix-domain\u0026gt;\u0026#39;],  optional: when developing against unstable APIs (technical preview), these need to be enabled in the server core:  dav.enable.tech_preview =\u0026gt; true, Setting up OAuth2 To connect to the ownCloud server, it is necessary to set it up with OAuth2.\nInstall and enable the oauth2 app:\n% occ market:install oauth2 % occ app:enable oauth2 Login as administrator in the ownCloud Server web interface and go to the \u0026ldquo;User Authentication\u0026rdquo; section in the admin settings and add an entry for Phoenix as follows:\n pick an arbitrary name for the client set the redirection URI to \u0026lt;phoenix-url\u0026gt;/oidc-callback.html make sure to take note of the client identifier value as it will be needed in the Phoenix configuration later on  Setting up Phoenix In the local Phoenix checkout, copy the config.json.sample-oc10 file to config.json and adjust it accordingly:\n Set the \u0026ldquo;server\u0026rdquo; key to the URL of the ownCloud server including path. If the URL contains a path, please also add a trailing slash there. Set the \u0026ldquo;clientId\u0026rdquo; key to the client identifier as copied from the \u0026ldquo;User Authentication\u0026rdquo; section before. Adjust \u0026ldquo;url\u0026rdquo; and \u0026ldquo;authUrl\u0026rdquo; using the ownCloud server URL as prefix for both Optionally adjust \u0026ldquo;apps\u0026rdquo; for the list of apps to be loaded. These match the app names inside the \u0026ldquo;apps\u0026rdquo; folder.  Running Phoenix  if running from source, make sure to build Phoenix first run by launching a webpack dev server yarn watch-all when working on the Phoenix code, webpack will recompile the code automatically  Running acceptance tests For testing, please refer to the ownCloud 10 testing section\n"});index.add({'id':61,'href':'/ocis/extensions/','title':"Extension",'content':"    How to build and run ocis-simple Hacking ocis-hello  Option 1:   Hacking phoenix (and ocis-phoenix) The ownCloud design system External phoenix apps Phoenix extension points  Phoenix core Files app   API driven development     How to build and run ocis-simple ocis uses build tags to build different flavors of the binary. In order to work on a new extension we are going to reduce the scope a little and use the simple tag. Let us begin by creating a dedicated folder:\nmkdir ocis-extension-workshop \u0026amp;\u0026amp; ocis-extension-workshop Following https://github.com/owncloud/ocis\ngit clone https://github.com/owncloud/ocis.git cd ocis TAGS=simple make generate build Q: Can you specify which version of phoenix to use? A: No, the phoenix that is used is compiled into the assets of ocis-phoenix which is currently not automatically updated. We\u0026rsquo;ll see how to use a custom phoenix later.\nbin/ocis server\nOpen the browser at http://localhost:9100\n You land on the login screen. click login You are redirected to an idp at http://localhost:9140/oauth2/auth with a login mask. Use einstein:relativityto login (one of the three demo users) You are redirected to http://localhost:9100/#/hello the ocis-hello app Replace World with something else and submit. You should see Hello %something else%  Q: One of the required ports is already in use. Ocis seems to be trying to restart the service over and over. What gives? A: Using the ocis binary to start the server will case ocis to keep track of the different services and restart them in case they crash.\nHacking ocis-hello go back to the ocis-extension-workshop folder\ncd .. Following https://github.com/owncloud/ocis-hello\ngit clone https://github.com/owncloud/ocis-hello.git cd ocis-hello yarn install # this actually creates the assets yarn build # this will compile the assets into the binary make generate build Two options:\n run only the necessery services from ocis and ocis-hello independently compile ocis with the updated ocis-hello  Option 1: get a list of ocis services:\nps ax | grep ocis Try to kill ocis hello\nRemember: for now, killing a service will cause ocis to restart it. This is subject to change.\nIn order to be able to manage the processes ourselves we need to start them independently:\nbin/ocis server starts the same services as:\nbin/ocis micro \u0026amp; bin/ocis phoenix \u0026amp; bin/ocis hello \u0026amp; bin/ocis reva \u0026amp; Now we can kill the ocis hello and use our custom built ocis-hello binary:\ncd ../ocis-hello bin/ocis-hello server Hacking phoenix (and ocis-phoenix) Following https://github.com/owncloud/phoenix we are going to build the current phoenix\ngit clone https://github.com/owncloud/phoenix.git cd phoenix yarn install yarn dist We can tell ocis to use the compiled assets:\nKill ocis phoenix, then use the compiled assets when starting phoenix.\ncd ../ocis PHOENIX_ASSET_PATH=\u0026#34;`pwd`/../phoenix/dist\u0026#34; bin/ocis phoenix The ownCloud design system The owncloud design system contains a set of ownCloud vue components for phoenix or your own ocis extensions. Use it for a consistent look and feel.\nPoint your browser to https://owncloud.github.io/owncloud-design-system and check the available components. Live editing the examples in the browser is supported.\nnote: There is a bug with navigation sub items: either click a nav item twice or refresh the page\nExternal phoenix apps This is what hello is: copy and extend!\n  Phoenix is configured using the config.json which is served by the phoenix service (either bin/ocis phoenix or bin/ocis-phoenix server)\n  point ocis phoenix to the web config which you extended with an external app: PHOENIX_WEB_CONFIG=\u0026quot;pwd/../phoenix/config.json\u0026quot; PHOENIX_ASSET_PATH=\u0026quot;pwd/../phoenix/dist\u0026quot; bin/ocis phoenix\n  { \u0026#34;server\u0026#34;: \u0026#34;http://localhost:9140\u0026#34;, \u0026#34;theme\u0026#34;: \u0026#34;owncloud\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, \u0026#34;openIdConnect\u0026#34;: { \u0026#34;metadata_url\u0026#34;: \u0026#34;http://localhost:9140/.well-known/openid-configuration\u0026#34;, \u0026#34;authority\u0026#34;: \u0026#34;http://localhost:9140\u0026#34;, \u0026#34;client_id\u0026#34;: \u0026#34;phoenix\u0026#34;, \u0026#34;response_type\u0026#34;: \u0026#34;code\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;openid profile email\u0026#34; }, \u0026#34;apps\u0026#34;: [], \u0026#34;external_apps\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;http://localhost:9105/hello.js\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9105\u0026#34; } }, { \u0026#34;id\u0026#34;: \u0026#34;myapp\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;http://localhost:6789/superapp.js\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;backend\u0026#34;: \u0026#34;http://someserver:1234\u0026#34;, \u0026#34;myconfig\u0026#34;: \u0026#34;is awesome\u0026#34; } } ] } Phoenix extension points For an up to date list check out the phoenix documentation.  Several ones available:\nPhoenix core  App switcher (defined in config.json) App container (loads UI of your extension)  Files app  File action Create new file action Sidebar Quick access for sidebar inside of file actions (in the file row)  Example of a file action in the app.js:\nconst appInfo = { name: \u0026#39;MarkdownEditor\u0026#39;, id: \u0026#39;markdown-editor\u0026#39;, icon: \u0026#39;text\u0026#39;, isFileEditor: true, extensions: [{ extension: \u0026#39;txt\u0026#39;, newFileMenu: { menuTitle ($gettext) { return $gettext(\u0026#39;Create new plain text file‚Ä¶\u0026#39;) } } }, { extension: \u0026#39;md\u0026#39;, newFileMenu: { menuTitle ($gettext) { return $gettext(\u0026#39;Create new mark-down file‚Ä¶\u0026#39;) } } }] } For the side bar have a look at the files app, defaults.js \u0026amp; fileSideBars\nAPI driven development Until now we only had a look at the ui and how the extensions are managed on the cli. But how do apps actually talk to the server?\nShort answer: any way you like\nLong answer: micro and ocis-hello follow a protocol driven development:\n  specify the API using protobuf\n  generate client and server code\n  evolve based on the protocol\n  CS3 api uses protobuf as well and uses GRPC\n  ocis uses go-micro, which provides http and grpc gateways\n  the gateways and protocols are optional\n  owncloud and kopano are looking into a MS graph like api to handle phoenix requests.\n they might be about user, contacrs, calendars \u0026hellip; which is covered by the graph api we want to integrate with eg. kopano and provide a commen api (file sync and share is covered as well)    as an example for protobuf take a look at ocis-hello\n  "});index.add({'id':62,'href':'/extensions/glauth/license/','title':"License",'content':"This project is licensed under the Apache 2.0 license. For the license of the used libraries you have to check the respective sources.\n"});index.add({'id':63,'href':'/extensions/ocs/license/','title':"License",'content':"This project is licensed under the Apache 2.0 license. For the license of the used libraries you have to check the respective sources.\n"});index.add({'id':64,'href':'/extensions/storage/license/','title':"License",'content':"This project is licensed under the Apache 2.0 license. For the license of the used libraries you have to check the respective sources.\n"});index.add({'id':65,'href':'/extensions/store/license/','title':"License",'content':"This project is licensed under the Apache 2.0 license. For the license of the used libraries you have to check the respective sources.\n"});index.add({'id':66,'href':'/extensions/thumbnails/releasing/','title':"Releasing",'content':"    Preperation Release     To release a new version of ocis-thumbnails, you have to follow a few simple steps.\nPreperation  Create a new branch e.g. release-x.x.x where x.x.x is the version you want to release. Checkout the preparation branch. Create a new changelog folder and move the unreleased snippets there. mkdir changelog/x.x.x_yyyy-MM-dd/ # yyyy-MM-dd is the current date mv changelog/unreleased/* changelog/x.x.x_yyyy-MM-dd/ Commit and push the changes git add --all git commit -m \u0026#34;prepare release x.x.x\u0026#34; git push Create a pull request to the master branch.  Release  After the preparation branch has been merged update your local master. git checkout master git pull Create a new tag (preferably signed). git tag -s vx.x.x -m \u0026#34;release vx.x.x\u0026#34; git push --tags Wait for CI and check that the GitHub release was published.  Congratulations, you just released ocis-thumbnails!\n"});index.add({'id':67,'href':'/extensions/ocis-phoenix/releasing/','title':"Releasing",'content':"    Releasing  Package Hierarchy  Prerequisites Updating ocis-phoenix Next steps         Releasing The next generation Web Frontend is shipped as an ocis Extension. The ocis-phoenix extension is also embedded in the single binary and part of the ocis server command.\nTo update this package within all the deliveries, we need to update the package in the following chain from the bottom to the top.\nPackage Hierarchy  ocis  ocis-phoenix  ocis-pkg phoenix      Prerequisites Before updating the assets, make sure that Phoenix has been released first and take note of its release tag name.\nUpdating ocis-phoenix  Create a branch release-$version. in https://github.com/owncloud/ocis-phoenix Create a Folder in changelog for the release version and date mkdir $major.$minor.$patchVersion_YYYY-MM-DD. Move all changelog items from the changelog/unreleased/ folder to the $major.$minor.$patchVersion_YYYY-MM-DD folder. Update the go module ocis-pkg to the latest version https://blog.golang.org/using-go-modules . Update the phoenix asset by adjusting the value of PHOENIX_ASSETS_VERSION at the top of the Makefile and specify the tag name of the latest Phoenix release. Run make clean generate. Create a changelog item for the update in the changelog/$major.$minor.$patchVersion_YYYY-MM-DD folder. Commit your changes. After merging, wait for the CI to run on the merge commit. Go to \u0026ldquo;Releases\u0026rdquo; in GH click \u0026ldquo;Draft a new Release\u0026rdquo;. Use v$major.$minor.$patch as a tag (the v prefix is important) and publish it. The tag and the Release artifacts will be created automatically.  Next steps Next steps is usually updating the ocis-phoenix version in the ocis repository.\n"});index.add({'id':68,'href':'/ocis/login-flow/','title':"Login Flow",'content':"Login Flow The following sequence diagram describes the openid connect auth code flow. The eight numbered steps and notes correspond to the openid connect auth code flow steps. Example requests are based on the spec as well.:\n  mermaid.initialize({ flowchart: { useMaxWidth: true } });  sequenceDiagram %% we have comments!! \\o/ %% this documents the login workflow %% examples taken from the oidc spec https://openid.net/specs/openid-connect-core-1_0.html#CodeFlowAuth %% TODO add PKCE, see https://developer.okta.com/blog/2019/08/22/okta-authjs-pkce#use-pkce-to-make-your-apps-more-secure participant user as User participant client as Client participant proxy as ocis-proxy participant idp as IdP participant glauth as ocis-glauth participant graph as ocis-graph participant accounts as ocis-accounts participant ldap as external LDAP server user-+client: What is the content of my home? client-+proxy: PROPFIND no (or expired) auth Note over client,proxy: ocis needs to know the IdP that is\nused to authenticate users. The\nproxy will redirect unauthenticated\nrequests to that IdP. proxy---client: 302 Found Note over client, idp: HTTP/1.1 302 Found\nLocation: https://server.example.com/authorize?\nresponse_type=code\u0026\nscope=openid%20profile%20email\n\u0026client_id=s6BhdRkqt3\n\u0026state=af0ifjsldkj\n\u0026redirect_uri=https%3A%2F%2Fclient.example.org%2Fcb Note over client, idp: We should follow the OpenID Connect Discovery protocol Note over client, idp: Clients might fall back to the ocis server if the discovery failed.\nWe can provide a webfinger endpoint there to let guests use an idp\nthat is backed by the accounts service. Note over client, idp: For now, clients can only handle one IdP, which is configured in ocis. client--client: 1. Client prepares an Authentication Request\ncontaining the desired request parameters. client-+idp: 2. Client sends the request to the Authorization Server. Note over client, idp: GET /authorize?\nresponse_type=code\n\u0026scope=openid%20profile%20email\n\u0026client_id=s6BhdRkqt3\n\u0026state=af0ifjsldkj\n\u0026redirect_uri=https%3A%2F%2Fclient.example.org%2Fcb HTTP/1.1\nHost: server.example.com Note over user, idp: 3. Authorization Server Authenticates the End-User. Note over idp,ldap: Either an IdP already exists or a new one is introduced. Since we are not yet using oidc discovery we can only use one IdP. alt all users managed by konnectd/ocis idp-+glauth: LDAP query/bind glauth-+graph: GET user with Basic Auth\nGraphAPI graph-+accounts: internal GRPC accounts---graph: response graph---glauth: OData response glauth---idp: LDAP result Note over accounts,ldap: In case internal users are managed\nin an external ldap they have to be\nsynced to the accounts service to\nshow up as recipients during sharing. else all users authenticated by an external idp idp-+ldap: LDAP query/bind ldap---idp: LDAP result alt guest accounts managed in ocis / lookup using glauth proxy: Note over idp,glauth: Idp is configured to use glauth as a\nsecond ldap server. idp-+glauth: LDAP query/bind glauth-+graph: GET user with Basic Auth\nGraphAPI graph-+accounts: internal GRPC accounts---graph: response graph---glauth: OData response glauth---idp: LDAP result else guest account provisioned by other means Note over accounts, ldap: In case guest accounts are managed\nin an existing ldap they need to be\nsynced to the accounts service to\nbe able to login and show up as\nrecipients during sharing. end end Note over user, idp: 4. Authorization Server obtains End-User Consent/Authorization. idp---client: 5. Authorization Server sends the End-User back\nto the Client with an Authorization Code. Note over client, idp: HTTP/1.1 302 Found\nLocation: https://client.example.org/cb?\ncode=SplxlOBeZQQYbYS6WxSbIA\u0026state=af0ifjsldkj client-+idp: 6. Client requests a response using the\nAuthorization Code at the Token Endpoint. Note over client, idp: POST /token HTTP/1.1\nHost: server.example.com\nContent-Type: application/x-www-form-urlencoded\ngrant_type=authorization_code\u0026code=SplxlOBeZQQYbYS6WxSbIA\n\u0026redirect_uri=https%3A%2F%2Fclient.example.org%2Fcb idp---client: 7. Client receives a response that contains an\nID Token and Access Token in the response body. Note over client, idp: HTTP/1.1 200 OK\nContent-Type: application/json\nCache-Control: no-store\nPragma: no-cache\n{\n\"access_token\": \"SlAV32hkKG\",\n\"token_type\": \"Bearer\",\n\"refresh_token\": \"8xLOxBtZp8\",\n\"expires_in\": 3600,\n\"id_token\": \"a ... b.c ... d.e ... f\" // must be a JWT\n} client--client: 8. Client validates the ID token and\nretrieves the End-User's Subject Identifier. client-+proxy: PROPFIND With access token proxy---client: 207 Multi-Status client---user: List of Files X, Y, Z ... "});index.add({'id':69,'href':'/ocis/request-flow/','title':"Request Flow",'content':"Request Flow The following sequence diagram describes the general request flow. It shows where account provisioning and token minting are happening:\n  mermaid.initialize({ flowchart: { useMaxWidth: true } });  sequenceDiagram %% we have comments!! \\o/ participant user as User participant client as Client participant proxy as ocis-proxy participant idp as IdP participant accounts as ocis-accounts participant ldap as corporate LDAP server user-+client: What is the content of my home? client-+proxy: PROPFIND Bearer auth using oidc auth token Note over client,proxy: What is in a bearer token? The spec recommends opaque tokens. Treat it as random byte noise. Note over client,proxy: the proxy MUST authenticate users using ocis-accounts because it needs to decide where to send the request %% Mention introspection endpoint for opaque tokens %% konnectd uses jwt, so we can save a request %% either way the token can be used to look up the sub and iss of the user %% or is token check enough? proxy-+idp: GET /userinfo alt userinfo succeeds idp--proxy: 200 OK Note over proxy,accounts: Content-Type: application/json\n{\n\"sub\": \"248289761001\",\n\"name\": \"Jane Doe\",\n\"given_name\": \"Jane\",\n\"family_name\": \"Doe\",\n\"preferred_username\": \"j.doe\",\n\"email\": \"janedoe@example.com\",\n\"picture\": \"http://example.com/janedoe/me.jpg\"\n} %% see: https://openid.net/specs/openid-connect-core-1_0.html#UserInfoResponse else userinfo fails idp---proxy: 401 Unauthorized Note over proxy,accounts: WWW-Authenticate: error=\"invalid_token\",\nerror_description=\"The Access Token expired\" proxy--client: 401 Unauthorized or 302 Found with redirect to idp Note over client: start at login flow\nor refresh the token end proxy-+accounts: TODO API call to exchange sub@iss with account UUID Note over proxy,accounts: does not autoprovision users. They are explicitly provsioned later. alt account exists or has been migrated accounts--proxy: existing account UUID else account does not exist opt oc10 endpoint is configured Note over proxy,oc10: Check if user exists in oc10 proxy-+oc10: GET /apps/graphapi/v1.0/users/\u0026lt;uuid\u0026gt; opt user exists in oc10 oc10---proxy: 200 %% TODO auth using internal token proxy-+oc10: PROPFIND Note over proxy,oc10: forward existing bearer auth oc10---proxy: Multistatus response proxy--client: Multistatus response client--user: List of Files X, Y, Z ... end end Note over proxy,accounts: provision a new account including displayname, email and sub@iss TODO only if the user is allowed to login, based on group membership in the ldap server proxy-proxy: generate new uuid proxy-+accounts: TODO create account with new generated uuid accounts---proxy: OK / error else account has been disabled accounts---proxy: account is disabled proxy--client: 401 Unauthorized or 302 Found with redirect to idp Note over client: start at login flow\nor refresh the token end proxy-proxy: store uuid in context %% what if oc10 does not support a certain request / API proxy-proxy: mint an internal jwt that includes the UUID and username using revas `x-access-token` header proxy-+reva: PROPFIND Token auth using internal JWT reva---proxy: Multistatus response proxy---client: Multistatus response client---user: List of Files X, Y, Z ... "});index.add({'id':70,'href':'/ocis/public-upload-flow/','title':"Public upload Flow",'content':"Public Upload flow The following diagram describes the flow of requests:\nocis-reva sharing\nREVA_SHARING_ADDR = 0.0.0.0:9150\nocis-reva sharing...ocis-reva frontend\nREVA_FRONTEND_ADDR =¬†0.0.0.0:9140\nREVA_GATEWAY_URL =¬†ocis:9142\nocis-reva frontend...ocis-proxy\nPROXY_HTTP_ADDR =¬†0.0.0.0:9200\nocis-proxy...2¬†¬†POST¬†http://ocis:9140/remote.php/dav/files/einstein/2¬†POST¬†http:/...ocdav\nprefix = \"\"\ntimeout = 86400\nocdav...datagateway\nprefix = \"data\"\ntimeout = 86400\ndatagateway...client\nclient\u0026#xa;22¬†¬†PATCH https://oc.example.org/data/{token}\nTus-Resumable: 1.0.022¬†PATCH http...ocis-reva gateway\nREVA_GATEWAY_ADDR = 0.0.0.0:9142\nocis-reva gateway...storage-registry\nstorage-registry\u0026#xa;Expose: trueExpose: true24 ¬†PATCH http://ocis:9156/data/u-u-i-d24 PATCH http...4¬† GetStorageProvider\n(ShareReference)4¬†GetStorageP...5¬† ProviderInfo5¬†ProviderInfostorageprovider\nREVA_STORAGE_HOME_ADDR = 0.0.0.0:9154\nREVA_STORAGE_HOME_DRIVER¬†= eoshome\nREVA_STORAGE_HOME_EXPOSE_DATA_SERVER = false\nREVA_STORAGE_HOME_DATA_SERVER_URL =\nhttp://ocis:9156/data\nstorageprovider...Expose: falseExpose: false6¬† InitiateFileUpload\n(ShareReference)6¬†InitiateFil...EOSEOS15 ¬†WriteFile(upload info)15 WriteFile(...7¬† GetPublicShare7¬†GetPublicSh...19¬†¬†UploadEndpoint\nhttps://oc.example.org/data/{token}19¬†UploadEndp...20¬†¬†201 Created\nLocation: https://oc.example.org/data/{token}20¬†201 Create...21¬†¬†201 Created\nLocation: https://oc.example.org/data/{token}21¬†201 Create...1¬†POST https://oc.example.org/remote.php/dav/files/einstein/\nUpload-Length: 100\nTus-Resumable: 1.0.0\nUpload-Metadata: filename d29ybGRfZG9taW5hdGlvbl9wbGFuLnBkZg==,dir d29ybGRfZG9taW5hdGlvbl9wbGFuLnBkZg==1¬†POST https:...23¬†¬†PATCH http://ocis:9140/data/{token}\nTus-Resumable: 1.0.023¬†PATCH http...3¬† InitiateFileUpload3¬†InitiateFil...25¬†¬†Write(bytes)25¬†Write(byte...26¬†¬†204 No Content26¬†204 No Con...27¬†¬†204 No Content27¬†204 No Con...28¬†¬†204 No Content28¬†204 No Con...publicstorageprovider\nexpose-data-server = true\npublicstorageprovider...publicshareprovider\npublicshareprovider\u0026#xa;8¬†¬†GetPublicShare8¬†GetPublicSh...9¬† PublicShare9¬†PublicShare10¬†¬†PublicShare10¬†PublicShare11¬†¬†InitiateFileUpload(TargetReference)11¬†InitiateFi...12¬† GetStorageProvider\n(TargetReference)12¬†GetStorage...13¬†¬†ProviderInfo13¬†ProviderIn...14¬† InitiateFileUpload(TargetReference)14¬†InitiateFi...16¬† UploadEndpoint\nhttp://ocis:9156/data/u-u-i-d\nExpose: false16¬†UploadEndp...17¬†UploadEndpoint\nhttps://oc.example.org/data/\ntoken: sign(http://ocis:9156/data/u-u-i-d)17¬†UploadEndp...18¬† UploadEndpoint\nhttps://oc.example.org/data/{token}\nExpose: true18¬†UploadEndp...gateway\nREVA_TRANSFER_EXPIRES = 86400\nREVA_FRONTEND_URL =\nhttps://oc.example.org\nREVA_DATAGATEWAY_URL =\nhttps://oc.example.org/data\n\ngateway...When a storage provider\nsets the Expose flag of an Upload/Download Endpoint to false the gateway will wrap the url in a JWT and return the URL of the datagateway along with a transfer-token.When a storage provider...dataprovider\nREVA_STORAGE_HOME_DATA_ADDR = 0.0.0.0:9156\nREVA_STORAGE_HOME_DATA_DRIVER = eoshome\ndataprovider...GOAL: transfer bytes from the client up here ...GOAL: tran...... to the storage system somewhere down here... to the storage syst...Viewer does not support full SVG 1.1 "});index.add({'id':71,'href':'/extensions/storage/updating/','title':"Updating reva",'content':"    Updating reva     Updating reva  Run go get github.com/cs3org/reva@master Create a changelog entry containing changes that were done in reva Create a Pull Request to ocis-reva master with those changes If test issues appear, you might need to adjust the tests After the PR is merged, consider doing a release of the storage submodule  "});index.add({'id':72,'href':'/extensions/settings/bundles/','title':"Settings Bundles",'content':"A Settings Bundle is a collection of settings, uniquely identified by the key of the extension registering the bundle and the key of the bundle itself. It\u0026rsquo;s purpose is to let oCIS extensions define settings and make them available to users. They are dynamically rendered into forms, available in the frontend.\nAs of now we support five different types of settings:\n boolean integer string single choice list of integers or strings multiple choice list of integers or strings  Each Setting is uniquely identified by a key within the bundle. Some attributes depend on the chosen type of setting. Through the information provided with the attributes of the setting, the settings frontend dynamically renders form elements, allowing users to change their settings individually.\nExample { \u0026#34;identifier\u0026#34;: { \u0026#34;extension\u0026#34;: \u0026#34;ocis-accounts\u0026#34;, \u0026#34;bundleKey\u0026#34;: \u0026#34;profile\u0026#34; }, \u0026#34;displayName\u0026#34;: \u0026#34;Profile\u0026#34;, \u0026#34;settings\u0026#34;: [ { \u0026#34;settingKey\u0026#34;: \u0026#34;lastname\u0026#34;, \u0026#34;displayName\u0026#34;: \u0026#34;Lastname\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Input for lastname\u0026#34;, \u0026#34;stringValue\u0026#34;: { \u0026#34;placeholder\u0026#34;: \u0026#34;Set lastname\u0026#34; } }, { \u0026#34;settingKey\u0026#34;: \u0026#34;age\u0026#34;, \u0026#34;displayName\u0026#34;: \u0026#34;Age\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Input for age\u0026#34;, \u0026#34;intValue\u0026#34;: { \u0026#34;min\u0026#34;: \u0026#34;16\u0026#34;, \u0026#34;max\u0026#34;: \u0026#34;200\u0026#34;, \u0026#34;step\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;placeholder\u0026#34;: \u0026#34;Set age\u0026#34; } }, { \u0026#34;settingKey\u0026#34;: \u0026#34;timezone\u0026#34;, \u0026#34;displayName\u0026#34;: \u0026#34;Timezone\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;User timezone\u0026#34;, \u0026#34;singleChoiceValue\u0026#34;: { \u0026#34;options\u0026#34;: [ { \u0026#34;stringValue\u0026#34;: \u0026#34;Europe/Berlin\u0026#34;, \u0026#34;displayValue\u0026#34;: \u0026#34;Europe/Berlin\u0026#34; }, { \u0026#34;stringValue\u0026#34;: \u0026#34;Asia/Kathmandu\u0026#34;, \u0026#34;displayValue\u0026#34;: \u0026#34;Asia/Kathmandu\u0026#34; } ] } } ] } "});index.add({'id':73,'href':'/clients/web/backend-ocis/','title':"Setup with OCIS",'content':"    Setting up OCIS services Setting up Phoenix Setting up ocis-phoenix service Running Phoenix Running acceptance tests     Setting up OCIS services  Setup OCIS by cloning the ocis repository and following the setup instructions there. Do not start the whole server but run ./bin/ocis --log-level debug $EXTENSION for all the existing extensions except the phoenix service. A list of extensions can be found by running ./bin/ocis without arguments and looking at the \u0026ldquo;Extensions\u0026rdquo; section.  Setting up Phoenix  Please note that config.json is generated by ocis-phoenix so there is no need to create one. If you want to provide a config.json file, you can do so by starting ocis with PHOENIX_WEB_CONFIG=/path/to/config.json  Setting up ocis-phoenix service  Clone the ocis-phoenix repository and follow the setup instructions there. Set export PHOENIX_ASSET_PATH=$PHOENIX_CHECKOUT/dist and replace with the path to the local git checkout of the Phoenix repository Run \u0026ldquo;ocis-phoenix\u0026rdquo;: ./bin/ocis-phoenix --log-level debug server  Running Phoenix  in the Phoenix checkout folder, run yarn watch-all-ocis open https://localhost:9200 and accept the certificate. when signing in, use one of the available test users whenever code changes are made, you need to manually reload the browser page (no hot reload)  Running acceptance tests For testing, please refer to the OCIS testing section\n"});index.add({'id':74,'href':'/ocis/development/debugging/','title':"Debugging",'content':"Debugging As a single binary for easy deployment running ocis server just forks itself to start all the services, which makes debugging those processes a little harder.\nUltimately, we want to be able to stop a single service using eg. ocis kill phoenix so that you can start the service you want to debug in debug mode. We need to change the way we fork processes though, otherwise the runtime will automatically restart a service if killed.\nStart ocis For debugging there are two workflows that work well, depending on your preferences.\nUse the debug binary and attach to the process as needed Run the debug binary with OCIS_LOG_LEVEL=debug bin/ocis-debug server and then find the service you want to debug using:\n# ps ax | grep ocis 12837 pts/1 Sl+ 0:00 bin/ocis-debug server 12845 pts/1 Sl 0:00 bin/ocis-debug graph 12847 pts/1 Sl 0:00 bin/ocis-debug reva-auth-bearer 12848 pts/1 Sl 0:00 bin/ocis-debug graph-explorer 12849 pts/1 Sl 0:00 bin/ocis-debug ocs 12850 pts/1 Sl 0:00 bin/ocis-debug reva-storage-oc-data 12863 pts/1 Sl 0:00 bin/ocis-debug webdav 12874 pts/1 Sl 0:00 bin/ocis-debug reva-frontend 12897 pts/1 Sl 0:00 bin/ocis-debug reva-sharing 12905 pts/1 Sl 0:00 bin/ocis-debug reva-gateway 12912 pts/1 Sl 0:00 bin/ocis-debug reva-storage-home 12920 pts/1 Sl 0:00 bin/ocis-debug reva-users 12929 pts/1 Sl 0:00 bin/ocis-debug glauth 12940 pts/1 Sl 0:00 bin/ocis-debug reva-storage-home-data 12948 pts/1 Sl 0:00 bin/ocis-debug konnectd 12952 pts/1 Sl 0:00 bin/ocis-debug proxy 12961 pts/1 Sl 0:00 bin/ocis-debug thumbnails 12971 pts/1 Sl 0:00 bin/ocis-debug reva-storage-oc 12981 pts/1 Sl 0:00 bin/ocis-debug web 12993 pts/1 Sl 0:00 bin/ocis-debug api 12998 pts/1 Sl 0:00 bin/ocis-debug registry 13004 pts/1 Sl 0:00 bin/ocis-debug phoenix 13015 pts/1 Sl 0:00 bin/ocis-debug reva-auth-basic Then you can set a breakpoint in the service you need and attach to the process via processid. To debug the reva-sharing service the VS Code launch.json would look like this:\n{ \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;ocis attach\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;attach\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;processId\u0026#34;: 12897, } ] } Start all services independently to replace one of them with a debug process  You can use this ./ocis.sh script to start all services independently, so they don\u0026rsquo;t get restrarted by the runtime when you kill them:  #/bin/sh LOG_LEVEL=\u0026#34;debug\u0026#34; bin/ocis --log-level=$LOG_LEVEL micro \u0026amp; bin/ocis --log-level=$LOG_LEVEL glauth \u0026amp; bin/ocis --log-level=$LOG_LEVEL graph-explorer \u0026amp; bin/ocis --log-level=$LOG_LEVEL graph \u0026amp; #bin/ocis --log-level=$LOG_LEVEL hello \u0026amp; bin/ocis --log-level=$LOG_LEVEL konnectd \u0026amp; #bin/ocis --log-level=$LOG_LEVEL ocs \u0026amp; bin/ocis --log-level=$LOG_LEVEL phoenix \u0026amp; bin/ocis --log-level=$LOG_LEVEL reva-auth-basic \u0026amp; bin/ocis --log-level=$LOG_LEVEL reva-auth-bearer \u0026amp; bin/ocis --log-level=$LOG_LEVEL reva-frontend \u0026amp; bin/ocis --log-level=$LOG_LEVEL reva-gateway \u0026amp; bin/ocis --log-level=$LOG_LEVEL reva-sharing \u0026amp; bin/ocis --log-level=$LOG_LEVEL reva-storage-home \u0026amp; bin/ocis --log-level=$LOG_LEVEL reva-storage-home-data \u0026amp; bin/ocis --log-level=$LOG_LEVEL reva-storage-oc \u0026amp; bin/ocis --log-level=$LOG_LEVEL reva-storage-oc-data \u0026amp; bin/ocis --log-level=$LOG_LEVEL reva-storage-root \u0026amp; bin/ocis --log-level=$LOG_LEVEL reva-users \u0026amp; #bin/ocis --log-level=$LOG_LEVEL webdav bin/ocis --log-level=$LOG_LEVEL proxy \u0026amp; Get the list of running processes:  # ps ax | grep ocis 12837 pts/1 Sl+ 0:00 bin/ocis-debug server 12845 pts/1 Sl 0:00 bin/ocis-debug graph 12847 pts/1 Sl 0:00 bin/ocis-debug reva-auth-bearer 12848 pts/1 Sl 0:00 bin/ocis-debug graph-explorer 12849 pts/1 Sl 0:00 bin/ocis-debug ocs 12850 pts/1 Sl 0:00 bin/ocis-debug reva-storage-oc-data 12863 pts/1 Sl 0:00 bin/ocis-debug webdav 12874 pts/1 Sl 0:00 bin/ocis-debug reva-frontend 12897 pts/1 Sl 0:00 bin/ocis-debug reva-sharing 12905 pts/1 Sl 0:00 bin/ocis-debug reva-gateway 12912 pts/1 Sl 0:00 bin/ocis-debug reva-storage-home 12920 pts/1 Sl 0:00 bin/ocis-debug reva-users 12929 pts/1 Sl 0:00 bin/ocis-debug glauth 12940 pts/1 Sl 0:00 bin/ocis-debug reva-storage-home-data 12948 pts/1 Sl 0:00 bin/ocis-debug konnectd 12952 pts/1 Sl 0:00 bin/ocis-debug proxy 12961 pts/1 Sl 0:00 bin/ocis-debug thumbnails 12971 pts/1 Sl 0:00 bin/ocis-debug reva-storage-oc 12981 pts/1 Sl 0:00 bin/ocis-debug web 12993 pts/1 Sl 0:00 bin/ocis-debug api 12998 pts/1 Sl 0:00 bin/ocis-debug registry 13004 pts/1 Sl 0:00 bin/ocis-debug phoenix 13015 pts/1 Sl 0:00 bin/ocis-debug reva-auth-basic Kill the service you want to start in debug mode:  # kill 17628 Start the service you are interested in in debug mode. When using make to build the binary there is already a bin/ocis-debug binary for you. When running an IDE tell it which service to start by providing the corresponding sub command, eg. bin\\ocis-debug reva-frontend.  Gather error messages We recommend you collect all related information in a single file or in a github issue. Let us start with an error that pops up in the Web UI:\n Error while sharing. error sending a grpc stat request\n This popped up when I tried to add marie as a collaborator in phoenix. That triggers a request to the server which I copied as curl. We can strip a lot of headers and the gist of it is:\n# curl \u0026#39;https://localhost:9200/ocs/v1.php/apps/files_sharing/api/v1/shares\u0026#39; -d \u0026#39;shareType=0\u0026amp;shareWith=marie\u0026amp;path=%2FNeuer+Ordner\u0026amp;permissions=1\u0026#39; -u einstein:relativity -k -v | xmllint -format - [... headers ...] \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;ocs\u0026gt; \u0026lt;meta\u0026gt; \u0026lt;status\u0026gt;error\u0026lt;/status\u0026gt; \u0026lt;statuscode\u0026gt;998\u0026lt;/statuscode\u0026gt; \u0026lt;message\u0026gt;error sending a grpc stat request\u0026lt;/message\u0026gt; \u0026lt;/meta\u0026gt; \u0026lt;/ocs\u0026gt; The username and password only work when basic auth is available. Otherwise you have to obtain a bearer token, eg. by grabbing it from the browser.  TODO add ocis cli tool to obtain a bearer token.  We also have a few interesting log entries:\n0:43PM INF home/jfd/go/pkg/mod/github.com/cs3org/reva@v0.0.2-0.20200318111623-a2f97d4aa741/internal/grpc/interceptors/log/log.go:69 \u0026gt; unary code=OK end=\u0026#34;18/Mar/2020:22:43:40 +0100\u0026#34; from=tcp://[::1]:44078 pid=17836 pkg=rgrpc start=\u0026#34;18/Mar/2020:22:43:40 +0100\u0026#34; time_ns=95841 traceid=b4eb9a9f45921f7d3632523ca32a42b0 uri=/cs3.storage.registry.v1beta1.RegistryAPI/GetStorageProvider user-agent=grpc-go/1.26.0 10:43PM ERR home/jfd/go/pkg/mod/github.com/cs3org/reva@v0.0.2-0.20200318111623-a2f97d4aa741/internal/grpc/interceptors/log/log.go:69 \u0026gt; unary code=Unknown end=\u0026#34;18/Mar/2020:22:43:40 +0100\u0026#34; from=tcp://[::1]:43910 pid=17836 pkg=rgrpc start=\u0026#34;18/Mar/2020:22:43:40 +0100\u0026#34; time_ns=586115 traceid=b4eb9a9f45921f7d3632523ca32a42b0 uri=/cs3.gateway.v1beta1.GatewayAPI/Stat user-agent=grpc-go/1.26.0 10:43PM ERR home/jfd/go/pkg/mod/github.com/cs3org/reva@v0.0.2-0.20200318111623-a2f97d4aa741/internal/http/services/owncloud/ocs/reqres.go:94 \u0026gt; error sending a grpc stat request error=\u0026#34;rpc error: code = Unknown desc = gateway: error calling Stat: rpc error: code = Unavailable desc = connection error: desc = \\\u0026#34;transport: Error while dialing dial tcp [::1]:9152: connect: connection refused\\\u0026#34;\u0026#34; pid=17832 pkg=rhttp traceid=b4eb9a9f45921f7d3632523ca32a42b0 TODO return the trace id in the response so we can correlate easier. For reva tracked in https://github.com/cs3org/reva/issues/587  The last line gives us a hint where the log message originated: .../github.com/cs3org/reva@v0.0.2-0.20200318111623-a2f97d4aa741/internal/http/services/owncloud/ocs/reqres.go:94. Which looks like this:\n89: // WriteOCSResponse handles writing ocs responses in json and xml 90: func WriteOCSResponse(w http.ResponseWriter, r *http.Request, res *Response, err error) { 91: var encoded []byte 92: 93: if err != nil { 94: appctx.GetLogger(r.Context()).Error().Err(err).Msg(res.OCS.Meta.Message) 95: } Ok, so this seems to be a convenience method that is called from multiple places an also handles errors. Unfortunately, this hides the actual source of the error. We could set a breakpoint in line 94 and reproduce the problem, which can be a lot harder than just clicking the share button or sending a curl request again. So let us see what else the log tells us.\nThe previous line tells us that a Stat request failed: uri=/cs3.gateway.v1beta1.GatewayAPI/Stat. This time the line is written by the grpc log interceptor. What else is there?\nThe first line tells us that looking up the responsible storage provider seems to have succeeded: uri=/cs3.storage.registry.v1beta1.RegistryAPI/GetStorageProvider.\nAt this point it your familiarity with the codebase starts to become a factor. If you are new you should probably go back to setting a break point on the log line and check the stack trace.\nDebug wherever the call trace leads you to \u0026hellip; good luck!\nManaging dependencies and testing changes You can either run and manage the services independently, or you can update the go.mod file and replace dependencies with your local version.\nTo debug the reva frontend we need to add two replacements:\n// use the local ocis-reva repo replace github.com/owncloud/ocis-reva =\u0026gt; ../ocis-reva // also use the local reva repo replace github.com/cs3org/reva =\u0026gt; ../reva The username and password only work when basic auth is available. Otherwise you have to obtain a bearer token, eg. by grabbing it from the browser.  Rebuild ocis to make sure the dependency is used. It should be sufficient to just restart the service you want to debug.\n"});index.add({'id':75,'href':'/extensions/thumbnails/grpc/','title':"GRPC API",'content':"    pkg/proto/v0/thumbnails.proto  GetRequest GetResponse GetRequest.FileType ThumbnailService   Scalar Value Types     pkg/proto/v0/thumbnails.proto GetRequest A request to retrieve a thumbnail\n   Field Type Label Description     filepath string  The path to the source image   filetype GetRequest.FileType  The type to which the thumbnail should get encoded to.   etag string  The etag of the source image   width int32  The width of the thumbnail   height int32  The height of the thumbnail   authorization string  The authorization token    GetResponse The service response\n   Field Type Label Description     thumbnail bytes  The thumbnail as a binary   mimetype string  The mimetype of the thumbnail    GetRequest.FileType The file types to which the thumbnail cna get encoded to.\n   Name Number Description     PNG 0 Represents PNG type   JPG 1 Represents JPG type    ThumbnailService A Service for handling thumbnail generation\n   Method Name Request Type Response Type Description     GetThumbnail GetRequest GetResponse Generates the thumbnail and returns it.    Scalar Value Types    .proto Type Notes C++ Java     double   double double   float   float float   int32  Uses variable-length encoding. Inefficient for encoding negative numbers ‚Äì if your field is likely to have negative values, use sint32 instead. int32 int   int64  Uses variable-length encoding. Inefficient for encoding negative numbers ‚Äì if your field is likely to have negative values, use sint64 instead. int64 long   uint32  Uses variable-length encoding. uint32 int   uint64  Uses variable-length encoding. uint64 long   sint32  Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32 int   sint64  Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64 long   fixed32  Always four bytes. More efficient than uint32 if values are often greater than 2^28. uint32 int   fixed64  Always eight bytes. More efficient than uint64 if values are often greater than 2^56. uint64 long   sfixed32  Always four bytes. int32 int   sfixed64  Always eight bytes. int64 long   bool   bool boolean   string  A string must always contain UTF-8 encoded or 7-bit ASCII text. string String   bytes  May contain any arbitrary sequence of bytes. string ByteString    "});index.add({'id':76,'href':'/extensions/ocis-phoenix/license/','title':"License",'content':"This project is licensed under the Apache 2.0 license. For the license of the used libraries you have to check the respective sources.\n"});index.add({'id':77,'href':'/extensions/ocis_hello/configuration-with-ocis/','title':"Running",'content':"Configuring ocis-hello with ocis We will need various services to run ocis\nRunning a ldap server in docker container We will use the ldap server as users provider for ocis.\ndocker run --hostname ldap.my-company.com \\ -e LDAP_TLS_VERIFY_CLIENT=never \\ -e LDAP_DOMAIN=owncloud.com \\ -e LDAP_ORGANISATION=ownCloud \\ -e LDAP_ADMIN_PASSWORD=admin \\ --name docker-slapd \\ -p 127.0.0.1:389:389 \\ -p 636:636 -d osixia/openldap Running a redis server in a docker container Redis will be used by ocis for various caching purposes.\ndocker run -e REDIS_DATABASES=1 -p 6379:6379 -d webhippie/redis:latest Running ocis In order to run this extension we will need to run ocis first. For that clone and build the ocis single binary from the github repo https://github.com/owncloud/ocis. After that we will need to create a config file for phoenix so that we can load the hello app in the frontend. Create a file phoenix-config.json with the following contents.\n{ \u0026#34;server\u0026#34;: \u0026#34;https://localhost:9200\u0026#34;, \u0026#34;theme\u0026#34;: \u0026#34;owncloud\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, \u0026#34;openIdConnect\u0026#34;: { \u0026#34;metadata_url\u0026#34;: \u0026#34;https://localhost:9200/.well-known/openid-configuration\u0026#34;, \u0026#34;authority\u0026#34;: \u0026#34;https://localhost:9200\u0026#34;, \u0026#34;client_id\u0026#34;: \u0026#34;phoenix\u0026#34;, \u0026#34;response_type\u0026#34;: \u0026#34;code\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;openid profile email\u0026#34; }, \u0026#34;apps\u0026#34;: [ \u0026#34;files\u0026#34;, \u0026#34;draw-io\u0026#34;, \u0026#34;pdf-viewer\u0026#34;, \u0026#34;markdown-editor\u0026#34;, \u0026#34;media-viewer\u0026#34; ], \u0026#34;external_apps\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;http://localhost:9105/hello.js\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9105\u0026#34; } } ] } Here we can add the url for the js file from where the hello app will be loaded.\nAfter that we will need a configuration file for ocis where we can specify the path for the hello app in the backend. For this you can use the existing proxy-example.json file from the ocis-proxy repo. Just add an extra endpoint at the end for the hello app.\n{ \u0026#34;endpoint\u0026#34;: \u0026#34;/api/v0/greet\u0026#34;, \u0026#34;backend\u0026#34;: \u0026#34;http://localhost:9105\u0026#34; } With all this in place we can finally start ocis. But first we will need to set some configuration variables.\nexport REVA_USERS_DRIVER=ldap export REVA_LDAP_HOSTNAME=localhost export REVA_LDAP_PORT=636 export REVA_LDAP_BASE_DN=\u0026#39;dc=owncloud,dc=com\u0026#39; export REVA_LDAP_USERFILTER=\u0026#39;(\u0026amp;(objectclass=posixAccount)(cn=%s))\u0026#39; export REVA_LDAP_GROUPFILTER=\u0026#39;(\u0026amp;(objectclass=posixGroup)(cn=%s))\u0026#39; export REVA_LDAP_BIND_DN=\u0026#39;cn=admin,dc=owncloud,dc=com\u0026#39; export REVA_LDAP_BIND_PASSWORD=admin export REVA_LDAP_SCHEMA_UID=uid export REVA_LDAP_SCHEMA_MAIL=mail export REVA_LDAP_SCHEMA_DISPLAYNAME=displayName export REVA_LDAP_SCHEMA_CN=cn export LDAP_URI=ldap://localhost export LDAP_BINDDN=\u0026#39;cn=admin,dc=owncloud,dc=com\u0026#39; export LDAP_BINDPW=admin export LDAP_BASEDN=\u0026#39;dc=owncloud,dc=com\u0026#39; In addition to all these we will also need to set the config files we just modified. For that set these variables with the path to the config files.\nexport PHOENIX_WEB_CONFIG=\u0026lt;path to phoenix config file\u0026gt; export OCIS_CONFIG_FILE=\u0026lt;path to ocis proxy config file\u0026gt; And finally start the ocis server\nbin/ocis server After this we will need to start the ocis-hello service. For that just build ocis-hello binary.\ncd ocis-hello make And Run the service\nbin/ocis-hello server "});index.add({'id':78,'href':'/extensions/ocis_hello/settings/','title':"Settings",'content':"The ocis-settings service exposes an endpoint for registering so called settings bundles. This gives control to every service to define settings that are needed for fulfilling it\u0026rsquo;s intended purpose. There are different types of settings available out of the box - hopefully those already fit your needs. The settings defined through settings bundles can be changed by authenticated users through an ocis-web extension, which is also provided by the settings service. As a result, your service only has to register a settings bundle and oCIS takes care of everything else. Your service can simply use the settings values that were set by users.\nWith this chapter we want to show you, how to register a settings bundle and how to use the respective values that were set by users. We do this by customizing the greeter phrase from our greeter service in ocis-hello.\nYou can find the source code, especially how it\u0026rsquo;s integrated into the service, in the following files:\n pkg/service/v0/service.go for the requests, pkg/command/server.go for the integration of RegisterSettingsBundles into the service start.  Register settings bundle In order to register a settings bundle, you need to create a request message and then send it to the BundleService of ocis-settings through a gRPC call.\nCreate request request := \u0026amp;settings.SaveSettingsBundleRequest{ SettingsBundle: \u0026amp;settings.SettingsBundle{ Identifier: \u0026amp;settings.Identifier{ Extension: \u0026#34;ocis-hello\u0026#34;, BundleKey: \u0026#34;greeting\u0026#34;, }, DisplayName: \u0026#34;Greeting\u0026#34;, Settings: []*settings.Setting{ { SettingKey: \u0026#34;phrase\u0026#34;, DisplayName: \u0026#34;Phrase\u0026#34;, Description: \u0026#34;Phrase for replies on the greet request\u0026#34;, Value: \u0026amp;settings.Setting_StringValue{ StringValue: \u0026amp;settings.StringSetting{ Required: true, Default: \u0026#34;Hello\u0026#34;, MaxLength: 15, }, }, }, }, }, } The request holds only one field, which is a SettingsBundle. It consists of an Identifier, a DisplayName and a list of Settings.\n The Extension and BundleKey inside the Identifier are required and have to be alphanumeric (- and _ are allowed as well). The Identifier has to stay stable - if you change it, existing settings will not be migrated to the new identifier. The DisplayName is required and may contain any UTF8 character. It will be shown in the settings user frontend in a generated form, so please try to be descriptive. You can change the DisplayName at any time. Settings is the list of settings you want to make available with this settings bundle. In this example, there is only one setting defined - a string setting for the phrase our greeter uses in the response. You can explore more types of settings in the settings package. All of them come with their own characteristics and validations. For the phrase setting we decided to set it to Required, so that it can\u0026rsquo;t be empty, and to set a MaxLength of 15 characters, so that the phrase is not too long. The SettingKey is particularly important, as this is used for referencing the setting in other requests. It has to fulfill the same rules as the other Identifier attributes. Please also take the time to set a Description, in order to provide accessibility in the generated forms as good as possible.  Send request to ocis-settings This request message can be sent to the BundleService of ocis-settings like this:\nbundleService := settings.NewBundleService(\u0026#34;com.owncloud.api.settings\u0026#34;, mclient.DefaultClient) response, err := bundleService.SaveSettingsBundle(context.Background(), request) We run this request on every start of ocis-hello so that the settings service always has the most recent version of the settings bundle.\nUse settings value We registered the greeter phrase setting for a reason: We want to allow the authenticated user to customize how they want to be greeted by ocis-hello. In order to do this, we need to ask ocis-settings on every request, what the greeter phrase of the authenticated user is.\nAccount UUID The settings request has one important prerequisite: As our service is stateless, we need to know the account UUID of the authenticated user the incoming POST request to our greeter service is coming from. As that POST request is coming through ocis-proxy, there is an HTTP header x-access-token that holds a JWT with the account UUID in it. We just have to dismantle the JWT to get the UUID. There is a middleware for that in ocis-pkg. You can look up the server configuration for that middleware in pkg/server/http/server.go. In essence, it dismantles the x-access-token, extracts the account UUID and makes it available in the context. It can be subsequently retrieved from the context like this:\nownAccountUUID := ctx.Value(middleware.UUIDKey).(string) Create request With the account UUID we can build an Identifier for the request to ocis-settings as follows:\nrequest := \u0026amp;settings.GetSettingsValueRequest{ Identifier: \u0026amp;settings.Identifier{ Extension: \u0026#34;ocis-hello\u0026#34;, BundleKey: \u0026#34;greeting\u0026#34;, SettingKey: \u0026#34;phrase\u0026#34;, AccountUuid: ownAccountUUID, }, } The Identifier for getting a value from ocis-settings needs the three fields for extension, bundle and setting that we chose in the settings bundle. The fourth field is the UUID of the authenticated user.\nSend request to ocis-settings This request message can be sent to the ValueService of ocis-settings like this:\nvalueService := settings.NewValueService(\u0026#34;com.owncloud.api.settings\u0026#34;, mclient.DefaultClient) response, err := valueService.GetSettingsValue(ctx, request) If this request is successful we will have a - possibly customized - greeting phrase. It could also be the default value, if the user didn\u0026rsquo;t customize their phrase in the settings frontend.\nConclusion You have learned how to register settings bundles, how to get the account UUID of the authenticated user and how to query the settings service for settings values.\n"});index.add({'id':79,'href':'/extensions/ocis_hello/testing/','title':"Testing",'content':"This repository provides a general guideline for creating tests for the ocis extensions. The tests can be written in various levels from unit, integration, and end-to-end. It is not essential to write tests on all these levels as it can be redundant in some cases. This repository provides a reference for all levels of tests.\nUnit tests Unit tests generally live inside *_test.go files in the /pkg directory. One such example in this extension is in /pkg/service/v0/service_test.go. Similarly the unit test for the protobuf generated code can also be written just like in /pkg/proto/hello.pb_test.go.\nIntegration tests There are mainly 2 types of integration tests, namely HTTP tests, and GRPC tests. These tests mostly live in /pkg/proto directory where all the protobuf definitions are specified. The examples for the HTTP integration tests are in /pkg/proto/hello.pb.web_test.go whereas the GRPC tests are in /pkg/proto/hello.pb.micro_test.go.\nEnd-to-End tests For extensions with an UI, we can also write end-to-end tests using the Nightwatch test framework. These tests live in /ui/tests directory. We can reuse already existing Gherkin steps from the phoenix tests here.\nRunning the tests Unit and integration tests The unit and integration tests are run using the simple go test command. If you wish to run all the tests with the coverage you can just use make command.\nmake test You can also run a specific file with the go test command\ngo test \u0026lt;path to package or file\u0026gt; End-to-End tests Running end-to-end tests is a bit more complicated than unit and integration tests. First of all we will need a complete ocis setup with ocis-hello running. For that refer to this guide.\nAfter that, We need to set the proper test environment. To run the end-to-end tests, first-of-all we need the phoenix repository where all the test infrastructure exists. So, clone the phoenix repository in your system in any location.\ngit clone https://github.com/owncloud/phoenix $HOME/phoenix Next we will need to start the selenium server which will control the browser. There is a script in the phoenix repo that starts the selenium server, just run that to start selenium.\ncd $HOME/phoenix yarn run selenium Now we can run the tests. The tests will take several configuration variables which can be found here. Without configuration, most of the defaults will work. We just need make sure to set these values through env variable.\nexport PHOENIX_PATH=$HOME/phoenix export OCIS_SKELETON_DIR=\u0026lt;path to the skeleton directory\u0026gt; export PHOENIX_CONFIG=\u0026lt;path to the config.json file used by phoenix\u0026gt; The phoenix path should be set to the directory where the phoenix source files are. Our tests use the existing infrastructure from the phoenix directory to run the tests.\nThe skeleton directory for the webui tests can be found in the testing app. You can just clone that repository in your local machine and point the env variable to the correct path.\nWhile running ocis we should always use a config file for phoenix because our tests will read this file and sometimes even change it which cannot be done if you use env variables or the default values.\nWith all this in place we can just run the tests with a simple make command. First go to the ocis-hello repository\ncd \u0026lt;path to ocis-hello\u0026gt; Then Simply run\nmake test-acceptance-webui To run just one feature you can run\nmake test-acceptance-webui \u0026lt;path-to-feature file\u0026gt;:\u0026lt;line-number\u0026gt; "});index.add({'id':80,'href':'/extensions/settings/values/','title':"Settings Values",'content':"A Settings Value is the value an authenticated user has chosen for a specific setting, defined in a settings bundle. For choosing settings values as a user the sole entry point is the ocis-web extension provided by this service.\nIdentifying settings values A settings value is uniquely identified by four attributes. Three of them are coming from the definition of the setting within it\u0026rsquo;s settings bundle (see Settings Bundles for an example). The fourth identifies the user.\n extension: Key of the extension that registered the settings bundle, bundleKey: Key of the settings bundle, settingKey: Key of the setting as defined within the bundle, accountUuid: The UUID of the authenticated user who has saved the setting.  When requests are going through ocis-proxy, the accountUuid attribute can be set to the static keyword me instead of using a real UUID. ocis-proxy will take care of minting the UUID of the authenticated user into a JWT, providing it in the HTTP header as x-access-token. That UUID is then used in this service, to replace me with the actual UUID of the authenticated user.  Example of stored settings values { \u0026#34;values\u0026#34;: { \u0026#34;language\u0026#34;: { \u0026#34;identifier\u0026#34;: { \u0026#34;extension\u0026#34;: \u0026#34;ocis-accounts\u0026#34;, \u0026#34;bundleKey\u0026#34;: \u0026#34;profile\u0026#34;, \u0026#34;settingKey\u0026#34;: \u0026#34;language\u0026#34;, \u0026#34;accountUuid\u0026#34;: \u0026#34;5681371f-4a6e-43bc-8bb5-9c9237fa9c58\u0026#34; }, \u0026#34;listValue\u0026#34;: { \u0026#34;values\u0026#34;: [ { \u0026#34;stringValue\u0026#34;: \u0026#34;de\u0026#34; } ] } }, \u0026#34;timezone\u0026#34;: { \u0026#34;identifier\u0026#34;: { \u0026#34;extension\u0026#34;: \u0026#34;ocis-accounts\u0026#34;, \u0026#34;bundleKey\u0026#34;: \u0026#34;profile\u0026#34;, \u0026#34;settingKey\u0026#34;: \u0026#34;timezone\u0026#34;, \u0026#34;accountUuid\u0026#34;: \u0026#34;5681371f-4a6e-43bc-8bb5-9c9237fa9c58\u0026#34; }, \u0026#34;listValue\u0026#34;: { \u0026#34;values\u0026#34;: [ { \u0026#34;stringValue\u0026#34;: \u0026#34;Europe/Berlin\u0026#34; } ] } } } } gRPC endpoints The obvious way of modifying settings is the ocis-web extension, as described earlier. However, services can use the respective gRPC endpoints of the ValueService to query and modify settings values as well. The gRPC endpoints require the same identifier attributes as described above, so for making a request to the ValueService you will have to make sure that the accountUuid of the authenticated user is available in your service at the time of the request.\n"});index.add({'id':81,'href':'/ocis/development/tracing/','title':"Tracing",'content':"By default, we use Jaeger for request tracing within oCIS. You can follow these steps to get started:\n Start Jaeger by using the all-in-one docker image: docker run -d --name jaeger \\ -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \\ -p 5775:5775/udp \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 14268:14268 \\ -p 14250:14250 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1.17  Every single oCIS service has its own environment variables for enabling and configuring tracing.  You can enable and configure tracing on each service individually. For example, enable tracing in Reva when starting the oCIS single binary like this: REVA_TRACING_ENABLED=true \\ REVA_TRACING_ENDPOINT=localhost:6831 \\ REVA_TRACING_COLLECTOR=http://localhost:14268/api/traces \\ ./bin/ocis server  Enabling and configuring tracing on oCIS itself will forward the configuration to all services: OCIS_TRACING_ENABLED=true \\ OCIS_TRACING_ENDPOINT=localhost:6831 \\ OCIS_TRACING_COLLECTOR=http://localhost:14268/api/traces \\ ./bin/ocis server If you want to set individual tracing configuration for each service, make sure to set OCIS_TRACING_ENABLED=false.\n   Make the actual request that you want to trace. Open up the Jaeger UI to analyze request traces.  For more information on Jaeger, please refer to their Documentation.\n"});index.add({'id':82,'href':'/extensions/storage/releasing/','title':"Releasing",'content':"    Preparation Release     To release a new version of the storage submodule, you have to follow a few simple steps.\nPreparation  Before releasing, make sure that reva has been updated to the desired version  Release  Check out master git checkout master git pull origin master Create a new tag (preferably signed) and replace the version number accordingly. Prefix the tag with the submodule storage/v. git tag -s storage/vx.x.x -m \u0026#34;release vx.x.x\u0026#34; git push origin storage/vx.x.x Wait for CI and check that the GitHub release was published.  Congratulations, you just released the storage submodule!\n"});index.add({'id':83,'href':'/clients/web/testing/','title':"Running acceptance tests",'content':"    Setting up Selenium  Setup using Docker Setup using Docker Desktop for Mac Setup using standalone Selenium server   run tests  with ownCloud 10 backend with OCIS backend  the quick way (all automated) the manual way (e.g. to run from an existing ocis location)     Available settings to be set by environment variables Tipps  too many open files   Acceptance Tests in CI  1. phoenix Repo 2. ocis Repo       Setting up Selenium There are multiple ways to run Selenium:\n Setup using Docker Setup using Docker Desktop for Mac Setup using a standalone Selenium server  Setup using Docker  Set the environment variables SELENIUM_HOST as localhost and SERVER_HOST in the format http://\u0026lt;ip_addr\u0026gt;:9100. Run yarn run selenium (available only on Linux) If you are a Mac user, you can run yarn run selenium:mac  This command creates docker container which uses port forwarding instead of host networking which is not supported on Mac    Setup using Docker Desktop for Mac In order to run acceptance tests with selenium running in Docker Desktop for Mac while having ownCloud Server and Phoenix running as services on the host machine, localhost will not work as URL. Use the Docker host ip 172.17.0.1 or its alias host.docker.internal instead. This requires to adjust all relevant config files to use host.docker.internal instead of localhost (config.json in Phoenix and config/config.php in oC10) and to change the phoenix OIDC-callback url. Set the SERVER_HOST and BACKEND_HOST environment variables accordingly. In order to use the same url for development on the host machine, define it as an alias to 127.0.0.1 in /etc/hosts. After all these changes Phoenix will be accessible at http://host.docker.internal:8300 for both development and acceptance tests.\nSetup using standalone Selenium server When running a standalone Selenium server, make sure to set the environment variable SELENIUM_HOST, SELENIUM_PORT and LOCAL_UPLOAD_DIR accordingly.\nrun tests with ownCloud 10 backend  setup the ownCloud 10 backend clone and install testing app into ownCloud build Phoenix start the Phoenix server set SERVER_HOST to point at the URL where the Phoenix web pages are served, for example \u0026ldquo;http://localhost:8300\u0026rdquo; set BACKEND_HOST to point to the URL of the backend, for example \u0026ldquo;http://localhost/owncloud/\u0026rdquo; to be able to run federation tests, additional setup is needed:  Install and setup a second ownCloud server-instance that is accessible by a different URL. That second server-instance must have its own database and data directory. clone and install testing app into the second ownCloud server-instance from http://github.com/owncloud/testing . when running the acceptance tests use REMOTE_BACKEND_HOST environment variable to define its address. for e.g. REMOTE_BACKEND_HOST=http://\u0026lt;ip_address_of_second_ownCloud_server-instance\u0026gt; yarn run acceptance-tests \u0026lt;feature-files-to-test\u0026gt; . -set the SELENIUM_HOST environment variable to your host that runs selenium, mostly localhost -set the SELENIUM_PORT environment variable to your selenium port, mostly 4444    Run yarn run acceptance-tests \u0026lt;feature-files-to-test\u0026gt;.\nThe feature files are located in the \u0026ldquo;tests/acceptance/features\u0026rdquo; subdirectories.\nsee available settings for further setup if needed\nwith OCIS backend  build Phoenix create a new phoenix config.json file and copy it into the dist folder, even running phoenix in the default ocis environment does not need a config.json file, some tests rely on it being present. As starting point and example that should work when running every service on localhost use Linux: config.json.sample-ocis Mac: tests/acceptance/ocis-mac-config.json  the quick way (all automated)  run yarn run test-requirements:ocis (yarn run test-requirements:ocis:mac for Mac users) to install, configure and run all ocis requirements run yarn run acceptance-tests-ocis \u0026lt;feature-files-to-test\u0026gt; to run the tests, the feature files are located in the \u0026ldquo;tests/acceptance/features\u0026rdquo; subdirectories. after the tests run yarn run killall to stop all created docker containers, and the ocis services  the manual way (e.g. to run from an existing ocis location)   clone and build ocis\n  From inside the phoenix directory run yarn run testing-app to get the testing-app, it\u0026rsquo;s needed to have the skeleton folder for the tests\n  Run redis server using docker\nyarn run redis-server   Run the OCIS server with the necessary configurations\nexport REVA_STORAGE_OWNCLOUD_REDIS_ADDR=\u0026#39;localhost:6379\u0026#39; export PHOENIX_ASSET_PATH=\u0026#39;\u0026lt;path-to-phoenix-clone\u0026gt;/dist\u0026#39; export PHOENIX_WEB_CONFIG=\u0026#39;\u0026lt;path-to-phoenix-clone\u0026gt;/dist/config.json\u0026#39; note: PHOENIX_WEB_CONFIG should point to the same config file you have created earlier.\nrun the server:\nbin/ocis server   Run yarn run acceptance-tests-ocis \u0026lt;feature-files-to-test\u0026gt;. The feature files are located in the \u0026ldquo;tests/acceptance/features\u0026rdquo; subdirectories.\n  see available settings for further setup if needed\nAvailable settings to be set by environment variables These values can be set using the environment variables to configure yarn run acceptance-tests and yarn run acceptance-tests-ocis to match your local test environment.\n   setting meaning default     SERVER_HOST phoenix URL http://localhost:8300   BACKEND_HOST ownCloud server URL (or reva service url for running with OCIS) http://localhost:8080   BACKEND_USERNAME ownCloud administrator username admin   BACKEND_PASSWORD ownCloud administrator password admin   SELENIUM_HOST selenium server host, if not set yarn will start selenium automaticallyif running the selenium docker container as mentioned above set to localhost    SELENIUM_PORT port of selenium server 4444   SCREEN_RESOLUTION width and height in px to set the browser resolution to e.g. 375x812 empty = fullscreen   REMOTE_UPLOAD_DIR path to filesForUpload directory, used when uploading files through api ./tests/acceptance/filesForUpload   LOCAL_UPLOAD_DIR filesForUpload directory available for selenium for direct uploadsIf using selenium-docker and example above, set it as /uploads.If running local selenium, set value same as REMOTE_UPLOAD_DIR (please, remember to use absolute path) /uploads   REMOTE_BACKEND_HOST ownCloud remote server URL http://localhost:8080   RUN_ON_OCIS Running the tests using the OCIS backend false   OCIS_REVA_DATA_ROOT Data directory of OCIS /var/tmp/reva   OCIS_SKELETON_DIR Skeleton files directory for new users -   PHOENIX_CONFIG Path for the phoenix config file (usually in the dist folder) -    Tipps too many open files If tests were running fine and then suddenly start to fail your system might run into open file limits. In that case you will see messages in the OCIS log output that look like this:\n2020-05-12 11:33:43.974552 I | http: Accept error: accept tcp [::]:9200: accept4: too many open files; retrying in 1s\nIn that case increase the open file limits, how to do that would be beyond the scope of this documentation.\nAcceptance Tests in CI In the CI we run the UI tests using different backends on different repos. We use commit IDs to indicate the version of the backend or testrunner we want to use. These commit IDs should be regularly updated in the .drone.star file to keep the CI up to date. We run phoenix UI tests in following repos in the CI.\n1. phoenix Repo In the owncloud/phoenix repo, we run the tests using both oc10 backend as well as the OCIS backend. For the oc10 backend, we use owncloudci/core docker image which runs the latest daily-master-qa version of owncloud.\nFor the OCIS backend, we use the Commit ID from owncloud/ocis repo to indicate which version of backend to use. This can be specified in the .drone.star file in the config.defaults section.\n\u0026#39;defaults\u0026#39;: { \u0026#39;acceptance\u0026#39;: { \u0026#39;ocisBranch\u0026#39;: \u0026#39;master\u0026#39;, \u0026#39;ocisCommit\u0026#39;: \u0026#39;284a9996dffa912cc1382e259b748c56ddc4aa0f\u0026#39;, } }, If the version you want to run is on a different branch from master, you also need to change the branch name.\nIn order to check if new tests are compatible with OCIS, after changing the commit id and the branch name, we can create a draft PR in owncloud/phoenix which triggers the CI and we can see the result there.\n2. ocis Repo We follow the same approach in the owncloud/ocis repo too. In order to run the UI tests in CI we use commit IDs from phoenix which can be changed in the .drone.star file.\nacceptance(ctx, \u0026#39;master\u0026#39;, \u0026#39;604e8b5e083c835308f147e51a850df643374107\u0026#39;) This is the commit ID of phoenix indicating the version of testrunner we want to use. If the version is on a branch other than master, we will also need to change the branch name.\n"});index.add({'id':84,'href':'/extensions/thumbnails/license/','title':"License",'content':"This project is licensed under the Apache 2.0 license. For the license of the used libraries you have to check the respective sources.\n"});index.add({'id':85,'href':'/extensions/settings/glossary/','title':"Glossary",'content':"In the context of this extension and oCIS in general, we are using the following terminology.\nConfiguration  System configuration e.g. service host names and ports Changes need to be propagated to other services Typically modified on the CLI  Settings  Application level settings e.g. default language Can be modified at runtime without restarting the service Typically modified in the UI  Preferences  User settings Subset of \u0026ldquo;Settings\u0026rdquo; e.g. preferred language of a user  Settings Bundle  Collection of related settings Registered by an ocis extension  Settings Value  Manifestation of a setting for a specific user E.g. used for customization (at runtime) in ocis-web ocis-web-settings extension for modifying settings values is provided by this service Can be queried and modified by other ocis extensions  "});index.add({'id':86,'href':'/extensions/ocis_hello/license/','title':"License",'content':"This project is licensed under the Apache 2.0 license. For the license of the used libraries you have to check the respective sources.\n"});index.add({'id':87,'href':'/extensions/settings/license/','title':"License",'content':"This project is licensed under the Apache 2.0 license. For the license of the used libraries you have to check the respective sources.\n"});index.add({'id':88,'href':'/ocis/development/building-docs/','title':"Build the documentation",'content':"Buildling the documentation Following steps can be applied for every oCIS extension repository.\nSetting up  Install hugo Run make docs  Viewing the documentation To view the rendered docs in the browser run:\ncd hugo hugo -D server Then open \u0026ldquo;http://localhost:1313/\u0026rdquo;\nWhen making changes to the docs, run\nrsync -ax --delete ../docs/ content/ in the hugo folder and the server will pick up the changes and reload the page automatically.\nDeploying the documentation The documentation is automatically deployed from the master branch to https://owncloud.github.io\n"});index.add({'id':89,'href':'/ocis/license/','title':"License",'content':"This project is licensed under the Apache 2.0 license. For the license of the used libraries you have to check the respective sources.\n"});index.add({'id':90,'href':'/extensions/','title':"Extensions",'content':""});index.add({'id':91,'href':'/','title':"ownCloud",'content':"Developer Documentation Welcome to our developer documentation. Here you can find documentation for developers on\n The oCIS server oCIS extensions All Client, like Android, iOS, and the Desktop Client Integrations  We love open source The oCIS server is Apache v2 licensed. The lower storage layer of oCIS is defined by the CS3 APIs and implemented in the REVA project. Our goal is to develop the CS3 APIs to an open standard and collaborate on the open source REVA reference implementation for CS3 APIs.\nYou can also find all client sources on github.\nJoin us The oCIS server repository on github is a good entrypoint for you to join the project. But we also develop clients for iOS, Android, Desktop and Web.\nFor communication on development you can join our public chat https://talk.owncloud.com\nIf you want to help and improve ownCloud, start coding or open issues on github in the related repositiory.\nWe are very happy to hear your feedback and ideas!\n"});index.add({'id':92,'href':'/extensions/proxy/','title':"Proxy",'content':"This service provides a basic proxy in front of the public ocis services.\n"});index.add({'id':93,'href':'/extensions/konnectd/','title':"Konnectd",'content':"This service provides an OpenID Connect provider which is the default way to authenticate in OCIS.\n"});index.add({'id':94,'href':'/integration/','title':"Integrations",'content':""});index.add({'id':95,'href':'/clients/','title':"Clients",'content':""});index.add({'id':96,'href':'/extensions/ocis_hello/','title':"Hello",'content':"\nAbstract When getting started with ocis development developers need to learn about the building blocks of ocis extensions. Without guidance or orientation of the why and what of an extension they may start feeling lost. The ocis-hello repository serves as a blueprint for ocis extensions. It allows developers to get started with ocis extension development by looking at the code, configuration and documentation.\n  mermaid.initialize({ flowchart: { useMaxWidth: true } });  graph TD subgraph ow[ocis-web] owh[ocis-web-hello] end owh ---|\"greet()\"| ows[ocis-hello-server] ocis-hello provides a simple hello world example with\n a protobuf based greeter API a grpc service implementing the API a vue.js frontend using the API  It can be integrated into ocis web as documented in the extensions docs.\nTable of Contents    Getting Started     Building     Running     Settings     Testing     License     "});index.add({'id':97,'href':'/categories/','title':"Categories",'content':""});index.add({'id':98,'href':'/tags/','title':"Tags",'content':""});})();